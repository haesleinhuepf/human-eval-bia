{"task_id": "../test_cases/apply_otsu_threshold_and_count_positive_pixels.ipynb", "prompt": "def apply_otsu_threshold_and_count_positive_pixels(image):\n    \"\"\"\n    Takes an image, applies Otsu's threshold method to it to create a binary image and \n    counts the positive pixels.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n\n    result = np.sum(binary_image)\n\n    return result", "entry_point": "apply_otsu_threshold_and_count_positive_pixels", "test": "def check(candidate):\n    import numpy as np\n    \n    assert candidate(np.asarray([\n        [0,0,0,0,0],\n        [1,1,1,0,0],\n        [1,1,1,0,0],\n        [1,0,0,0,0],\n        [0,0,0,1,0],\n    ])) == 8\n\n    assert candidate(np.asarray([\n        [0,0,0,0,0],\n        [0,1,0,0,0],\n        [1,2,1,0,0],\n        [0,1,3,4,0],\n        [0,1,4,1,0],\n    ])) == 4\n\n    assert candidate(np.asarray([\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n    ])) == 0"}
{"task_id": "../test_cases/binary_closing.ipynb", "prompt": "def binary_closing(binary_image, radius:int=1):\n    \"\"\"\n    Applies binary closing to a binary_image with a square footprint with a given radius.\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    import skimage\n    size = radius * 2 + 1\n    return skimage.morphology.binary_closing(binary_image, footprint=np.ones((size, size)))", "entry_point": "binary_closing", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(np.asarray([\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,1,0,1,0,0],\n        [0,0,1,0,1,0,0],\n        [0,0,1,0,1,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n    ]))\n\n    reference = np.asarray([\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,1,1,1,0,0],\n        [0,0,1,1,1,0,0],\n        [0,0,1,1,1,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n    ])\n\n    assert np.array_equal(reference, result)"}
{"task_id": "../test_cases/binary_skeleton.ipynb", "prompt": "def binary_skeleton(binary_image):\n    \"\"\"\n    Applies skeletonization to a 2D binary image.\n    \"\"\"", "canonical_solution": "\n    from skimage.morphology import skeletonize\n    return skeletonize(binary_image)", "entry_point": "binary_skeleton", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(np.asarray([\n        [0,0,0,0,0,0,0],\n        [0,0,1,1,1,0,0],\n        [0,0,1,1,1,0,0],\n        [0,1,1,1,1,1,0],\n        [0,1,1,1,1,1,0],\n        [0,1,1,1,1,1,0],\n        [0,0,0,0,0,0,0],\n    ]))\n    \n    reference = np.asarray([\n        [0,0,0,0,0,0,0],\n        [0,0,0,1,0,0,0],\n        [0,0,0,1,0,0,0],\n        [0,0,0,1,0,0,0],\n        [0,1,1,1,1,1,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n    ])\n\n    # we're accepting a little error because for example \n    # the center pixel or the ending pixel may vary, \n    # depending on the implementation\n    assert np.abs(np.abs(result) - np.abs(reference)).sum() <= 3"}
{"task_id": "../test_cases/bland_altman.ipynb", "prompt": "def bland_altman(dataframe, column1:str, column2:str):\n    \"\"\"\n    Takes two specified columns from a given dataframe and applies Bland-Altman-Analysis to them.\n    Therefore, it adds two new columns, one called 'mean' containing the mean of the two corresponding values,\n    and one called 'diff' containing the difference between the two.\n    \"\"\"", "canonical_solution": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    dataframe['mean'] = (data1 + data2) / 2\n    dataframe['diff'] = data2 - data1\n    return dataframe", "entry_point": "bland_altman", "test": "def check(candidate):\n    import pandas as pd\n    import numpy as np\n    df = pd.DataFrame(\n        {\n         'a':[1,2,3,0],\n         'b':[2,2,3,6]\n        }\n    )\n\n    candidate(df, 'a', 'b')\n\n    assert len(df.columns) == 4\n    \n    mean_column = df['mean']\n    diff_column = df['diff']\n    \n    assert np.array_equal([1.5, 2, 3, 3], mean_column)\n    assert np.array_equal([1,  0,0, 6], diff_column) or \\\n           np.array_equal([-1, 0,0,-6], diff_column)"}
{"task_id": "../test_cases/combine_columns_of_tables.ipynb", "prompt": "def combine_columns_of_tables(dataframe1, dataframe2, index):\n    \"\"\"\n    This function combines to dataframes and makes sure the data is merged \n    using the given index column, which must be present in both dataframes.\n    The dataframes should be merged in a way that no data is lost and missing\n    fields are filled with NaN.\n    \"\"\"", "canonical_solution": "\n    import pandas as pd\n    return pd.merge(dataframe1, dataframe2, how='outer', on='label')", "entry_point": "combine_columns_of_tables", "test": "def check(candidate):\n    import pandas as pd\n    import numpy as np\n\n    table1 = pd.DataFrame({\n    \"label\":       [1,   2,   3],\n    \"circularity\": [0.3, 0.5, 0.7],\n    \"elongation\":  [2.3, 3.4, 1.2],\n    })\n\n    table2 = pd.DataFrame({\n    \"label\":    [3,   2,   1,   4],\n    \"area\":     [22,  32,  25,  18],\n    \"skewness\": [0.5, 0.6, 0.3, 0.3],\n    })\n\n    reference = pd.DataFrame({\n    \"label\":       [1,   2,   3,   4],\n    \"circularity\": [0.3, 0.5, 0.7, np.nan],\n    \"elongation\":  [2.3, 3.4, 1.2, np.nan],\n    \"area\":     [25,  32,  22,  18],\n    \"skewness\": [0.3, 0.6, 0.5, 0.3],\n    })\n    \n    result = candidate(table1, table2, \"label\")\n\n    comparison = result.compare(reference)\n    assert len(comparison.columns) == 0\n    assert len(comparison.index) == 0"}
{"task_id": "../test_cases/convert_points_polygon.ipynb", "prompt": "def create_polygon_from_coordinates(coordinates):\n    \"\"\"\n    Take a list of 4 or more coordinates in xy format and convert it into a shapely polygon. Return the polygon.\n    \"\"\"", "canonical_solution": "\n    from shapely import Polygon\n    polygon = Polygon(coordinates)\n    return polygon\n", "entry_point": "create_polygon_from_coordinates", "test": "def check(candidate):\n    from shapely import Polygon\n    points = [[0,0],[2,0],[3,5],[0,9]]\n    poly = candidate(points)\n    assert poly.is_valid\n    assert isinstance(poly,Polygon)"}
{"task_id": "../test_cases/convex_hull_measure_area.ipynb", "prompt": "def convex_hull_measure_area(point_cloud):\n    \"\"\"\n    Take a 3D point_cloud, determines the convex hull around the points and returns the surface area of the convex hull.\n    \"\"\"", "canonical_solution": "\n    import vedo\n    convex_hull = vedo.shapes.ConvexHull(point_cloud)\n    return convex_hull.area()", "entry_point": "convex_hull_measure_area", "test": "def check(candidate):\n    point_cloud = [[0,1,0],[0,1,1],[0,0,0],[0,0,1],[1,1,0],[1,1,1],[1,0,0],[1,0,1]]\n\n    assert abs(candidate(point_cloud) - 6) < 0.001\n\n    point_cloud = [[0,1,0],[0,1,1],[0,0,0],[0,0,1],[2,1,0],[2,1,1],[2,0,0],[2,0,1]]\n\n    assert abs(candidate(point_cloud) - 10) < 0.001\n"}
{"task_id": "../test_cases/convolve_images.ipynb", "prompt": "def convolve_images(image, kernel_image):\n    \"\"\"\n    Convolve an image with a kernel_image and return the result\n    \"\"\"", "canonical_solution": "\n    import scipy\n    return scipy.ndimage.convolve(image, kernel_image)\n    ", "entry_point": "convolve_images", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [0,0,0,0,0,0,0],\n        [0,1,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,1,0,0],\n        [0,0,0,0,0,0,0],\n    ])\n    kernel= np.asarray([\n        [0,1,0],\n        [1,1,1],\n        [0,2,0],\n    ])\n\n    reference = np.asarray([\n        [0,1,0,0,0,0,0],\n        [1,1,1,0,0,0,0],\n        [0,2,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,1,0,0],\n        [0,0,0,1,1,1,0],\n        [0,0,0,0,2,0,0],\n    ])\n\n    result = candidate(image, kernel)\n    \n    assert np.allclose(reference, result)\n\n    \n    image = np.asarray([\n        [0,0,0,0,0,0,0],\n        [0,1,1,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n    ])\n\n    reference = np.asarray([\n        [0,1,1,0,0,0,0],\n        [1,2,2,1,0,0,0],\n        [0,2,2,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n    ])\n\n    result = candidate(image, kernel)\n    \n    assert np.allclose(reference, result)\n   \n"}
{"task_id": "../test_cases/count_number_of_touching_neighbors.ipynb", "prompt": "def count_number_of_touching_neighbors(label_image):\n    \"\"\"\n    Takes a label image and returns a list of number of touching neighbors \n    for each labeled object.\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n\n    touch_matrix = cle.generate_touch_matrix(label_image)\n    cle.set_row(touch_matrix, 0, 0)\n    cle.set_column(touch_matrix, 0, 0)\n\n    return np.asarray(cle.sum_y_projection(touch_matrix))[0,1:]", "entry_point": "count_number_of_touching_neighbors", "test": "def check(candidate):\n    import numpy as np\n\n    label_image = np.asarray([\n        [0,0,0,0,0],\n        [0,0,2,2,0],\n        [0,0,1,3,0],\n        [0,4,1,0,0],\n        [0,0,0,0,0],\n    ])\n    print(candidate(label_image))\n    assert np.array_equal(candidate(label_image), [3, 2, 2, 1])"}
{"task_id": "../test_cases/count_objects_over_time.ipynb", "prompt": "def count_objects_over_time(binary_image_list):\n    \"\"\"\n    Takes a timelapse (list of binary images), counts the number of connected components and returns the resulting counts as list.\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    from skimage.measure import label\n    labels = [label(binary_image) for binary_image in binary_image_list]\n    return [len(np.unique(label)) - 1 for label in labels]", "entry_point": "count_objects_over_time", "test": "def check(candidate):\n    import numpy as np\n\n    images = [\n        np.asarray([\n            [1,0,0,0],    \n            [0,0,0,0],    \n            [0,0,1,0],    \n            [0,0,0,0],            \n        ]),\n        np.asarray([\n            [1,0,0,0],    \n            [0,0,0,0],    \n            [0,0,1,1],    \n            [0,0,0,0],            \n        ]),\n        np.asarray([\n            [1,0,0,0],    \n            [0,0,0,0],    \n            [0,0,0,1],    \n            [0,1,0,0],            \n        ]),\n        np.asarray([\n            [1,1,0,0],    \n            [0,0,0,0],    \n            [0,0,0,1],    \n            [0,1,0,0],            \n        ]),\n        np.asarray([\n            [0,0,1,0],    \n            [1,0,0,0],    \n            [0,0,0,1],    \n            [0,1,0,0],            \n        ]),\n    ]\n    reference = [2,2,3,3,4]\n    \n    result = candidate(images) \n\n    assert np.allclose(reference, result)\n"}
{"task_id": "../test_cases/count_overlapping_regions.ipynb", "prompt": "def count_overlapping_regions(label_image_1, label_image_2):\n    \"\"\"\n    Takes two label images and counts how many objects in label_image_1 overlap \n    with any label in label_image_2 with at least one pixel.\n    It returns the count of overlapping objects.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image_1, label_image_2, properties=('mean_intensity',))\n    return (pd.DataFrame(stats)['mean_intensity'] > 0).sum()", "entry_point": "count_overlapping_regions", "test": "def check(candidate):\n    import numpy as np\n\n    label_image_1 = np.asarray([\n        [0,1,0,0,0],\n        [0,0,2,0,0],\n        [0,0,0,3,0],\n        [0,4,4,0,0],\n        [0,0,0,5,0],\n    ])\n\n    label_image_2 = np.asarray([\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,1,0],\n        [0,0,1,0,0],\n        [0,0,0,1,0],\n    ])\n    \n    result = candidate(label_image_1, label_image_2) \n    assert result == 3\n\n    result = candidate(label_image_2, label_image_1)\n    assert result == 1\n"}
{"task_id": "../test_cases/create_multipolygon_from_coordinates.ipynb", "prompt": "def create_multipolygon_from_coordinate_list(coordinates):\n    \"\"\"\n    Take a list of coordinate lists that intersect only at one point and create a shapely multipolygon. \n    The multipolygon must be valid. Return the multipolygon\n    \"\"\"", "canonical_solution": "\n    from shapely.geometry import Polygon, MultiPolygon\n    multi_poly = MultiPolygon([Polygon(x) for x in coordinates])\n    return multi_poly", "entry_point": null, "test": "def check(candidate):\n    points = [[[0,0],[2,0],[3,5],[0,9]],\n          [[1,1],[2,0],[5,8],[8,8]]]\n    from shapely.geometry import MultiPolygon\n    ref_poly = candidate(points)\n    assert ref_poly.is_valid\n    assert isinstance(ref_poly,MultiPolygon)"}
{"task_id": "../test_cases/create_umap.ipynb", "prompt": "def create_umap(dataframe):\n    \"\"\"\n    Takes a dataframe and computes a UMAP from all columns. \n    The two UMAP vectors are stored in the dataframe as `umap0` and `umap1`.\n    \"\"\"", "canonical_solution": "\n    import umap\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    # no return value", "entry_point": "create_umap", "test": "def check(candidate):\n    import pandas as pd\n    df = pd.DataFrame(\n        {\n         \"a\":[1.6,2.3,2.6,3.7,3.4,3.9,4.3,4.3,4.0,5.1,5.2,5.3,5.5], \n         \"b\":[0.1,0.2,0.3,0.3,0.4,0.4,0.4,0.5,0.5,0.5,0.6,0.6,0.6],\n         \"c\":[1.6,2.3,2.6,3.7,3.4,3.9,4.3,4.3,4.0,5.1,5.2,5.3,5.4],\n         \"d\":[1.7,2.4,2.4,3.6,3.5,3.9,4.4,4.2,4.1,5.0,5.1,5.4,5.6]\n        }\n    )\n    candidate(df)\n    \n    expected_columns = ['umap0', 'umap1']\n\n    # I'm not sure how to check if the umap columns contain a proper umap, \n    # but we can check if all expected columns exist.\n    for ec in expected_columns:\n        assert ec in df.columns"}
{"task_id": "../test_cases/crop_quarter_image.ipynb", "prompt": "def crop_quarter_image(image):\n    \"\"\"\n    Crops out the first half image in both dimensions (width and height). \n    The resulting image will be of quarter size compared to the original image.\n    \"\"\"", "canonical_solution": "\n    width = image.shape[1]\n    height = image.shape[0]\n\n    return image[:int(width/2),:int(height/2)]", "entry_point": "crop_quarter_image", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [0,0,0,0,0,0],\n        [0,1,0,0,2,0],\n        [0,0,0,0,0,0],\n        [0,0,0,0,0,0],\n        [0,4,0,0,3,0],\n        [0,0,0,0,0,0],\n    ])\n\n    reference = np.asarray([\n        [0,0,0],\n        [0,1,0],\n        [0,0,0],\n    ])\n    \n    assert np.array_equal(candidate(image), reference)\n"}
{"task_id": "../test_cases/deconvolve_image.ipynb", "prompt": "def deconvolve_image(image, kernel_image):\n    \"\"\"\n    Deconvolve an image with a kernel_image and return the result.\n    \"\"\"", "canonical_solution": "\n    from scipy import fftpack\n\n    # adapted from: https://stackoverflow.com/questions/17473917/is-there-a-equivalent-of-scipy-signal-deconvolve-for-2d-arrays\n    star_fft = fftpack.fftshift(fftpack.fftn(image))\n    psf_fft = fftpack.fftshift(fftpack.fftn(kernel_image))\n    return fftpack.fftshift(fftpack.ifftn(fftpack.ifftshift(star_fft/psf_fft)))\n    ", "entry_point": "deconvolve_image", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [0,1,0,0,0,0,0],\n        [1,1,1,0,0,0,0],\n        [0,2,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,1,0,0],\n        [0,0,0,1,1,1,0],\n        [0,0,0,0,2,0,0],\n    ])\n    kernel= np.asarray([\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,1,0,0,0],\n        [0,0,1,1,1,0,0],\n        [0,0,0,2,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n    ])\n\n    reference = np.asarray([\n        [0,0,0,0,0,0,0],\n        [0,1,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,1,0,0],\n        [0,0,0,0,0,0,0],\n    ])\n\n    result = candidate(image, kernel)\n    \n    assert np.allclose(reference, result)\n\n    \n    image = np.asarray([\n        [0,1,1,0,0,0,0],\n        [1,2,2,1,0,0,0],\n        [0,2,2,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n    ])\n\n    reference = np.asarray([\n        [0,0,0,0,0,0,0],\n        [0,1,1,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n    ])\n\n    result = candidate(image, kernel)\n    assert np.allclose(reference, result)\n   \n"}
{"task_id": "../test_cases/detect_edges.ipynb", "prompt": "def detect_edges(image):\n    \"\"\"\n    Applies an edge-detection filter to an image.\n    \"\"\"", "canonical_solution": "\n    from scipy.ndimage import sobel\n    filtered_image = sobel(image)\n    return filtered_image", "entry_point": "detect_edges", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [1,1,2,2,2],\n        [1,1,2,2,2],\n        [1,1,2,2,2],\n        [1,1,2,2,2],\n        [1,1,2,2,2],\n    ])\n\n    result = candidate(image)\n    left_column = result[:,0]\n    center_columns = result[:,1:4]\n    right_column = result[:,-1]\n\n    assert left_column.max() == 0 and left_column.min() == 0\n    assert center_columns.max() != 0 or center_columns.min() != 0\n    assert right_column.max() == 0 and left_column.min() == 0"}
{"task_id": "../test_cases/detect_ellipse.ipynb", "prompt": "def detect_ellipse(image):\n    \"\"\"\n    Given a binary edge map, detect the ellipse in the image using a Hough Transform.\n    Return the center of the ellipse in the image as a tuple (y, x).\n    \"\"\"", "canonical_solution": "\n    from skimage.transform import hough_ellipse\n    result = hough_ellipse(image,  accuracy=5, threshold=10)\n    result.sort(order='accumulator')\n    \n    # Estimated parameters for the ellipse\n    best = list(result[-1])\n    yc, xc, a, b = (int(round(x)) for x in best[1:5])\n    \n    return yc, xc", "entry_point": "detect_ellipse", "test": "import numpy as np\ndef draw_elipse(x, y, a=20, b=10, angle_rad=np.pi / 4):\n    from skimage.draw import ellipse_perimeter\n    image = np.zeros((100, 100))\n    cy, cx = ellipse_perimeter(y, x, a, b, angle_rad)\n    image[cy, cx] = 1\n    return image\n\ndef check(candidate):\n\n    x = 60\n    y = 30\n    image = draw_elipse(x=x, y=y)\n    yc, xc = detect_ellipse(image)\n    \n    # Check if the center of the ellipse is detected within a distance of 1 pixel\n    assert abs(yc - y) <= 1\n    assert abs(xc - x) <= 1\n\n    x = 25\n    y = 12\n    image = draw_elipse(x=x, y=y, a=5, b=3)\n    yc, xc = detect_ellipse(image)\n    \n    # Check if the center of the ellipse is detected within a distance of 1 pixel\n    assert abs(yc - y) <= 1\n    assert abs(xc - x) <= 1\n"}
{"task_id": "../test_cases/distance_between_maxima.ipynb", "prompt": "def distance_between_maxima(image1,image2):\n    \"\"\"\n    Takes two images as input, finds the maximum pixel in each image, and returns \n    the distance in pixels between the two maxima.\n    Input: two 2D images as separate inputs\n    Output: Float\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n\n    im1 = np.asarray(image1)\n    im2 = np.asarray(image2)\n\n    x1,y1 = np.unravel_index(im1.argmax(), im1.shape)\n    x2,y2 = np.unravel_index(im2.argmax(), im2.shape)\n\n    distance = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n\n    return distance", "entry_point": "distance_between_maxima", "test": "def check(candidate):\n    import numpy as np\n\n    image1 = np.asarray([\n            [0,1,2,0,0],\n            [0,0,3,2,0],\n            [0,0,1,2,0],\n            [0,4,1,1,0],\n            [0,0,0,0,0],\n        ])\n\n    image2 = np.asarray([\n            [0,0,0,5,0],\n            [0,1,0,1,0],\n            [1,0,2,0,0],\n            [0,0,3,4,0],\n            [1,1,0,0,0],\n        ])\n    \n    result = candidate(image1,image2)\n\n    assert np.allclose(result, np.sqrt(13), 0.01)\n\n    image1 = np.asarray([\n            [0,0,0,0,0],\n            [0,0,1,0,0],\n            [0,0,0,0,0],\n            [0,0,0,0,0],\n            [0,0,0,0,0],\n        ])\n\n    image2 = np.asarray([\n            [0,0,0,0,0],\n            [0,0,0,0,0],\n            [0,0,1,0,0],\n            [0,0,0,0,0],\n            [0,0,0,0,0],\n        ])\n    \n    result = candidate(image1,image2)\n\n    assert np.allclose(result, 1, 0.01)\n"}
{"task_id": "../test_cases/expand_labels_without_overlap.ipynb", "prompt": "def expand_labels_without_overlap(label_image, radius:int=1):\n    \"\"\"\n    Takes a label_image and enlarges all labels by a given radius, without\n    labels overwriting each other.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    return skimage.segmentation.expand_labels(label_image, distance=radius)", "entry_point": "expand_labels_without_overlap", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(np.asarray([\n        [0,0,0,0,0],\n        [0,1,1,3,0],\n        [0,1,1,3,0],\n        [0,0,0,0,0],\n        [2,0,0,0,0],\n    ]))\n\n    reference = np.asarray([\n        [0,1,1,3,0],\n        [1,1,1,3,3],\n        [1,1,1,3,3],\n        [2,1,1,3,0],\n        [2,2,0,0,0],\n    ])\n\n    assert np.array_equal(reference, result)"}
{"task_id": "../test_cases/extract_surface_measure_area.ipynb", "prompt": "def extract_surface_measure_area(binary_volume_image):\n    \"\"\"\n    Take a 3D binary_volume_image, extracts the surface of the white (voxel value != 0) object \n    and returns the surface area of the object.\n    \"\"\"", "canonical_solution": "\n    import vedo\n    volume = vedo.Volume(binary_volume_image)\n    iso_surface = volume.isosurface()\n    return iso_surface.area()", "entry_point": "extract_surface_measure_area", "test": "def check(candidate):\n    import numpy as np\n    binary_volume_image = np.asarray([\n        [\n            [0,0,0,0],\n            [0,0,0,0],\n            [0,0,0,0],\n            [0,0,0,0],\n        ],[\n            [0,0,0,0],\n            [0,1,1,0],\n            [0,1,1,0],\n            [0,0,0,0],\n        ],[\n            [0,0,0,0],\n            [0,1,1,0],\n            [0,1,1,0],\n            [0,0,0,0],\n        ],[\n            [0,0,0,0],\n            [0,0,0,0],\n            [0,0,0,0],\n            [0,0,0,0],\n        ],\n    ])\n    assert abs(candidate(binary_volume_image) - 20) < 1\n\n    binary_volume_image = np.zeros((3,3,3))\n    binary_volume_image[1,1,1] = 1\n    assert abs(candidate(binary_volume_image) - 3) < 1\n"}
{"task_id": "../test_cases/fft_spectrum.ipynb", "prompt": "def check(candidate):\n    \n    def fft_spectrum_reference(nd_image, padding):\n        \"\"\"\n        Returns the FFT spectrum of an arbitrary nD image as the absolute logarithm (log1p) of the Fourier transform magnitude. Ensures that the DC component is at the center of the image. Uses reflection padding (provided as integer parameter) and Hamming apodization to reduce artefacts due to discontinuities at the image borders.\n        \"\"\"", "canonical_solution": "\n        import numpy as np\n    \n        # computing padding tuple:\n        pad_width = ((padding, padding),)*nd_image.ndim\n    \n        # Padding:\n        image_padded = np.pad(nd_image, pad_width=pad_width, mode='symmetric')\n        \n        # prepare the apodization window in 1D:\n        from scipy import signal\n        window_tuple = (signal.windows.hamming(length+2*padding) for length in nd_image.shape)\n        \n        # prepare the apodization window in nD:\n        import functools\n        window = functools.reduce(np.multiply.outer, window_tuple)\n        \n        # Apodize:\n        image_padded_apodized = window*image_padded\n    \n        # Compute the Fourier transform of the image:\n        image_fft = np.fft.fftn(image_padded_apodized)\n        \n        # Shift the zero-frequency component to the center of the spectrum:\n        image_fft_shifted = np.fft.fftshift(image_fft)\n        \n        # Compute the magnitude spectrum:\n        magnitude_spectrum = np.log1p(np.abs(image_fft_shifted))\n            \n        return(magnitude_spectrum)\n    \n    import numpy as np   \n\n    # Test image:\n    image = np.ones((5, 6, 7), dtype=np.int16)\n\n    # Padding:\n    padding_width = 10\n\n    # running the candidate function:\n    magnitude_spectrum_candidate = candidate(image, padding_width)\n    \n    # Reference implementation:\n    magnitude_spectrum_reference = fft_spectrum_reference(image, padding_width)\n    \n    assert np.allclose(magnitude_spectrum_candidate, magnitude_spectrum_reference)", "entry_point": "fft_spectrum", "test": null}
{"task_id": "../test_cases/find_closest_neighbors.ipynb", "prompt": "def find_closest_neighbors(label_image, target_label, n):\n    \"\"\"\n    Given a label_image and target_label number of interest, find the n closest \n    other labelled regions (by inter-centroid distance) and return them as list\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    from skimage.measure import centroid\n    \n    # Identify all centroid locations\n    label_count = np.max(label_image)\n    centroids = {}\n    for i in range(1, label_count + 1):\n        binary_image = (label_image == i)\n        centroids[i] = centroid(binary_image)\n    \n    # Find the closest top n\n    distances = [(other, np.linalg.norm(centroids[target_label] - centroids[other])) for other in centroids.keys() if other != target_label]\n    sorted_distances = sorted(distances, key = lambda pair: pair[1])\n    topn = [label for label, _ in sorted_distances[:n]]\n\n    return topn", "entry_point": "find_closest_neighbors", "test": "def check(candidate):\n    import numpy as np\n    \n    label_image = np.asarray([\n        [0,0,0,5,5],\n        [1,2,2,6,0],\n        [1,2,2,6,0],\n        [1,4,4,3,0],\n        [0,0,4,4,4],\n    ])\n\n\n    expected = [3, 6, 2]\n    result = candidate(label_image, target_label=4, n=3)\n    assert result == expected\n\n    expected = [2, 4,]\n    result = candidate(label_image, target_label=1, n=2)\n    assert result == expected\n\n    expected = [6,2]\n    result = candidate(label_image, target_label=5, n=2)\n    assert result == expected"}
{"task_id": "../test_cases/fit_circle.ipynb", "prompt": "def fit_circle(list_of_2d_points):\n    \"\"\"\n    Implements 2D circle fitting\n    Input: Collection of 2d points, represented as a list of lists [ [x0,y0], [x1,y1], ... ]  \n    Output: Tuple: xc, yc, radius\n    \"\"\"", "canonical_solution": "\n    import circle_fit as cf\n    xc, yc, r, _ = cf.least_squares_circle(list_of_2d_points)\n    return xc,yc,r", "entry_point": "fit_circle", "test": "def check(candidate):\n    coordinates = [[1, 0], [-1, 0], [0, 1], [0, -1]]\n    xc, yc, r = candidate(coordinates)\n    tolerance = 0.05\n    assert xc > 0 - tolerance \n    assert xc < 0 + tolerance\n    assert yc > 0 - tolerance \n    assert yc < 0 + tolerance\n    assert r > 1 - tolerance \n    assert r < 1 + tolerance"}
{"task_id": "../test_cases/fit_gaussian_to_spot.ipynb", "prompt": "def fit_gaussian_to_spot(image):\n    \"\"\"\n    Implements 2D gaussian fitting to a noisy spot in the image, find the center (xc, yc) and \n    standard deviation (sigma) of the gaussian fit to the spot, all in pixel coordinates. \n    Perform the fit using unweighted least-squares fitting, in which the sum of squared errors in minimized.\n    The first pixel (top-left corner) has coordinates (0,0). Background knowledge: the \n    image contains a single noisy gaussian spot with a width of approximately 5 pixels. \n    The intensity of the spot and number of background photons is arbitrary. \n    The pixel size is irrelevant, since everything is in pixel units.\n\n    Input: 2D square grayscale image\n    Output: Tuple: (xc, yc, sigma)\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    import scipy \n\n    image = np.asarray(image)\n    num_px = image.shape[0]\n    [xx, yy] = np.meshgrid(np.arange(0,num_px), np.arange(0,num_px))\n\n\n    def twoDGauss(x,y,ux,uy,sigma):\n        '''\n        Creates theoretical normalized 2D gaussian spot, centered around (ux,uy) \n        with standard deviation sigma, on grid specified by x and y\n        '''\n        p = 1/(2*np.pi*sigma**2) * np.exp(- ( (x-ux)**2+(y-uy)**2 ) / (2*sigma**2))\n        return p\n\n    def expected(x,y,params):   \n        '''\n        Creates simulated realistic Gaussian spot on x-y grid, with following\n        parameters = [x0,y0,sigma,bg,N], speficically:\n            - x0 = x-position of gaussian (px coord., first pixel is (0,0))\n            - y0 = y-positoin of gaussian (px coord.)\n            - sigma = stdev of gaussian (px coord)\n            - bg = number of photons in background\n            - N = number of photons in spot\n        '''\n        E = params[4] * twoDGauss(x,y,params[0],params[1],params[2]) + params[3]\n        return E\n\n    def SSE(params):\n        '''\n        Calculates sum-of-squared errors difference between 'image' and expected Gaussian defined by 'params'\n        This is essentially the cost-function that is minimized in the fit\n        '''\n        Expec = expected(xx,yy,params)\n        sse = np.sum((image -  Expec)**2)\n        return sse\n\n\n    #guess fit parameters:\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    sigma_guess = 2                 #assume sigma is 2 pixels\n    bg_guess = (np.sum(image) - np.sum(image[1:-1,1:-1]))/(4*num_px-4)           \n                                    #average of border pixels\n    N_guess = np.sum(image) - bg_guess * num_px**2\n                                    #sum of intensities, minus background\n    params_guess = [x_guess,x_guess,sigma_guess, bg_guess, N_guess]\n\n    #perform the fit\n    param = scipy.optimize.fmin(func=SSE,x0=params_guess, maxiter=10000,maxfun=10000,ftol=1e-5,disp=0)\n\n    xc_fit      = param[0]  #fitted x-position\n    yc_fit      = param[1]  #fitted y-position\n    sigma_fit   = param[2]  #fitted sigma\n\n    return (xc_fit, yc_fit, sigma_fit)", "entry_point": "fit_gaussian_to_spot", "test": "def check(candidate):\n    import numpy as np\n    np.random.seed(11)  #fit random seed, so every initialization of noise is equal\n\n    def twoDGauss(x,y,ux,uy,sigma):\n        '''\n        Creates theoretical normalized 2D gaussian spot, centered around (ux,uy) \n        with standard deviation sigma, on grid specified by x and y\n        '''\n        p = 1/(2*np.pi*sigma**2) * np.exp(- ( (x-ux)**2+(y-uy)**2 ) / (2*sigma**2))\n        return p\n\n    def expected(x,y,params):   \n        '''\n        Creates simulated realistic Gaussian spot on x-y grid, with following:\n        parameters = [x0,y0,sigma,bg,N], with:\n            - x0 = x-position of gaussian (px coord., first pixel is (0,0))\n            - y0 = y-positoin of gaussian (px coord.)\n            - sigma = stdev of gaussian (px coord)\n            - bg = number of photons in background\n            - N = number of photons in spot\n        '''\n        E = params[4] * twoDGauss(x,y,params[0],params[1],params[2]) + params[3]\n        return E\n    \n    #Create sample image\n    num_px = 10\n    x_gt = 3.1      #x-position Gaussian\n    y_gt = 4.9      #y-position Gaussian\n    sigma_gt = 1.9  #sigma Gaussian\n    N_gt = 1000     #number of signal photons\n    bg_gt = 10      #number of background photons per pixel\n    noise_gt = 10   #sigma of added noise\n    param_gt = [x_gt,y_gt,sigma_gt,bg_gt,N_gt] \n    [xx, yy] = np.meshgrid(np.arange(0,num_px), np.arange(0,num_px))\n    image = expected(xx,yy,param_gt) + np.random.randn(num_px,num_px)*noise_gt\n\n    #perform the fit\n    xc_fit, yc_fit, sigma_fit = candidate(image)\n    \n    #assess fitted parameters\n    assert np.allclose(xc_fit,      x_gt,       0.1)\n    assert np.allclose(yc_fit,      y_gt,       0.1)\n    assert np.allclose(sigma_fit,   sigma_gt,   0.1)\n"}
{"task_id": "../test_cases/flow_field_deformation.ipynb", "prompt": "def flow_field_deformation(flow_field, target):\n    \"\"\"\n    Given a vector field `flow_field` (H, W, 2) in which every pixel represents the relative \n    displacement vector to its position, then apply the deformation to the target (N, W) \n    image and return the deformed image.\n    \"\"\"", "canonical_solution": "\n    import SimpleITK as sitk\n\n    target = sitk.GetImageFromArray(target)\n\n    displacement = sitk.DisplacementFieldTransform(2)\n    field_size = list(flow_field.shape[:2])\n    field_origin = [0, 0]\n    field_spacing = [1.0, 1.0]\n    field_direction = [1, 0, 0, 1]  # direction cosine matrix (row major order)\n\n    # Concatenate all the information into a single list\n    displacement.SetFixedParameters(\n        field_size + field_origin + field_spacing + field_direction\n    )\n    # Set the interpolator to nearest neighbor\n    displacement.SetInterpolator(sitk.sitkNearestNeighbor)\n\n    originalDisplacements = flow_field.reshape((-1, 2)).flatten()\n    displacement.SetParameters(originalDisplacements)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetTransform(displacement)\n    resampler.SetReferenceImage(target)\n    resampled = resampler.Execute(target)\n\n    return sitk.GetArrayFromImage(resampled)", "entry_point": "flow_field_deformation", "test": "def check(candidate):\n    import numpy as np\n\n    flow_field = np.zeros((5, 5, 2))\n    flow_field[3, 2] = [-1, -1]\n\n    image = np.arange(25).reshape((5, 5))\n    result = candidate(flow_field, image)\n    \n    assert result[3, 2] == result[2, 1]"}
{"task_id": "../test_cases/generate_image_histogram.ipynb", "prompt": "def generate_image_histogram(image,num_bins:int=5):\n    \"\"\"\n    Takes a 2D input image, generates a histogram of the image using the value in num_bins and returns only the histogram values\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    return np.histogram(image,bins=num_bins)[0]", "entry_point": "generate_image_histogram", "test": "def check(candidate):\n    import numpy as np\n    \n    image = np.asarray([\n        [1,2,4,2,1],\n        [2,2,3,2,2],\n        [1,3,5,3,1],\n        [2,2,3,2,2],\n        [1,2,4,2,1],\n    ])\n    reference = np.asarray([6, 12,  4,  2,  1])\n    \n    result = np.asarray(candidate(image))\n\n    assert np.array_equal(result,reference)\n"}
{"task_id": "../test_cases/identify_centroids.ipynb", "prompt": "def identify_centroids(label_image):\n    \"\"\"\n    Given a label image, return a dict of {label: [list of weighted floating-point centroid coords], ...}  for each labelled\n    region (assume contiguity). Labels run between 1 and some integer n.\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    from skimage.measure import centroid\n    n = np.max(label_image)\n    out = {}\n    for i in range(1, n + 1):\n        binary_image = (label_image == i)\n        out[i] = centroid(binary_image)\n    return out", "entry_point": "identify_centroids", "test": "def check(candidate):\n    import numpy as np\n    \n    label_image = np.asarray([\n        [0,0,0,0,0],\n        [1,2,2,0,0],\n        [1,2,2,0,0],\n        [1,4,4,3,0],\n        [0,0,4,4,4],\n    ])\n\n    expected = {1: [2.0, 0.0], 2: [1.5, 1.5], 3: [3.0, 3.0], 4: [3.6, 2.4]}\n\n    result = candidate(label_image).items()\n\n    for label, centroid in result:\n        assert np.allclose(np.array(centroid), np.array(expected[label]))\n    \n    assert len(result) == len(expected)"}
{"task_id": "../test_cases/interpolate_stack.ipynb", "prompt": null, "canonical_solution": null, "entry_point": "interpolate_stack", "test": "def check(candidate):\n    import numpy as np\n    \n    start_slice = np.array([[0., 1., 2., 0.],\n        [0., 3., 4., 0.],\n        [0., 1., 2., 0.],\n        [0., 3., 4., 0.]])\n    \n    end_slice = np.array([[0., 6., 7., 0.],\n        [0., 8., 9., 0.],\n        [0., 3., 4., 0.],\n        [0., 5., 5.5, 0.]])\n\n    # number of slices including start_slice and end_slice\n    num = 6\n\n    reference = np.array([[[0., 1., 2., 0.],\n        [0., 3., 4., 0.],\n        [0., 1., 2., 0.],\n        [0., 3., 4., 0.]],\n                          \n        [[0., 2., 3., 0.],\n        [0., 4., 5., 0.],\n        [0., 1.4, 2.4, 0.],\n        [0., 3.4, 4.3, 0.]],\n\n       [[0., 3., 4., 0.],\n        [0., 5., 6., 0.],\n        [0., 1.8, 2.8, 0.],\n        [0., 3.8, 4.6, 0.]],\n\n       [[0., 4., 5., 0.],\n        [0., 6., 7., 0.],\n        [0., 2.2, 3.2, 0.],\n        [0., 4.2, 4.9, 0.]],\n\n       [[0., 5., 6., 0.],\n        [0., 7., 8., 0.],\n        [0., 2.6, 3.6, 0.],\n        [0., 4.6, 5.2, 0.]],\n\n       [[0., 6., 7., 0.],\n        [0., 8., 9., 0.],\n        [0., 3., 4., 0.],\n        [0., 5., 5.5, 0.]]])\n    \n    assert np.array_equal(candidate(start_slice, end_slice, num), reference)\n\n    start_slice = np.array([[0, 1, 2]])\n    end_slice = np.array([[4, 5, 6]])\n\n    reference = np.array([[[0, 1, 2]],\n                          [[2, 3, 4]],\n                          [[4, 5, 6]]])\n    assert np.array_equal(candidate(start_slice, end_slice, 3), reference)\n"}
{"task_id": "../test_cases/label_binary_image_and_count_labels.ipynb", "prompt": "def label_binary_image_and_count_labels(binary_image):\n    \"\"\"\n    Consumes as input a binary image, applies connected component labeling to it, \n    counts the labeled objects and returns their count as single number.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    import numpy as np\n    label_image = skimage.measure.label(binary_image)\n\n    return len(np.unique(label_image)) - 1", "entry_point": "label_binary_image_and_count_labels", "test": "def check(candidate):\n    import numpy as np\n    \n    assert candidate(np.asarray([\n        [0,0,0,0,0],\n        [0,1,0,0,0],\n        [0,0,0,0,0],\n        [1,0,0,0,0],\n        [0,0,0,1,0],\n    ])) == 3\n\n    assert candidate(np.asarray([\n        [0,0,0,0,0],\n        [0,1,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n    ])) == 1\n\n    assert candidate(np.asarray([\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n    ])) == 0"}
{"task_id": "../test_cases/label_sequentially.ipynb", "prompt": "def label_sequentially(label_image):\n    \"\"\"\n    Takes a label_image with n labels and relabels the objects, \n    to make sure all integer labels between 0 and n are used. \n    No gaps are there.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    return skimage.segmentation.relabel_sequential(label_image)[0]", "entry_point": "label_sequentially", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(np.asarray([\n        [0,1,0,0,0],\n        [0,0,0,0,0],\n        [0,4,0,0,0],\n        [0,0,5,0,0],\n        [0,0,0,6,0],\n    ])) \n\n    # -1 becaue background counts\n    assert len(np.unique(result)) - 1 == 4\n    assert result.max() == 4\n    assert result.shape[0] == 5\n    assert result.shape[1] == 5"}
{"task_id": "../test_cases/linear_intensity_profile.ipynb", "prompt": null, "canonical_solution": null, "entry_point": "linear_intensity_profile", "test": "def check(candidate):\n    # import \n    import numpy as np\n\n    # image\n    image = np.array([[0, 1, 3, 8, 6],\n                      [9, 3, 4, 9, 1],\n                      [1, 4, 5, 2, 2],\n                      [0, 1, 1, 5, 6],\n                      [2, 1, 4, 1, 1]])\n\n    # horizontal line \n    start_horizontal = 1, 1\n    end_horizontal = 1, 4\n    reference_horizontal = np.array([3, 4, 9, 1])\n\n    # vertical line\n    start_vertical = 0, 4\n    end_vertical = 4, 4\n    reference_vertical = np.array([6, 1, 2, 6, 1])\n\n    # diagonal line\n    start_diagonal = 0, 0\n    end_diagonal = 4, 4\n    reference_diagonal = np.array([0., 4., 4., 5., 3., 4., 1.])\n    # comment: the profile_line function interpolates pixel values at those coordinates using linear interpolation\n    # therefore it uses in this case (0,0), (0.8, 0.8), (1.6, 1.6), (2.4, 2.4), (3.2, 3.2), (4, 4)\n\n    # assert\n    assert np.array_equal(candidate(image, start_horizontal, end_horizontal), reference_horizontal)\n    assert np.array_equal(candidate(image, start_vertical, end_vertical), reference_vertical)\n    assert np.array_equal(candidate(image, start_diagonal, end_diagonal), reference_diagonal)"}
{"task_id": "../test_cases/list_image_files_in_folder.ipynb", "prompt": "def list_image_files_in_folder(folder_location):\n    \"\"\"\n    Lists all image files in a folder.\n    \"\"\"", "canonical_solution": "\n    import os\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    return [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]", "entry_point": "list_image_files_in_folder", "test": "def check(candidate):\n    list_files = candidate(\"../example_data/S-BIAD634/images_and_stuff/\")\n    \n    assert \"Ganglioneuroblastoma_8.tif\" in list_files\n    assert \"Ganglioneuroblastoma_9.tif\" in list_files\n    assert \"Ganglioneuroblastoma_10.tif\" in list_files\n    assert len(list_files) == 3"}
{"task_id": "../test_cases/load_tif_and_output_rgb.ipynb", "prompt": "def load_tif_and_output_rgb(path_to_tif):\n    \"\"\"\n    Given a fully defined `path_to_tif` string, return a numpy array containing the image in RGB format.\n    \"\"\"", "canonical_solution": "\n    from cv2 import imread, cvtColor, COLOR_BGR2RGB\n    image = imread(path_to_tif)\n    return cvtColor(image, COLOR_BGR2RGB)", "entry_point": "load_tif_and_output_rgb", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(\"../example_data/simple_patch.tif\")\n    expected = np.array([\n        [[  0, 204, 102], [  0, 204, 127], [  0, 204, 153]],\n        [[  0,   0, 102], [  0,   0, 127], [  0,   0, 153]],\n        [[  0,  51, 102], [  0,  51, 127], [  0,  51, 153]]],\n        dtype=np.uint8)\n\n    assert np.all(result[4:7, 4:7, :] == expected)"}
{"task_id": "../test_cases/local_maxima_from_distance_transform.ipynb", "prompt": "def local_maxima_from_distance_transform(binary_image, nms_window):\n    \"\"\"\n    Takes a binary_image and computes the distance transform of the image. \n    Then, it finds the local maxima of the distance transform image and returns their coordinates.\n    The local maxima are filtered by a non-maximum suppression window of size nms_window.\n    The function returns the y,x coordinates as list.\n    \"\"\"", "canonical_solution": "\n    import scipy.ndimage as ndi\n    import skimage.feature as skf\n    \n    distance_transform = ndi.distance_transform_edt(binary_image)\n    \n    image_max = ndi.maximum_filter(distance_transform, size=nms_window, mode='constant')\n    \n    # suppress non-maxima values by setting them to -1\n    mask = distance_transform == image_max\n    image_max[~mask] = -1\n    \n    local_maxima = skf.peak_local_max(image_max)\n\n    return local_maxima.tolist()", "entry_point": "local_maxima_from_distance_transform", "test": "def check(candidate):\n    import numpy as np\n\n    # Test 1: no non-maximum suppression\n    result = candidate(np.asarray([\n        [0, 0, 0, 0, 0],\n        [0, 1, 1, 1, 0],\n        [0, 1, 1, 1, 0],\n        [0, 1, 1, 1, 0],\n        [0, 0, 1, 0, 0],\n        [0, 1, 1, 1, 1],\n        [0, 0, 1, 0, 0],\n    ]), 0)\n\n    result = set([tuple(x) for x in result])\n\n    reference = {(2, 2), (5, 2)}\n    \n    # compare the results\n    for r in reference:\n        assert r in result\n    \n    \n    # Test 1: with non-maximum suppression window\n    result = candidate(np.asarray([\n        [0, 0, 0, 0, 0],\n        [0, 1, 1, 1, 0],\n        [0, 1, 1, 1, 0],\n        [0, 1, 1, 1, 0],\n        [0, 0, 1, 0, 0],\n        [0, 1, 1, 1, 1],\n        [0, 0, 1, 0, 0],\n    ]), 7)\n    \n    result = set([tuple(x) for x in result])\n    \n    reference = {(2, 2)}\n\n    assert reference == result"}
{"task_id": "../test_cases/map_pixel_count_of_labels.ipynb", "prompt": "def map_pixel_count_of_labels(label_image):\n    \"\"\"\n    Takes a label_image, determines the pixel-count per label and creates an image where the label values are replaced by the corresponding pixel count.\n    \"\"\"", "canonical_solution": "\n    import pyclesperanto_prototype as cle\n    return cle.pixel_count_map(label_image)", "entry_point": "map_pixel_count_of_labels", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(np.asarray([\n        [0,0,0,0,0],\n        [1,2,2,0,0],\n        [1,2,2,0,0],\n        [1,0,0,3,0],\n        [0,0,0,4,0],\n    ]))\n\n    reference = np.asarray([\n        [0,0,0,0,0],\n        [3,4,4,0,0],\n        [3,4,4,0,0],\n        [3,0,0,1,0],\n        [0,0,0,1,0],\n    ])\n\n    assert np.array_equal(reference, result)"}
{"task_id": "../test_cases/mask_image.ipynb", "prompt": "def mask_image(image, mask):\n    \"\"\"\n    Takes a 2D input image and a 2D binary mask image, then applies the mask to the input image and returns the result.\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    image = np.asarray(image)\n    mask = np.asarray(mask)\n    return image * mask", "entry_point": "mask_image", "test": "def check(candidate):\n    import numpy as np\n    \n    image = [\n        [2,2,2,2,2],\n        [2,2,3,2,2],\n        [2,3,3,3,2],\n        [2,2,3,2,2],\n        [2,2,2,2,2],\n    ]\n    mask = [\n        [0,0,0,0,0],\n        [0,0,1,0,0],\n        [0,1,1,1,0],\n        [0,0,1,0,0],\n        [0,0,0,0,0],\n    ]\n    reference = [\n        [0,0,0,0,0],\n        [0,0,3,0,0],\n        [0,3,3,3,0],\n        [0,0,3,0,0],\n        [0,0,0,0,0],\n    ]\n    masked_image = candidate(image,mask)\n    assert np.array_equal(masked_image, reference)"}
{"task_id": "../test_cases/maximum_intensity_projection.ipynb", "prompt": "def maximum_intensity_projection(image):\n    \"\"\"\n    Performs a maximum intensity projection along the first axis of an image.\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    return np.asarray(image).max(axis=0)", "entry_point": "maximum_intensity_projection", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [0,0,0,0,0,0],\n        [0,1,0,0,2,0],\n        [0,0,0,0,0,0],\n        [0,0,0,0,0,0],\n        [0,4,0,0,3,0],\n        [0,0,0,0,0,0],\n    ])\n\n    reference = np.asarray(\n        [0,4,0,0,3,0]\n    )\n    \n    assert np.array_equal(candidate(image), reference)\n"}
{"task_id": "../test_cases/mean_squared_error.ipynb", "prompt": "def mean_squared_error(image1, image2):\n    \"\"\"\n    Computes the mean-squared-error of two images compared pixel-by-pixel\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    image1 = np.asarray(image1)\n    image2 = np.asarray(image2)\n    return ((image1 - image2)**2).mean()\n    # adapted from : https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy", "entry_point": "mean_squared_error", "test": "def check(candidate):\n    image1 = [\n        [0,0,0,0,0],\n        [0,1,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,2,0],\n        [0,0,0,0,0],\n    ]\n    image2 = [\n        [0,0,0,0,0],\n        [0,1,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,2,0],\n        [0,0,0,0,0],\n    ]\n\n    mse = candidate(image1,image2)\n    print(mse)\n    assert mse == 0\n\n    image3 = [\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n    ]\n\n    mse = candidate(image1,image3)\n    print(mse)\n    assert mse == 5 / 25\n    \n"}
{"task_id": "../test_cases/mean_std_column.ipynb", "prompt": "def mean_std_column(dataframe, column:str):\n    \"\"\"\n    Computes the mean average and standard deviation of a specified column \n    in a given dataframe and returns these two values.\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    data = dataframe[column]\n    return np.mean(data), np.std(data)", "entry_point": "mean_std_column", "test": "def check(candidate):\n    import pandas as pd\n    df = pd.DataFrame(\n        {\n         \"a\":[1.6,2.3,2.6,3.7,3.4,3.9,4.3,4.3,4.0,5.1,5.2,5.3,5.5], \n         \"b\":[0.1,0.2,0.3,0.3,0.4,0.4,0.4,0.5,0.5,0.5,0.6,0.6,0.6],\n         \"c\":[1.6,2.3,2.6,3.7,3.4,3.9,4.3,4.3,4.0,5.1,5.2,5.3,5.4],\n         \"d\":[1.7,2.4,2.4,3.6,3.5,3.9,4.4,4.2,4.1,5.0,5.1,5.4,5.6]\n        }\n    )\n    \n    result_mean, result_std = candidate(df, \"a\")\n    assert abs(result_mean - 3.938) < 0.001\n    assert ((abs(result_std - 1.170) < 0.001) or (abs(result_std- 1.218) < 0.001))\n\n    result_mean, result_std = candidate(df, \"b\")\n    assert abs(result_mean - 0.415) < 0.001\n    assert ((abs(result_std - 0.151) < 0.001) or (abs(result_std- 0.157) < 0.001))\n\n    result_mean, result_std = candidate(df, \"c\")\n    assert abs(result_mean - 3.931) < 0.001\n    assert ((abs(result_std - 1.160) < 0.001) or (abs(result_std- 1.207) < 0.001))\n\n    result_mean, result_std = candidate(df, \"d\")\n    assert abs(result_mean - 3.946) < 0.001\n    assert ((abs(result_std - 1.168) < 0.001) or (abs(result_std- 1.216) < 0.001))\n"}
{"task_id": "../test_cases/measure_aspect_ratio_of_regions.ipynb", "prompt": "def measure_aspect_ratio_of_regions(label_image):\n    \"\"\"\n    Takes a label image and returns a pandas dataframe\n    with measurements for aspect_ratio of the objects\n    \"\"\"", "canonical_solution": "\n    import skimage\n    import pandas as pd\n    stats = pd.DataFrame(skimage.measure.regionprops_table(label_image, properties=('minor_axis_length', 'major_axis_length')))\n    stats['aspect_ratio'] = stats['major_axis_length'] / stats['minor_axis_length']\n    return stats", "entry_point": "measure_aspect_ratio_of_regions", "test": "def check(candidate):\n    import numpy as np\n\n    label_image = np.asarray([\n        [0,1,1,0,0,3,3],\n        [0,1,1,0,0,3,3],\n        [0,2,2,2,2,3,3],\n        [0,2,2,2,2,3,3],\n        [0,4,4,4,0,3,3],\n        [0,4,4,4,0,3,3],\n        [0,4,4,4,0,0,0],\n    ])\n    \n    result = candidate(label_image) \n    print(result['aspect_ratio'])\n    assert np.allclose(result['aspect_ratio'], [1,2,3,1], atol=0.5)\n"}
{"task_id": "../test_cases/measure_intensity_of_labels.ipynb", "prompt": "def measure_intensity_of_labels(label_image, intensity_image):\n    \"\"\"\n    Takes a label image and an intensity image, and returns a list of mean intensities \n    of all pixels in the intensity image, belonging to a given label.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image, intensity_image)\n    return [s.mean_intensity for s in stats]", "entry_point": "measure_intensity_of_labels", "test": "def check(candidate):\n    import numpy as np\n\n    label_image = np.asarray([\n        [0,1,0,0,0],\n        [0,0,0,0,0],\n        [0,2,2,2,2],\n        [0,3,3,0,0],\n        [0,0,0,4,0],\n    ])\n\n    intensity_image = np.asarray([\n        [0,2,0,0,0],\n        [0,0,0,0,0],\n        [0,3,3,4,4],\n        [0,3,3,0,0],\n        [0,0,0,5,0],\n    ])\n    \n    result = candidate(label_image, intensity_image) \n    assert np.array_equal([2,3.5,3,5], result)"}
{"task_id": "../test_cases/measure_intensity_over_time.ipynb", "prompt": "def measure_intensity_over_time(image_list):\n    \"\"\"\n    Takes a timelapse (list of images), measures the average intensity over time and returns the resulting measurements as list.\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    return np.asarray(image_list).mean(axis=(1,2))", "entry_point": "measure_intensity_over_time", "test": "def check(candidate):\n    import numpy as np\n\n    images = [\n        np.asarray([[0,1],[1,1]]),\n        np.asarray([[0,2],[2,2]]),\n        np.asarray([[0,3],[3,3]]),\n        np.asarray([[0,3],[2,2]]),\n        np.asarray([[0,2],[2,1]]),\n        np.asarray([[0,1],[1,0]]),\n    ]\n    reference = [0.75, 1.5, 2.25, 7/4, 5/4, 0.5]\n    \n    result = candidate(images) \n\n    assert np.allclose(reference, result, atol=0.001)\n"}
{"task_id": "../test_cases/measure_mean_image_intensity.ipynb", "prompt": "def measure_mean_image_intensity(image):\n    \"\"\"\n    Takes an image and returns its mean intensity\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    return np.asarray(image).mean()", "entry_point": "measure_mean_image_intensity", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(np.asarray([\n        [1,2,3,4,5],\n        [1,2,3,4,5],\n        [1,2,3,4,5],\n        [1,2,3,4,5],\n        [1,2,3,4,5],\n    ])) \n    assert result == 3"}
{"task_id": "../test_cases/measure_pixel_count_of_labels.ipynb", "prompt": "def measure_pixel_count_of_labels(label_image):\n    \"\"\"\n    Takes a label image and returns a list of counts of number of pixels per label.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image)\n    return [s.area for s in stats]", "entry_point": "measure_pixel_count_of_labels", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(np.asarray([\n        [0,1,0,0,0],\n        [0,0,0,0,0],\n        [0,2,2,2,0],\n        [0,3,3,0,0],\n        [0,0,0,4,0],\n    ])) \n    assert np.array_equal([1,3,2,1], result)"}
{"task_id": "../test_cases/measure_properties_of_regions.ipynb", "prompt": "def measure_properties_of_regions(label_image, intensity_image):\n    \"\"\"\n    Takes a label image and an intensity image, and returns pandas dataframe\n    with measurements for area, perimeter and mean_intensity.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\n    return pd.DataFrame(stats)", "entry_point": "measure_properties_of_regions", "test": "def check(candidate):\n    import numpy as np\n\n    label_image = np.asarray([\n        [0,1,0,0,0],\n        [0,0,0,0,0],\n        [0,2,2,2,2],\n        [0,3,3,0,0],\n        [0,0,0,4,0],\n    ])\n\n    intensity_image = np.asarray([\n        [0,2,0,0,0],\n        [0,0,0,0,0],\n        [0,3,3,4,4],\n        [0,3,3,0,0],\n        [0,0,0,5,0],\n    ])\n    \n    result = candidate(label_image, intensity_image) \n    \n    assert \"mean_intensity\" in result.columns\n    assert \"area\" in result.columns\n    assert \"perimeter\" in result.columns\n    assert len(result.columns) == 3\n    assert len(result) == 4"}
{"task_id": "../test_cases/open_image_read_voxel_size.ipynb", "prompt": "def open_image_read_voxel_size(image_filename):\n    \"\"\"\n    Reads an image file and return its voxel size in Z-Y-X order.\n    \"\"\"", "canonical_solution": "\n    from aicsimageio import AICSImage\n    aics_image = AICSImage(image_filename)\n\n    return aics_image.physical_pixel_sizes.Z, \\\n            aics_image.physical_pixel_sizes.Y, \\\n            aics_image.physical_pixel_sizes.X", "entry_point": "open_image_read_voxel_size", "test": "def check(candidate):\n    voxel_size = candidate(\"../example_data/noise.ome.tif\")\n\n    assert voxel_size[0] == 0.5\n    assert voxel_size[1] == 0.2\n    assert voxel_size[2] == 0.2\n\n    voxel_size = candidate(\"../example_data/noise.tif\")\n\n    assert voxel_size[0] == 0.5\n    assert voxel_size[1] == 0.2\n    assert voxel_size[2] == 0.2"}
{"task_id": "../test_cases/open_image_return_dimensions.ipynb", "prompt": "def open_image_return_dimensions(image_file_location):\n    \"\"\"\n    Opens an image from a path and returns its height and width\n    \"\"\"", "canonical_solution": "\n    from skimage.io import imread\n    image = imread(image_file_location)\n    return image.shape", "entry_point": "open_image_return_dimensions", "test": "def check(candidate):\n    shape = candidate(\"../example_data/blobs.tif\")\n    \n    assert shape[0] == 254\n    assert shape[1] == 256\n"}
{"task_id": "../test_cases/open_nifti_image.ipynb", "prompt": "def open_nifti_image(image_file_location):\n    \"\"\"\n    This function loads a nifti image from the file at image_location and returns the image data as a numpy array. \n    \"\"\"", "canonical_solution": "\n    \n    import nibabel as nib\n    import numpy as nb\n\n    img = nib.load(image_file_location)\n    data = img.get_fdata()\n    return(data)", "entry_point": "open_nifti_image", "test": "def check(candidate):\n    import numpy as np\n\n    reference = np.ones((5, 5, 5), dtype=np.int16)\n\n    image_location = '../example_data/test3d.nii.gz'\n    data = candidate(image_location)\n    assert np.array_equal(data, reference)"}
{"task_id": "../test_cases/open_zarr.ipynb", "prompt": "def open_zarr(zarr_file_location):\n    \"\"\"\n    Opens a zarr file and returns the array\n    \"\"\"", "canonical_solution": "\n    import zarr\n    array = zarr.load(zarr_file_location)\n    return array", "entry_point": "open_zarr", "test": "def check(candidate):\n    array = candidate(\"../example_data/one-dimensional.zarr\")\n    import numpy as np\n    assert np.all(array == np.arange(10))"}
{"task_id": "../test_cases/pair_wise_correlation_matrix.ipynb", "prompt": "def pair_wise_correlation_matrix(dataframe):\n    \"\"\"\n    Takes a pandas dataframe and computes for all columns their Pearson's correlation coefficient\n    for all columns in the dataframe. For n columns, this is a n x n matrix of coefficients.\n    The matrix is returned as dataframe.\n    \"\"\"", "canonical_solution": "\n    return dataframe.corr()", "entry_point": "pair_wise_correlation_matrix", "test": "def check(candidate):\n    import pandas as pd\n    df = pd.DataFrame(\n        {\n         \"a\":[1.6,2.3,2.6,3.7,3.4,3.9,4.3,4.3,4.0,5.1,5.2,5.3,5.5], \n         \"b\":[0.1,0.2,0.3,0.3,0.4,0.4,0.4,0.5,0.5,0.5,0.6,0.6,0.6],\n         \"c\":[1.6,2.3,2.6,3.7,3.4,3.9,4.3,4.3,4.0,5.1,5.2,5.3,5.4],\n         \"d\":[1.7,2.4,2.4,3.6,3.5,3.9,4.4,4.2,4.1,5.0,5.1,5.4,5.6],\n         \"e\":[1.7,2.4,2.4,3.6,3.5,3.9,4.4,4.2,4.1,5.0,5.1,5.4,5.6]\n        }\n    )\n\n    result = candidate(df)\n\n    print(result)\n\n    assert 'a' in result.columns\n    assert 'b' in result.columns\n    assert 'c' in result.columns\n    assert 'd' in result.columns\n    assert 'e' in result.columns\n\n    assert abs(result['a'].iloc[0] - 1) < 0.0001\n    assert abs(result['b'].iloc[1] - 1) < 0.0001\n    assert abs(result['c'].iloc[2] - 1) < 0.0001\n    assert abs(result['d'].iloc[3] - 1) < 0.0001\n    assert abs(result['e'].iloc[4] - 1) < 0.0001\n\n    # columns d and e are identical\n    assert abs(result['e'].iloc[3] - 1) < 0.0001\n    \n    assert result.size == 25"}
{"task_id": "../test_cases/radial_intensity_profile.ipynb", "prompt": "def radial_intensity_profile(image, xc, yc):\n    \"\"\"\n    Computes the radial intensity profile of an image around a given coordinate\n    Inputs:\n    - image: 2d numpy array\n    - xy, yc: the center coordinates\n    Output:\n    - an array containing the average intensities\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    y, x = np.indices((image.shape))\n    r = np.sqrt((x - xc)**2 + (y - yc)**2)\n    r = r.astype(int)\n    summed_values = np.bincount(r.ravel(), image.ravel())\n    number_of_pixels_at_r = np.bincount(r.ravel())\n    radial_profile = summed_values / number_of_pixels_at_r\n    return radial_profile ", "entry_point": "radial_intensity_profile", "test": "def check(candidate):\n    import numpy as np\n    xc = 5\n    yc = 5 \n    x, y = np.indices(np.zeros(shape=(11,11)).shape)\n    distance_image = np.sqrt((x - xc)**2 + (y - yc)**2)\n    result = candidate(distance_image, xc, yc) \n    reference = [0, 1, 2, 3, 4, 5]\n    \n    assert np.allclose(reference, result[0:len(reference)], atol=0.5)"}
{"task_id": "../test_cases/region_growing_segmentation.ipynb", "prompt": "def region_growing_segmentation(image, point):\n    \"\"\"\n    Segments an image using the region-growing/flood filling \n    starting from a single point.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    return skimage.segmentation.flood(image, point)", "entry_point": "region_growing_segmentation", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(np.asarray([\n        [0,0,1,0,0,0,0,1,0,0],\n        [0,0,1,0,0,0,0,1,0,0],\n        [1,1,1,1,1,1,1,1,1,1],\n        [0,0,1,0,0,0,0,1,0,0],\n        [0,0,1,0,0,0,0,1,0,0],\n        [0,0,1,0,0,0,0,1,0,0],\n        [0,0,1,0,0,0,0,1,0,0],\n        [1,1,1,1,1,1,1,1,1,1],\n        [0,0,1,0,0,0,0,1,0,0],\n        [0,0,1,0,0,0,0,1,0,0],\n    ]), (5,5)) \n\n    assert result.sum() * 1 == 16\n    assert result.min() == 0\n    assert result.max() == 1"}
{"task_id": "../test_cases/register_timelapse.ipynb", "prompt": "def register_timelapse(video):\n    \"\"\"\n    Register a 3D timelapse (T,Z,Y,X) with subpixel precision using translations in Z, Y, X.\n    The last frame is the reference frame, and it remains fixed.\n    The entire registered time-lapse is returned.\n    \"\"\"", "canonical_solution": "\n    from skimage import registration\n    import scipy.ndimage as ndi\n\n    new_video = video.copy()\n    ref_frame = new_video[-1]\n    for t in range(len(video) - 1, 0, -1):\n        mov_frame = video[t - 1]\n        shift, _, _ = registration.phase_cross_correlation(\n            ref_frame,\n            mov_frame,\n            upsample_factor=4,\n            normalization=None,\n        )\n        # replaces old ref_frame with shifted mov_frame\n        ref_frame = ndi.shift(mov_frame, shift, order=1)\n        new_video[t - 1] = ref_frame\n\n    return new_video", "entry_point": "register_timelapse", "test": "def check(candidate):\n    import numpy as np\n    from skimage.feature import peak_local_max\n    shape = (15, 15, 15)\n    \n    def _gaussian(mean):\n        variance = 0.5\n\n        support = np.stack(np.meshgrid(*[\n            np.linspace(-s // 2, s // 2, s) + m\n            for s, m in zip(shape, mean)\n        ], indexing=\"ij\"))\n\n        density = np.exp(-np.linalg.norm(support, axis=0) / (2 * variance))\n        return density\n\n    video = np.stack([\n        _gaussian((-3, 3, 0)),\n        _gaussian((2, 0, -2)),\n        _gaussian((0, 2, 0))\n    ])\n        \n    ref_coord = peak_local_max(video[-1])\n    res_coords = np.concatenate([\n        peak_local_max(frame)\n        for frame in candidate(video)\n        # for frame in video  # sanity check making sure original video doesn't pass test\n    ])\n\n    max_dist = np.abs(res_coords - ref_coord)\n    np.testing.assert_array_less(max_dist, 0.5)"}
{"task_id": "../test_cases/remove_labels_on_edges.ipynb", "prompt": "def remove_labels_on_edges(label_image):\n    \"\"\"\n    Takes a label_image and removes all objects which touch the image border.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    return skimage.segmentation.clear_border(label_image)", "entry_point": "remove_labels_on_edges", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(np.asarray([\n        [0,0,0,0,0],\n        [1,2,2,0,0],\n        [1,2,2,0,0],\n        [1,0,0,3,0],\n        [0,0,0,4,0],\n    ]))\n\n    # -1 becaue background counts\n    assert len(np.unique(result)) - 1 == 2\n    assert result.shape[0] == 5\n    assert result.shape[1] == 5"}
{"task_id": "../test_cases/remove_noise_edge_preserving.ipynb", "prompt": "def remove_noise_edge_preserving(image, radius:int=1):\n    \"\"\"\n    Applies an edge-preserving noise-removal filter to an image.\n    \"\"\"", "canonical_solution": "\n    from scipy.ndimage import median_filter\n    filtered_image = median_filter(image, size=radius * 2 + 1)\n    return filtered_image", "entry_point": "remove_noise_edge_preserving", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [1,1,2,2,2],\n        [1,2,2,2,2],\n        [1,1,2,2,2],\n        [1,1,1,2,2],\n        [1,1,2,2,2],\n    ])\n\n    reference = np.asarray([\n        [1,1,2,2,2],\n        [1,1,2,2,2],\n        [1,1,2,2,2],\n        [1,1,2,2,2],\n        [1,1,2,2,2],\n    ])\n    \n    assert np.array_equal(candidate(image), reference)\n\n    assert candidate(image, radius=5).mean() == 2\n\n"}
{"task_id": "../test_cases/remove_small_labels.ipynb", "prompt": "def remove_small_labels(label_image, size_threshold:int=0):\n    \"\"\"\n    Takes a label_image and removes all objects that are smaller than a given size_threshold.\n    \"\"\"", "canonical_solution": "\n    import pyclesperanto_prototype as cle\n    return cle.exclude_small_labels(label_image, maximum_size=size_threshold)", "entry_point": "remove_small_labels", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(np.asarray([\n        [0,0,0,0,0],\n        [1,2,2,0,0],\n        [1,2,2,0,0],\n        [1,0,0,3,0],\n        [0,0,0,4,0],\n    ]), size_threshold=2)\n\n    reference = np.asarray([\n        [0,0,0,0,0],\n        [1,2,2,0,0],\n        [1,2,2,0,0],\n        [1,0,0,0,0],\n        [0,0,0,0,0],\n    ])\n\n    assert np.array_equal(reference, result)"}
{"task_id": "../test_cases/return_hello_world.ipynb", "prompt": "def return_hello_world():\n    \"\"\"\n    Returns the string \"hello world\".\n    \"\"\"", "canonical_solution": "\n    return \"hello world\"", "entry_point": "return_hello_world", "test": "def check(candidate):\n    assert candidate() == \"hello world\""}
{"task_id": "../test_cases/rgb_to_grey_image_transform.ipynb", "prompt": "def rgb_to_grey_image_transform(rgb_image, r:float, g:float, b:float):\n    \"\"\"\n    Convert an RGB image to a single-channel gray scale image with \n    configurable weights r, g and b.\n    The weights are normalized to be 1 in sum.\n    \"\"\"", "canonical_solution": "\n    rgb_sum = r + g + b\n    r = r / rgb_sum\n    g = g / rgb_sum\n    b = b / rgb_sum\n    \n    import numpy as np\n    channel_r = np.asarray(rgb_image)[...,0]\n    channel_g = np.asarray(rgb_image)[...,1]\n    channel_b = np.asarray(rgb_image)[...,2]\n    grey_image = channel_r * r + \\\n                 channel_g * g + \\\n                 channel_b * b\n    \n    return grey_image", "entry_point": "rgb_to_grey_image_transform", "test": "def check(candidate):\n    import numpy as np\n    assert np.allclose(candidate([[[0,1,2], [3,3,3]]], 0.5, 0.25, 0.25),\n                                     [[0.75,  3]], atol=0.0001)\n\n    assert np.allclose(candidate([[[0,1,2], [3,3,3]]], 1, 2, 2),\n                                     [[1.2,  3]], atol=0.0001)\n                          "}
{"task_id": "../test_cases/rotate_image_by_90_degrees.ipynb", "prompt": "def rotate_image_by_90_degrees(image):\n    \"\"\"\n    Rotates an image by 90 degrees clockwise around the center of the image.\n    \"\"\"", "canonical_solution": "\n    import pyclesperanto_prototype as cle\n    return cle.rotate(image, angle_around_z_in_degrees=90)", "entry_point": "rotate_image_by_90_degrees", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [0,0,0,0,0,0],\n        [0,1,0,0,2,0],\n        [0,0,0,0,0,0],\n        [0,0,0,0,0,0],\n        [0,4,0,0,3,0],\n        [0,0,0,0,0,0],\n    ])\n\n    reference = np.asarray([\n        [0,0,0,0,0,0],\n        [0,4,0,0,1,0],\n        [0,0,0,0,0,0],\n        [0,0,0,0,0,0],\n        [0,3,0,0,2,0],\n        [0,0,0,0,0,0],\n    ])\n    \n    assert np.array_equal(candidate(image), reference)\n"}
{"task_id": "../test_cases/save_image_with_voxel_size.ipynb", "prompt": "def save_image_with_voxel_size(image, vx, vy, vz):\n    \"\"\"\n    Takes a 3D input image and voxel sizes in x, y and z, \n    sets the voxel size of the image using the given parameters \n    vx,vy and vz, saves the image to a temporary directory as an \n    ome tiff file and returns the saved image path.\n    \"\"\"", "canonical_solution": "\n    from aicsimageio import AICSImage \n    from aicsimageio.types import PhysicalPixelSizes\n    from tempfile import tempdir\n    import os \n\n    image = AICSImage(image)\n    AICSImage.physical_pixel_sizes = PhysicalPixelSizes(Z=vz,Y=vy,X=vx)\n    img_path = os.path.join(tempdir, 'voxel_save_test.ome.tiff')\n    image.save(img_path)\n    return img_path", "entry_point": "save_image_with_voxel_size", "test": "def check(candidate):\n    import numpy as np\n    from aicsimageio import AICSImage \n    from aicsimageio.types import PhysicalPixelSizes\n    from tempfile import tempdir\n    import os \n    \n    img_3d = np.random.randint(0,65535,(25,25,25),dtype=np.uint16)\n    vz,vy,vx = 2,0.5,0.5\n    reference_voxel_size = PhysicalPixelSizes(Z=vz,Y=vy,X=vx)\n    ref_img_path = candidate(img_3d, vx, vy, vz)  \n    img_3d_pixel_size = AICSImage(ref_img_path).physical_pixel_sizes\n    assert img_3d_pixel_size == reference_voxel_size\n    "}
{"task_id": "../test_cases/scale_image_affine_transform.ipynb", "prompt": "def scale_image_affine_transform(image,sx,sy):\n    \"\"\"\n    Compose affine transform to scale an image by scaling factors sx and sy. \n    Returns the scaled image and the affine transform matrix used for scaling. \n    The affine transform must be a 3x3 matrix in xy order.\n    \"\"\"", "canonical_solution": "\n    from pyclesperanto_prototype import AffineTransform3D\n    import pyclesperanto_prototype as cle \n    import numpy as np\n    \n    output_img_shape =  (image.shape[0]*sy, image.shape[1]*sx)\n\n    transform = AffineTransform3D()\n    transform.center(image.shape)\n    transform.scale(scale_x = sx, scale_y = sy)\n    transform.center(output_img_shape,undo=True)\n    scaled_image = np.array(cle.affine_transform(image,transform=transform,auto_size=True))\n    return scaled_image, transform._matrix", "entry_point": "scale_image_affine_transform", "test": "def check(candidate):\n    import numpy as np \n    \n    image = np.asarray([\n            [0, 0, 0, 0, 0],\n            [0, 0, 1, 1, 0],\n            [0, 0, 1, 1, 0],\n            [0, 0, 0, 0, 0],\n            [0, 0, 0, 0, 0],\n        ])\n    sx = 1\n    sy = 2\n    scaled_image,transform = candidate(image, sx, sy)\n    reference = np.asarray([[0, 0, 0, 0, 0,],\n                                [0, 0, 0, 0, 0],\n                                [0, 0, 1, 1, 0],\n                                [0, 0, 1, 1, 0],\n                                [0, 0, 1, 1, 0],\n                                [0, 0, 1, 1, 0],\n                                [0, 0, 0, 0, 0],\n                                [0, 0, 0, 0, 0],\n                                [0, 0, 0, 0, 0],\n                                [0, 0, 0, 0, 0]])\n\n    scale_transform = np.asarray([[1., 0., 0., 0.],\n                                [0., 2., 0., 0.],\n                                [0., 0., 1., 0.],\n                                [0., 0., 0., 1.]])\n    #print(scaled_image,\"\\n\",transform)\n    assert np.array_equal(scaled_image,reference)\n    assert np.array_equal(transform,scale_transform)\n    "}
{"task_id": "../test_cases/select_coexpressing_cells.ipynb", "prompt": "def select_coexpressing_cells(image, label_image, threshold):\n    \"\"\"\n    Selects and returns the subset of cell segments from a label_image\n    that co expresses the total intensity of all channels above a\n    certain threshold given an input image (HxWxC)\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    import pandas as pd\n    from skimage.measure import regionprops_table\n\n    df = pd.DataFrame(\n        regionprops_table(label_image, image, properties=(\"label\", \"area\", \"intensity_mean\"))\n    )\n    mean_cols = [c for c in df.columns if c.startswith(\"intensity_mean\")]\n    sum_cols = [f\"intensity_sum-{i}\" for i in range(len(mean_cols))]\n    \n    df[sum_cols] = df[mean_cols] * df[\"area\"].to_numpy()\n    \n    selected_ids = df.loc[(df[sum_cols] > threshold).all(axis=1), \"label\"].to_numpy()\n    \n    below_threshold_mask = np.isin(label_image, selected_ids, invert=False)\n    filtered_labels = label_image * below_threshold_mask\n\n    return filtered_labels", "entry_point": "select_coexpressing_cells", "test": "def check(candidate):\n    import numpy as np\n\n    labels = np.asarray([[0, 1, 1],\n                         [2, 2, 3],\n                         [0, 0, 3]])\n\n    image = np.asarray([[[0, 0, 0], [5, 2, 6], [5, 2, 4]],\n                        [[10,5, 3], [0, 5, 7], [1, 4, 4]],\n                        [[0, 0, 0], [0, 0, 0], [4, 4, 4]]])\n\n    expected_labels = np.asarray([[0, 0, 0],\n                                  [2, 2, 0],\n                                  [0, 0, 0]])\n\n    results = candidate(image, labels, 7)\n\n    np.testing.assert_equal(expected_labels, results)"}
{"task_id": "../test_cases/subsample_image.ipynb", "prompt": "def subsample_image(image, n:int=2):\n    \"\"\"\n    Subsamples an image by skipping every n'th pixel in X and Y.\n    \"\"\"", "canonical_solution": "\n    return image[::n,::n]", "entry_point": "subsample_image", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [1,2,3,4,5,6],\n        [7,8,9,0,1,2],\n        [3,4,5,6,7,8],\n        [9,0,1,2,3,4],\n        [5,6,7,8,9,0],\n        [1,2,3,4,5,6],\n    ])\n\n    reference = np.asarray([\n        [1,3,5],\n        [3,5,7],\n        [5,7,9],\n    ])\n    \n    assert np.array_equal(candidate(image, n=2), reference)\n\n    reference = np.asarray([\n        [1,4],\n        [9,2],\n    ])\n\n    assert np.array_equal(candidate(image, n=3), reference)"}
{"task_id": "../test_cases/subtract_background_tophat.ipynb", "prompt": "def subtract_background_tophat(image, radius:int=1):\n    \"\"\"\n    Applies a top-hat filter with a given radius to an image with dark background (low values) and bright foreground (high values).\n    \"\"\"", "canonical_solution": "\n    from skimage.morphology import white_tophat\n    from skimage.morphology import disk\n    filtered_image = white_tophat(image, footprint=disk(radius))\n    \n    return filtered_image", "entry_point": "subtract_background_tophat", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [1,1,1,1,1,1,1,1],\n        [1,2,1,1,1,1,1,1],\n        [1,1,1,1,1,1,1,1],\n        [1,1,1,1,1,1,1,1],\n        [1,1,1,1,1,1,1,1],\n        [1,1,4,1,1,1,1,1],\n        [1,1,1,1,1,1,2,1],\n        [1,1,1,1,1,1,1,1],\n    ])\n\n    reference = np.asarray([\n        [0,0,0,0,0,0,0,0],\n        [0,1,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,3,0,0,0,0,0],\n        [0,0,0,0,0,0,1,0],\n        [0,0,0,0,0,0,0,0],\n    ])\n    \n    assert np.array_equal(candidate(image), reference)\n    assert np.array_equal(candidate(reference), reference)\n\n    # note this test case is kept simple to allow also other top-hat implementations (e.g. with a square footpint) to pass\n"}
{"task_id": "../test_cases/sum_images.ipynb", "prompt": "def sum_images(image1, image2):\n    \"\"\"\n    Sums two images pixel-by-pixel and returns the result\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    return np.asarray(image1) + np.asarray(image2)", "entry_point": "sum_images", "test": "def check(candidate):\n    import numpy as np\n\n    image1 = np.random.random((5,6))\n    image2 = np.random.random((5,6))\n    sum_image = image1 + image2\n    \n    assert np.allclose(candidate(image1, image2), sum_image)\n\n    image1 =    [[1,2,3], [4,5,6]]\n    image2 =    [[5,6,7], [0,1,2]]\n    sum_image = [[6,8,10],[4,6,8]]\n    \n    assert np.allclose(candidate(image1, image2), sum_image)\n"}
{"task_id": "../test_cases/sum_intensity_projection.ipynb", "prompt": "def sum_intensity_projection(image):\n    \"\"\"\n    Performs a sum intensity projection along the first axis of an image.\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    return np.asarray(image).sum(axis=0)", "entry_point": "sum_intensity_projection", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [0,0,0,0,0,0],\n        [0,1,0,0,3,0],\n        [0,0,0,0,0,0],\n        [0,0,0,0,0,0],\n        [0,4,0,0,6,0],\n        [0,0,0,0,0,0],\n    ])\n\n    reference = np.asarray(\n        [0,5,0,0,9,0]\n    )\n    \n    assert np.array_equal(candidate(image), reference)\n"}
{"task_id": "../test_cases/tiled_image_processing.ipynb", "prompt": "def tiled_image_processing(image, radius, tile_size):\n    \"\"\"\n    Apply a maximum filter with a given radius to the image using a tile-by-tile strategy.\n    The tile_size denotes the size of the tiles in X and Y.\n    \"\"\"", "canonical_solution": "\n    import dask\n    import dask.array as da\n\n    tiles = da.from_array(image, chunks=(tile_size, tile_size))\n    \n    def procedure(image):\n        from scipy.ndimage import maximum_filter\n        return maximum_filter(image, size=radius*2+1)\n\n    # setup a lazy result (not computed yet)\n    tile_map = da.map_blocks(procedure, tiles)\n\n    # actually apply filter\n    result = tile_map.compute()\n\n    return result", "entry_point": "tiled_image_processing", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [0,0,0,0,0,0],\n        [1,0,0,1,0,0],\n        [0,0,0,0,0,0],\n        [0,0,2,0,0,0],\n        [0,0,0,1,0,0],\n        [0,0,0,0,0,0],\n    ])\n\n    # this reference image has tile-border artefacts,\n    # the maximum-filter does not consider pixels beyond\n    # the 3x3 border\n    reference = np.asarray([\n        [1,1,0,1,1,0],\n        [1,1,0,1,1,0],\n        [1,1,0,1,1,0],\n        [0,2,2,1,1,0],\n        [0,2,2,1,1,0],\n        [0,0,0,1,1,0],\n    ])\n\n    result = candidate(image, 1, 3)\n\n    assert np.array_equal(result, reference)"}
{"task_id": "../test_cases/translate_3d_image_along_vector.ipynb", "prompt": null, "canonical_solution": null, "entry_point": "translate_3d_image_along_vector", "test": "def check(candidate):\n    # import\n    import numpy as np\n\n    # translation along x, y and z\n    t_x = -1\n    t_y = 2\n    t_z = 1\n\n    # image\n    image = np.array([[[0., 1., 2., 0.],\n        [0., 3., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]],\n\n       [[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]]])\n\n    reference = np.array([[[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]],\n\n       [[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [1., 2., 0., 0.],\n        [3., 0., 0., 0.]]])\n\n    # assert \n    assert np.array_equal(candidate(image, t_x, t_y, t_z), reference)"}
{"task_id": "../test_cases/transpose_image_axes.ipynb", "prompt": "def transpose_image_axes(image):\n    \"\"\"\n    Transposes the first two axes of an image.\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    return np.asarray(image).T", "entry_point": "transpose_image_axes", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [0,0,0,0,0,0],\n        [0,1,0,0,2,0],\n        [0,0,0,0,0,0],\n        [0,0,0,0,0,0],\n        [0,4,0,0,3,0],\n        [0,0,0,0,0,0],\n    ])\n\n    reference = np.asarray([\n        [0,0,0,0,0,0],\n        [0,1,0,0,4,0],\n        [0,0,0,0,0,0],\n        [0,0,0,0,0,0],\n        [0,2,0,0,3,0],\n        [0,0,0,0,0,0],\n    ])\n    \n    assert np.array_equal(candidate(image), reference)\n"}
{"task_id": "../test_cases/t_test.ipynb", "prompt": "def t_test(dataframe, column1:str, column2:str):\n    \"\"\"\n    Takes two specified columns from a given dataframe and applies a paired T-test to it to determine the p-value.\n    \"\"\"", "canonical_solution": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    return scipy.stats.ttest_rel(data1, data2)[1]\n    ", "entry_point": "t_test", "test": "def check(candidate):\n    import pandas as pd\n    df = pd.DataFrame(\n        {\n         \"a\":[1.6,2.3,2.6,3.7,3.4,3.9,4.3,4.3,4.0,5.1,5.2,5.3,5.5], \n         \"b\":[0.1,0.2,0.3,0.3,0.4,0.4,0.4,0.5,0.5,0.5,0.6,0.6,0.6],\n         \"c\":[1.6,2.3,2.6,3.7,3.4,3.9,4.3,4.3,4.0,5.1,5.2,5.3,5.4],\n         \"d\":[1.7,2.4,2.4,3.6,3.5,3.9,4.4,4.2,4.1,5.0,5.1,5.4,5.6]\n        }\n    )\n    \n    result = candidate(df, \"a\",\"b\")\n    assert 6e-8 > result > 5e-8\n\n    result = candidate(df, \"a\",\"c\")\n    assert 0.4 > result > 0.3\n"}
{"task_id": "../test_cases/workflow_batch_process_folder_count_labels.ipynb", "prompt": "def workflow_batch_process_folder_count_labels(folder_location):\n    \"\"\"\n    This functions goes through all .tif image files in a specified folder, \n    loads the images and count labels each image. \n    It returns a dictionary with filenames and corresponding counts.\n    \"\"\"", "canonical_solution": "\n    import os\n    from skimage.io import imread\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]\n    result = {}\n\n    for filename in file_list:\n        image = imread(folder_location + filename)\n\n        labels = np.unique(image).tolist()\n        labels.pop(0)\n\n        count = len(labels)\n\n        result[filename] = count\n\n    return result", "entry_point": "workflow_batch_process_folder_count_labels", "test": "def check(candidate):\n    counts = candidate(\"../example_data/S-BIAD634/groundtruth/\")\n\n    assert counts[\"Ganglioneuroblastoma_0.tif\"] == 300\n    assert counts[\"Ganglioneuroblastoma_1.tif\"] == 398\n    assert counts[\"Ganglioneuroblastoma_2.tif\"] == 368\n    assert counts[\"Ganglioneuroblastoma_3.tif\"] == 378\n    assert counts[\"Ganglioneuroblastoma_4.tif\"] == 363\n    assert len(counts.keys()) == 5"}
{"task_id": "../test_cases/workflow_batch_process_folder_measure_intensity.ipynb", "prompt": "def workflow_batch_process_folder_measure_intensity(image_folder_location, labels_folder_location):\n    \"\"\"\n    This functions goes through all .tif image files in a specified image folder \n    and corresponding label images in another labels folder. \n    It loads the images and corresponding labels, and measures min, mean and max intensity of all labels.\n    The function returns a dataframe with five columns: min_intensity, mean_intensity, max_intensity, label and filename.\n    \"\"\"", "canonical_solution": "\n    import os\n    import pandas as pd\n    from skimage.io import imread\n    from skimage.measure import regionprops\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(image_folder_location) if str(fn[-4:]) in supported_fileendings]\n\n    result = []\n\n    for filename in file_list:\n        image = imread(image_folder_location + filename)[...,0]\n        labels = imread(labels_folder_location + filename)\n\n        stats = regionprops(labels, intensity_image=image)\n\n        for s in stats:\n            result.append({\n                \"filename\":filename,\n                \"label\":s.label,\n                \"min_intensity\":s.min_intensity,\n                \"mean_intensity\":s.mean_intensity,\n                \"max_intensity\":s.max_intensity,\n            })\n\n    return pd.DataFrame(result)", "entry_point": "workflow_batch_process_folder_measure_intensity", "test": "def check(candidate):\n    label_stats = candidate(\"../example_data/S-BIAD634/images/\", \"../example_data/S-BIAD634/groundtruth/\")\n\n    assert label_stats['label'].max() == 398\n    assert label_stats['min_intensity'].min() == 7\n    assert label_stats['max_intensity'].max() == 255\n\n    assert label_stats.size == 9035\n    \n    assert abs(label_stats['mean_intensity'].max() - 186) < 1\n\n    assert len(label_stats.columns) == 5\n    assert len(label_stats['mean_intensity']) == 1807\n\n    assert \"filename\" in label_stats.columns\n    assert \"label\" in label_stats.columns\n    assert \"min_intensity\" in label_stats.columns\n    assert \"mean_intensity\" in label_stats.columns\n    assert \"max_intensity\" in label_stats.columns"}
{"task_id": "../test_cases/workflow_segmentation_counting.ipynb", "prompt": "def workflow_segmentation_counting(image):\n    \"\"\"\n    This function segments objects in an image with intensity above average \n    and returns their count.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    import numpy as np\n    average_intensity = np.asarray(image).mean()\n    binary = image > average_intensity\n    labels = skimage.measure.label(binary)\n    return labels.max()", "entry_point": "workflow_segmentation_counting", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(np.asarray([\n        [0,0,0,0,0],\n        [0,1,0,0,0],\n        [0,0,0,2,0],\n        [0,1,0,0,0],\n        [0,0,0,0,0],\n    ])) \n    assert result == 3\n\n    result = candidate(np.asarray([\n        [0,0,0,0,0],\n        [0,100,0,90,0],\n        [0,0,0,0,0],\n        [0,110,0,80,0],\n        [0,0,0,0,0],\n    ])) \n    assert result == 4"}
{"task_id": "../test_cases/workflow_segmentation_measurement_summary.ipynb", "prompt": "def workflow_segmentation_measurement_summary(image):\n    \"\"\"\n    This function implements a workflow consisting of these steps:\n    * threshold intensity input image using Otsu's method\n    * label connected components\n    * measure area of the labeled objects\n    * determine mean area of all objects\n    \"\"\"", "canonical_solution": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n    label_image = skimage.measure.label(binary_image)\n    stats = skimage.measure.regionprops(label_image)\n    areas = [s.area for s in stats]\n    return np.mean(areas)", "entry_point": "workflow_segmentation_measurement_summary", "test": "def check(candidate):\n    import numpy as np\n    \n    assert candidate(np.asarray([\n        [0,0,0,0,0],\n        [1,1,1,0,0],\n        [1,1,1,0,0],\n        [1,1,0,0,0],\n        [0,0,0,0,0],\n    ])) == 8\n\n    assert candidate(np.asarray([\n        [1,1,0,1,1],\n        [1,1,0,0,0],\n        [0,0,0,1,1],\n        [1,1,0,1,1],\n        [0,0,0,0,0],\n    ])) == 3\n\n    assert candidate(np.asarray([\n        [0,0,0,0,0],\n        [0,1,0,1,0],\n        [0,0,0,0,0],\n        [0,0,1,0,0],\n        [0,0,0,0,0],\n    ])) == 1"}
{"task_id": "../test_cases/workflow_segment_measure_umap.ipynb", "prompt": "def workflow_segment_measure_umap(image):\n    \"\"\"\n    This function takes a single channel intensity image, \n    segments objects with intensity above half the maximum intensity, \n    labels connected components, \n    measures area, perimeter, mean_intensity, minor and major axis of the labeled objects, \n    and produces a UMAP from the given measurements. \n    The two UMAP vectors are saved as `umap0` and `umap1` togther with the measurements in a dataframe. \n    The function returns this dataframe.\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    import pandas as pd\n    import umap\n    from skimage.measure import label, regionprops_table\n\n    image = np.asarray(image)\n\n    # segment\n    binary = image > 0.5 * image.max()\n    labels = label(binary)\n\n    # measure\n    dataframe = pd.DataFrame(regionprops_table(labels, intensity_image=image, \n                                              properties=['area', 'perimeter', 'mean_intensity', \n                                                          'minor_axis_length', 'major_axis_length']))\n\n    # append UMAP\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    return dataframe", "entry_point": "workflow_segment_measure_umap", "test": "def check(candidate):\n    import numpy as np\n\n    images = np.asarray([\n            [1,0,0,0,1,0,1,1,0,0],    \n            [1,0,1,0,0,0,0,0,0,0],    \n            [1,0,0,0,1,0,1,0,1,0],    \n            [1,0,1,0,0,0,0,0,1,0],    \n            [1,0,0,0,0,0,0,0,0,0],    \n            [1,0,0,1,0,1,1,0,1,0],    \n            [1,0,0,1,0,1,0,0,1,0],    \n            [1,0,0,1,0,0,0,1,1,0],    \n            [1,0,0,0,0,1,0,0,0,0],    \n            [1,0,1,0,0,0,0,0,0,0],    \n        ])\n    \n    result = candidate(images) \n\n    expected_columns = ['area', 'perimeter', 'mean_intensity', \n                        'minor_axis_length', 'major_axis_length',\n                        'umap0', 'umap1']\n\n    # I'm not sure how to check if the umap columns contain a proper umap, \n    # but we can check if all expected columns exist.\n    for ec in expected_columns:\n        assert ec in result.columns"}
{"task_id": "../test_cases/workflow_watershed_segmentation_correction_measurement.ipynb", "prompt": "def workflow_watershed_segmentation_correction_measurement(image):\n    \"\"\"\n    This function implements a workflow consisting of these steps:\n    * blurs the image a bit\n    * detect local minima in the blurred image\n    * apply watershed segmentation flooding the blurred image from the \n      detected minima to retrieve a label image\n    * remove all objects which touch the image border\n    * measure the area of all remaining objects together\n    \"\"\"", "canonical_solution": "\n    import skimage\n    blurred = skimage.filters.gaussian(image, sigma=1)\n    minima = skimage.morphology.local_minima(blurred)\n    spots = skimage.measure.label(minima)\n    labels = skimage.segmentation.watershed(blurred, spots)\n    labels_without_border = skimage.segmentation.clear_border(labels)   \n    binary = labels_without_border > 0\n    return binary.sum()", "entry_point": "workflow_watershed_segmentation_correction_measurement", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(np.asarray([\n        [0,0,1,0,0,0,0,1,0,0],\n        [0,0,1,0,0,0,0,1,0,0],\n        [1,1,1,1,1,1,1,1,1,1],\n        [0,0,1,0,0,0,0,1,0,0],\n        [0,0,1,0,0,0,0,1,0,0],\n        [0,0,1,0,0,0,0,1,0,0],\n        [0,0,1,0,0,0,0,1,0,0],\n        [1,1,1,1,1,1,1,1,1,1],\n        [0,0,1,0,0,0,0,1,0,0],\n        [0,0,1,0,0,0,0,1,0,0],\n    ])) \n\n    # if only the 4x4 pixels are segmented:\n    assert result >= 16\n    # if it also considers borders as part of the center object:\n    assert result <= 36 \n"}
