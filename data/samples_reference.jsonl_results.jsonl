{"task_id": "../test_cases/apply_otsu_threshold_and_count_positive_pixels.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n\n    result = np.sum(binary_image)\n\n    return result", "full_response": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n\n    result = np.sum(binary_image)\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/binary_closing.ipynb", "completion": "\n    import numpy as np\n    import skimage\n    size = radius * 2 + 1\n    return skimage.morphology.binary_closing(binary_image, footprint=np.ones((size, size)))", "full_response": "\n    import numpy as np\n    import skimage\n    size = radius * 2 + 1\n    return skimage.morphology.binary_closing(binary_image, footprint=np.ones((size, size)))", "result": "passed", "passed": true}
{"task_id": "../test_cases/binary_skeleton.ipynb", "completion": "\n    from skimage.morphology import skeletonize\n    return skeletonize(binary_image)", "full_response": "\n    from skimage.morphology import skeletonize\n    return skeletonize(binary_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/bland_altman.ipynb", "completion": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    dataframe['mean'] = (data1 + data2) / 2\n    dataframe['diff'] = data2 - data1\n    return dataframe", "full_response": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    dataframe['mean'] = (data1 + data2) / 2\n    dataframe['diff'] = data2 - data1\n    return dataframe", "result": "passed", "passed": true}
{"task_id": "../test_cases/combine_columns_of_tables.ipynb", "completion": "\n    import pandas as pd\n    return pd.merge(dataframe1, dataframe2, how='outer', on='label')", "full_response": "\n    import pandas as pd\n    return pd.merge(dataframe1, dataframe2, how='outer', on='label')", "result": "passed", "passed": true}
{"task_id": "../test_cases/convert_points_polygon.ipynb", "completion": "\n    from shapely import Polygon\n    polygon = Polygon(coordinates)\n    return polygon\n", "full_response": "\n    from shapely import Polygon\n    polygon = Polygon(coordinates)\n    return polygon\n", "result": "passed", "passed": true}
{"task_id": "../test_cases/convex_hull_measure_area.ipynb", "completion": "\n    import vedo\n    convex_hull = vedo.shapes.ConvexHull(point_cloud)\n    return convex_hull.area()", "full_response": "\n    import vedo\n    convex_hull = vedo.shapes.ConvexHull(point_cloud)\n    return convex_hull.area()", "result": "passed", "passed": true}
{"task_id": "../test_cases/convolve_images.ipynb", "completion": "\n    import scipy\n    return scipy.ndimage.convolve(image, kernel_image)\n    ", "full_response": "\n    import scipy\n    return scipy.ndimage.convolve(image, kernel_image)\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_number_of_touching_neighbors.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n\n    touch_matrix = cle.generate_touch_matrix(label_image)\n    cle.set_row(touch_matrix, 0, 0)\n    cle.set_column(touch_matrix, 0, 0)\n\n    return np.asarray(cle.sum_y_projection(touch_matrix))[0,1:].tolist()", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n\n    touch_matrix = cle.generate_touch_matrix(label_image)\n    cle.set_row(touch_matrix, 0, 0)\n    cle.set_column(touch_matrix, 0, 0)\n\n    return np.asarray(cle.sum_y_projection(touch_matrix))[0,1:].tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_objects_over_time.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import label\n    labels = [label(binary_image) for binary_image in binary_image_list]\n    return [len(np.unique(label)) - 1 for label in labels]", "full_response": "\n    import numpy as np\n    from skimage.measure import label\n    labels = [label(binary_image) for binary_image in binary_image_list]\n    return [len(np.unique(label)) - 1 for label in labels]", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_overlapping_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image_1, label_image_2, properties=('mean_intensity',))\n    return (pd.DataFrame(stats)['mean_intensity'] > 0).sum()", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image_1, label_image_2, properties=('mean_intensity',))\n    return (pd.DataFrame(stats)['mean_intensity'] > 0).sum()", "result": "passed", "passed": true}
{"task_id": "../test_cases/create_umap.ipynb", "completion": "\n    import umap\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    # no return value", "full_response": "\n    import umap\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    # no return value", "result": "passed", "passed": true}
{"task_id": "../test_cases/crop_quarter_image.ipynb", "completion": "\n    width = image.shape[1]\n    height = image.shape[0]\n\n    return image[:int(width/2),:int(height/2)]", "full_response": "\n    width = image.shape[1]\n    height = image.shape[0]\n\n    return image[:int(width/2),:int(height/2)]", "result": "passed", "passed": true}
{"task_id": "../test_cases/dataframe_column_rename.ipynb", "completion": "\n    for old_value, new_value in replacements.items():\n        df[column] = df[column].replace(old_value, new_value, regex=True)\n    return df", "full_response": "\n    for old_value, new_value in replacements.items():\n        df[column] = df[column].replace(old_value, new_value, regex=True)\n    return df", "result": "passed", "passed": true}
{"task_id": "../test_cases/deconvolve_image.ipynb", "completion": "\n    from scipy import fftpack\n\n    # adapted from: https://stackoverflow.com/questions/17473917/is-there-a-equivalent-of-scipy-signal-deconvolve-for-2d-arrays\n    star_fft = fftpack.fftshift(fftpack.fftn(image))\n    psf_fft = fftpack.fftshift(fftpack.fftn(kernel_image))\n    return fftpack.fftshift(fftpack.ifftn(fftpack.ifftshift(star_fft/psf_fft)))\n    ", "full_response": "\n    from scipy import fftpack\n\n    # adapted from: https://stackoverflow.com/questions/17473917/is-there-a-equivalent-of-scipy-signal-deconvolve-for-2d-arrays\n    star_fft = fftpack.fftshift(fftpack.fftn(image))\n    psf_fft = fftpack.fftshift(fftpack.fftn(kernel_image))\n    return fftpack.fftshift(fftpack.ifftn(fftpack.ifftshift(star_fft/psf_fft)))\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/detect_edges.ipynb", "completion": "\n    from scipy.ndimage import sobel\n    filtered_image = sobel(image)\n    return filtered_image", "full_response": "\n    from scipy.ndimage import sobel\n    filtered_image = sobel(image)\n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/detect_ellipse.ipynb", "completion": "\n    from skimage.transform import hough_ellipse\n    result = hough_ellipse(image,  accuracy=5, threshold=10)\n    result.sort(order='accumulator')\n    \n    # Estimated parameters for the ellipse\n    best = list(result[-1])\n    yc, xc, a, b = (int(round(x)) for x in best[1:5])\n    \n    return yc, xc", "full_response": "\n    from skimage.transform import hough_ellipse\n    result = hough_ellipse(image,  accuracy=5, threshold=10)\n    result.sort(order='accumulator')\n    \n    # Estimated parameters for the ellipse\n    best = list(result[-1])\n    yc, xc, a, b = (int(round(x)) for x in best[1:5])\n    \n    return yc, xc", "result": "passed", "passed": true}
{"task_id": "../test_cases/distance_between_maxima.ipynb", "completion": "\n    import numpy as np\n\n    im1 = np.asarray(image1)\n    im2 = np.asarray(image2)\n\n    x1,y1 = np.unravel_index(im1.argmax(), im1.shape)\n    x2,y2 = np.unravel_index(im2.argmax(), im2.shape)\n\n    distance = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n\n    return distance", "full_response": "\n    import numpy as np\n\n    im1 = np.asarray(image1)\n    im2 = np.asarray(image2)\n\n    x1,y1 = np.unravel_index(im1.argmax(), im1.shape)\n    x2,y2 = np.unravel_index(im2.argmax(), im2.shape)\n\n    distance = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n\n    return distance", "result": "passed", "passed": true}
{"task_id": "../test_cases/expand_labels_without_overlap.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.expand_labels(label_image, distance=radius)", "full_response": "\n    import skimage\n    return skimage.segmentation.expand_labels(label_image, distance=radius)", "result": "passed", "passed": true}
{"task_id": "../test_cases/extract_surface_measure_area.ipynb", "completion": "\n    import vedo\n    volume = vedo.Volume(binary_volume_image)\n    iso_surface = volume.isosurface()\n    return iso_surface.area()", "full_response": "\n    import vedo\n    volume = vedo.Volume(binary_volume_image)\n    iso_surface = volume.isosurface()\n    return iso_surface.area()", "result": "passed", "passed": true}
{"task_id": "../test_cases/fft_spectrum.ipynb", "completion": "\n        import numpy as np\n    \n        # computing padding tuple:\n        pad_width = ((padding, padding),)*nd_image.ndim\n    \n        # Padding:\n        image_padded = np.pad(nd_image, pad_width=pad_width, mode='symmetric')\n        \n        # prepare the apodization window in 1D:\n        from scipy import signal\n        window_tuple = (signal.windows.hamming(length+2*padding) for length in nd_image.shape)\n        \n        # prepare the apodization window in nD:\n        import functools\n        window = functools.reduce(np.multiply.outer, window_tuple)\n        \n        # Apodize:\n        image_padded_apodized = window*image_padded\n    \n        # Compute the Fourier transform of the image:\n        image_fft = np.fft.fftn(image_padded_apodized)\n        \n        # Shift the zero-frequency component to the center of the spectrum:\n        image_fft_shifted = np.fft.fftshift(image_fft)\n        \n        # Compute the magnitude spectrum:\n        magnitude_spectrum = np.log1p(np.abs(image_fft_shifted))\n            \n        return(magnitude_spectrum)\n    \n    import numpy as np   \n\n    # Test image:\n    image = np.ones((5, 6, 7), dtype=np.int16)\n\n    # Padding:\n    padding_width = 10\n\n    # running the candidate function:\n    magnitude_spectrum_candidate = candidate(image, padding_width)\n    \n    # Reference implementation:\n    magnitude_spectrum_reference = fft_spectrum_reference(image, padding_width)\n    \n    assert np.allclose(magnitude_spectrum_candidate, magnitude_spectrum_reference)", "full_response": "\n        import numpy as np\n    \n        # computing padding tuple:\n        pad_width = ((padding, padding),)*nd_image.ndim\n    \n        # Padding:\n        image_padded = np.pad(nd_image, pad_width=pad_width, mode='symmetric')\n        \n        # prepare the apodization window in 1D:\n        from scipy import signal\n        window_tuple = (signal.windows.hamming(length+2*padding) for length in nd_image.shape)\n        \n        # prepare the apodization window in nD:\n        import functools\n        window = functools.reduce(np.multiply.outer, window_tuple)\n        \n        # Apodize:\n        image_padded_apodized = window*image_padded\n    \n        # Compute the Fourier transform of the image:\n        image_fft = np.fft.fftn(image_padded_apodized)\n        \n        # Shift the zero-frequency component to the center of the spectrum:\n        image_fft_shifted = np.fft.fftshift(image_fft)\n        \n        # Compute the magnitude spectrum:\n        magnitude_spectrum = np.log1p(np.abs(image_fft_shifted))\n            \n        return(magnitude_spectrum)\n    \n    import numpy as np   \n\n    # Test image:\n    image = np.ones((5, 6, 7), dtype=np.int16)\n\n    # Padding:\n    padding_width = 10\n\n    # running the candidate function:\n    magnitude_spectrum_candidate = candidate(image, padding_width)\n    \n    # Reference implementation:\n    magnitude_spectrum_reference = fft_spectrum_reference(image, padding_width)\n    \n    assert np.allclose(magnitude_spectrum_candidate, magnitude_spectrum_reference)", "result": "timed out", "passed": false}
{"task_id": "../test_cases/find_closest_neighbors.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import centroid\n    \n    # Identify all centroid locations\n    label_count = np.max(label_image)\n    centroids = {}\n    for i in range(1, label_count + 1):\n        binary_image = (label_image == i)\n        centroids[i] = centroid(binary_image)\n    \n    # Find the closest top n\n    distances = [(other, np.linalg.norm(centroids[target_label] - centroids[other])) for other in centroids.keys() if other != target_label]\n    sorted_distances = sorted(distances, key = lambda pair: pair[1])\n    topn = [label for label, _ in sorted_distances[:n]]\n\n    return topn", "full_response": "\n    import numpy as np\n    from skimage.measure import centroid\n    \n    # Identify all centroid locations\n    label_count = np.max(label_image)\n    centroids = {}\n    for i in range(1, label_count + 1):\n        binary_image = (label_image == i)\n        centroids[i] = centroid(binary_image)\n    \n    # Find the closest top n\n    distances = [(other, np.linalg.norm(centroids[target_label] - centroids[other])) for other in centroids.keys() if other != target_label]\n    sorted_distances = sorted(distances, key = lambda pair: pair[1])\n    topn = [label for label, _ in sorted_distances[:n]]\n\n    return topn", "result": "passed", "passed": true}
{"task_id": "../test_cases/fit_circle.ipynb", "completion": "\n    import circle_fit as cf\n    xc, yc, r, _ = cf.least_squares_circle(list_of_2d_points)\n    return xc,yc,r", "full_response": "\n    import circle_fit as cf\n    xc, yc, r, _ = cf.least_squares_circle(list_of_2d_points)\n    return xc,yc,r", "result": "passed", "passed": true}
{"task_id": "../test_cases/fit_gaussian_to_spot.ipynb", "completion": "\n    import numpy as np\n    import scipy \n\n    image = np.asarray(image)\n    num_px = image.shape[0]\n    [xx, yy] = np.meshgrid(np.arange(0,num_px), np.arange(0,num_px))\n\n\n    def twoDGauss(x,y,ux,uy,sigma):\n        '''\n        Creates theoretical normalized 2D gaussian spot, centered around (ux,uy) \n        with standard deviation sigma, on grid specified by x and y\n        '''\n        p = 1/(2*np.pi*sigma**2) * np.exp(- ( (x-ux)**2+(y-uy)**2 ) / (2*sigma**2))\n        return p\n\n    def expected(x,y,params):   \n        '''\n        Creates simulated realistic Gaussian spot on x-y grid, with following\n        parameters = [x0,y0,sigma,bg,N], speficically:\n            - x0 = x-position of gaussian (px coord., first pixel is (0,0))\n            - y0 = y-positoin of gaussian (px coord.)\n            - sigma = stdev of gaussian (px coord)\n            - bg = number of photons in background\n            - N = number of photons in spot\n        '''\n        E = params[4] * twoDGauss(x,y,params[0],params[1],params[2]) + params[3]\n        return E\n\n    def SSE(params):\n        '''\n        Calculates sum-of-squared errors difference between 'image' and expected Gaussian defined by 'params'\n        This is essentially the cost-function that is minimized in the fit\n        '''\n        Expec = expected(xx,yy,params)\n        sse = np.sum((image -  Expec)**2)\n        return sse\n\n\n    #guess fit parameters:\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    sigma_guess = 2                 #assume sigma is 2 pixels\n    bg_guess = (np.sum(image) - np.sum(image[1:-1,1:-1]))/(4*num_px-4)           \n                                    #average of border pixels\n    N_guess = np.sum(image) - bg_guess * num_px**2\n                                    #sum of intensities, minus background\n    params_guess = [x_guess,x_guess,sigma_guess, bg_guess, N_guess]\n\n    #perform the fit\n    param = scipy.optimize.fmin(func=SSE,x0=params_guess, maxiter=10000,maxfun=10000,ftol=1e-5,disp=0)\n\n    xc_fit      = param[0]  #fitted x-position\n    yc_fit      = param[1]  #fitted y-position\n    sigma_fit   = param[2]  #fitted sigma\n\n    return (xc_fit, yc_fit, sigma_fit)", "full_response": "\n    import numpy as np\n    import scipy \n\n    image = np.asarray(image)\n    num_px = image.shape[0]\n    [xx, yy] = np.meshgrid(np.arange(0,num_px), np.arange(0,num_px))\n\n\n    def twoDGauss(x,y,ux,uy,sigma):\n        '''\n        Creates theoretical normalized 2D gaussian spot, centered around (ux,uy) \n        with standard deviation sigma, on grid specified by x and y\n        '''\n        p = 1/(2*np.pi*sigma**2) * np.exp(- ( (x-ux)**2+(y-uy)**2 ) / (2*sigma**2))\n        return p\n\n    def expected(x,y,params):   \n        '''\n        Creates simulated realistic Gaussian spot on x-y grid, with following\n        parameters = [x0,y0,sigma,bg,N], speficically:\n            - x0 = x-position of gaussian (px coord., first pixel is (0,0))\n            - y0 = y-positoin of gaussian (px coord.)\n            - sigma = stdev of gaussian (px coord)\n            - bg = number of photons in background\n            - N = number of photons in spot\n        '''\n        E = params[4] * twoDGauss(x,y,params[0],params[1],params[2]) + params[3]\n        return E\n\n    def SSE(params):\n        '''\n        Calculates sum-of-squared errors difference between 'image' and expected Gaussian defined by 'params'\n        This is essentially the cost-function that is minimized in the fit\n        '''\n        Expec = expected(xx,yy,params)\n        sse = np.sum((image -  Expec)**2)\n        return sse\n\n\n    #guess fit parameters:\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    sigma_guess = 2                 #assume sigma is 2 pixels\n    bg_guess = (np.sum(image) - np.sum(image[1:-1,1:-1]))/(4*num_px-4)           \n                                    #average of border pixels\n    N_guess = np.sum(image) - bg_guess * num_px**2\n                                    #sum of intensities, minus background\n    params_guess = [x_guess,x_guess,sigma_guess, bg_guess, N_guess]\n\n    #perform the fit\n    param = scipy.optimize.fmin(func=SSE,x0=params_guess, maxiter=10000,maxfun=10000,ftol=1e-5,disp=0)\n\n    xc_fit      = param[0]  #fitted x-position\n    yc_fit      = param[1]  #fitted y-position\n    sigma_fit   = param[2]  #fitted sigma\n\n    return (xc_fit, yc_fit, sigma_fit)", "result": "passed", "passed": true}
{"task_id": "../test_cases/flow_field_deformation.ipynb", "completion": "\n    import SimpleITK as sitk\n\n    target = sitk.GetImageFromArray(target)\n\n    displacement = sitk.DisplacementFieldTransform(2)\n    field_size = list(flow_field.shape[:2])\n    field_origin = [0, 0]\n    field_spacing = [1.0, 1.0]\n    field_direction = [1, 0, 0, 1]  # direction cosine matrix (row major order)\n\n    # Concatenate all the information into a single list\n    displacement.SetFixedParameters(\n        field_size + field_origin + field_spacing + field_direction\n    )\n    # Set the interpolator to nearest neighbor\n    displacement.SetInterpolator(sitk.sitkNearestNeighbor)\n\n    originalDisplacements = flow_field.reshape((-1, 2)).flatten()\n    displacement.SetParameters(originalDisplacements)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetTransform(displacement)\n    resampler.SetReferenceImage(target)\n    resampled = resampler.Execute(target)\n\n    return sitk.GetArrayFromImage(resampled)", "full_response": "\n    import SimpleITK as sitk\n\n    target = sitk.GetImageFromArray(target)\n\n    displacement = sitk.DisplacementFieldTransform(2)\n    field_size = list(flow_field.shape[:2])\n    field_origin = [0, 0]\n    field_spacing = [1.0, 1.0]\n    field_direction = [1, 0, 0, 1]  # direction cosine matrix (row major order)\n\n    # Concatenate all the information into a single list\n    displacement.SetFixedParameters(\n        field_size + field_origin + field_spacing + field_direction\n    )\n    # Set the interpolator to nearest neighbor\n    displacement.SetInterpolator(sitk.sitkNearestNeighbor)\n\n    originalDisplacements = flow_field.reshape((-1, 2)).flatten()\n    displacement.SetParameters(originalDisplacements)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetTransform(displacement)\n    resampler.SetReferenceImage(target)\n    resampled = resampler.Execute(target)\n\n    return sitk.GetArrayFromImage(resampled)", "result": "passed", "passed": true}
{"task_id": "../test_cases/generate_image_histogram.ipynb", "completion": "\n    import numpy as np\n    return np.histogram(image,bins=num_bins)[0]", "full_response": "\n    import numpy as np\n    return np.histogram(image,bins=num_bins)[0]", "result": "passed", "passed": true}
{"task_id": "../test_cases/identify_centroids.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import centroid\n    n = np.max(label_image)\n    out = {}\n    for i in range(1, n + 1):\n        binary_image = (label_image == i)\n        out[i] = centroid(binary_image)\n    return out", "full_response": "\n    import numpy as np\n    from skimage.measure import centroid\n    n = np.max(label_image)\n    out = {}\n    for i in range(1, n + 1):\n        binary_image = (label_image == i)\n        out[i] = centroid(binary_image)\n    return out", "result": "passed", "passed": true}
{"task_id": "../test_cases/interpolate_stack.ipynb", "completion": "\n    import numpy as np\n\n    return np.linspace(start_slice, end_slice, num)", "full_response": "\n    import numpy as np\n\n    return np.linspace(start_slice, end_slice, num)", "result": "passed", "passed": true}
{"task_id": "../test_cases/label_binary_image_and_count_labels.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    label_image = skimage.measure.label(binary_image)\n\n    return len(np.unique(label_image)) - 1", "full_response": "\n    import skimage\n    import numpy as np\n    label_image = skimage.measure.label(binary_image)\n\n    return len(np.unique(label_image)) - 1", "result": "passed", "passed": true}
{"task_id": "../test_cases/label_sequentially.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.relabel_sequential(label_image)[0]", "full_response": "\n    import skimage\n    return skimage.segmentation.relabel_sequential(label_image)[0]", "result": "passed", "passed": true}
{"task_id": "../test_cases/linear_intensity_profile.ipynb", "completion": "\n    from skimage.measure import profile_line\n    return profile_line(image, starting_point, ending_point)", "full_response": "\n    from skimage.measure import profile_line\n    return profile_line(image, starting_point, ending_point)", "result": "passed", "passed": true}
{"task_id": "../test_cases/list_image_files_in_folder.ipynb", "completion": "\n    import os\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    return [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]", "full_response": "\n    import os\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    return [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]", "result": "passed", "passed": true}
{"task_id": "../test_cases/load_tif_and_output_rgb.ipynb", "completion": "\n    from cv2 import imread, cvtColor, COLOR_BGR2RGB\n    image = imread(path_to_tif)\n    return cvtColor(image, COLOR_BGR2RGB)", "full_response": "\n    from cv2 import imread, cvtColor, COLOR_BGR2RGB\n    image = imread(path_to_tif)\n    return cvtColor(image, COLOR_BGR2RGB)", "result": "failed: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n", "passed": false}
{"task_id": "../test_cases/local_maxima_from_distance_transform.ipynb", "completion": "\n    import scipy.ndimage as ndi\n    import skimage.feature as skf\n    \n    distance_transform = ndi.distance_transform_edt(binary_image)\n    \n    image_max = ndi.maximum_filter(distance_transform, size=nms_window, mode='constant')\n    \n    # suppress non-maxima values by setting them to -1\n    mask = distance_transform == image_max\n    image_max[~mask] = -1\n    \n    local_maxima = skf.peak_local_max(image_max)\n\n    return local_maxima.tolist()", "full_response": "\n    import scipy.ndimage as ndi\n    import skimage.feature as skf\n    \n    distance_transform = ndi.distance_transform_edt(binary_image)\n    \n    image_max = ndi.maximum_filter(distance_transform, size=nms_window, mode='constant')\n    \n    # suppress non-maxima values by setting them to -1\n    mask = distance_transform == image_max\n    image_max[~mask] = -1\n    \n    local_maxima = skf.peak_local_max(image_max)\n\n    return local_maxima.tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/map_pixel_count_of_labels.ipynb", "completion": "\n    import pyclesperanto_prototype as cle\n    return cle.pixel_count_map(label_image)", "full_response": "\n    import pyclesperanto_prototype as cle\n    return cle.pixel_count_map(label_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/mask_image.ipynb", "completion": "\n    import numpy as np\n    return image * mask", "full_response": "\n    import numpy as np\n    return image * mask", "result": "passed", "passed": true}
{"task_id": "../test_cases/maximum_intensity_projection.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).max(axis=0)", "full_response": "\n    import numpy as np\n    return np.asarray(image).max(axis=0)", "result": "passed", "passed": true}
{"task_id": "../test_cases/mean_squared_error.ipynb", "completion": "\n    return ((image1 - image2)**2).mean()\n    # adapted from : https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy", "full_response": "\n    return ((image1 - image2)**2).mean()\n    # adapted from : https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy", "result": "passed", "passed": true}
{"task_id": "../test_cases/mean_std_column.ipynb", "completion": "\n    import numpy as np\n    data = dataframe[column]\n    return np.mean(data), np.std(data)", "full_response": "\n    import numpy as np\n    data = dataframe[column]\n    return np.mean(data), np.std(data)", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_aspect_ratio_of_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = pd.DataFrame(skimage.measure.regionprops_table(label_image, properties=('minor_axis_length', 'major_axis_length')))\n    stats['aspect_ratio'] = stats['major_axis_length'] / stats['minor_axis_length']\n    return stats", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = pd.DataFrame(skimage.measure.regionprops_table(label_image, properties=('minor_axis_length', 'major_axis_length')))\n    stats['aspect_ratio'] = stats['major_axis_length'] / stats['minor_axis_length']\n    return stats", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_intensity_of_labels.ipynb", "completion": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image, intensity_image)\n    return [s.mean_intensity for s in stats]", "full_response": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image, intensity_image)\n    return [s.mean_intensity for s in stats]", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_intensity_over_time.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image_list).mean(axis=(1,2)).tolist()", "full_response": "\n    import numpy as np\n    return np.asarray(image_list).mean(axis=(1,2)).tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_mean_image_intensity.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).mean()", "full_response": "\n    import numpy as np\n    return np.asarray(image).mean()", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_pixel_count_of_labels.ipynb", "completion": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image)\n    return [s.area for s in stats]", "full_response": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image)\n    return [s.area for s in stats]", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_properties_of_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\n    return pd.DataFrame(stats)", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\n    return pd.DataFrame(stats)", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_image_read_voxel_size.ipynb", "completion": "\n    from aicsimageio import AICSImage\n    aics_image = AICSImage(image_filename)\n\n    return aics_image.physical_pixel_sizes.Z, \\\n            aics_image.physical_pixel_sizes.Y, \\\n            aics_image.physical_pixel_sizes.X", "full_response": "\n    from aicsimageio import AICSImage\n    aics_image = AICSImage(image_filename)\n\n    return aics_image.physical_pixel_sizes.Z, \\\n            aics_image.physical_pixel_sizes.Y, \\\n            aics_image.physical_pixel_sizes.X", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_image_return_dimensions.ipynb", "completion": "\n    from skimage.io import imread\n    image = imread(image_file_location)\n    return image.shape", "full_response": "\n    from skimage.io import imread\n    image = imread(image_file_location)\n    return image.shape", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_nifti_image.ipynb", "completion": "\n    \n    import nibabel as nib\n    import numpy as nb\n\n    img = nib.load(image_file_location)\n    data = img.get_fdata()\n    return(data)", "full_response": "\n    \n    import nibabel as nib\n    import numpy as nb\n\n    img = nib.load(image_file_location)\n    data = img.get_fdata()\n    return(data)", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_zarr.ipynb", "completion": "\n    import zarr\n    array = zarr.load(zarr_file_location)\n    return array", "full_response": "\n    import zarr\n    array = zarr.load(zarr_file_location)\n    return array", "result": "passed", "passed": true}
{"task_id": "../test_cases/pair_wise_correlation_matrix.ipynb", "completion": "\n    return dataframe.corr()", "full_response": "\n    return dataframe.corr()", "result": "passed", "passed": true}
{"task_id": "../test_cases/radial_intensity_profile.ipynb", "completion": "\n    import numpy as np\n    y, x = np.indices((image.shape))\n    r = np.sqrt((x - xc)**2 + (y - yc)**2)\n    r = r.astype(int)\n    summed_values = np.bincount(r.ravel(), image.ravel())\n    number_of_pixels_at_r = np.bincount(r.ravel())\n    radial_profile = summed_values / number_of_pixels_at_r\n    return radial_profile ", "full_response": "\n    import numpy as np\n    y, x = np.indices((image.shape))\n    r = np.sqrt((x - xc)**2 + (y - yc)**2)\n    r = r.astype(int)\n    summed_values = np.bincount(r.ravel(), image.ravel())\n    number_of_pixels_at_r = np.bincount(r.ravel())\n    radial_profile = summed_values / number_of_pixels_at_r\n    return radial_profile ", "result": "passed", "passed": true}
{"task_id": "../test_cases/read_imagej_tif_metadata.ipynb", "completion": "\n    from tifffile import TiffFile\n    \n    with (TiffFile(image_filename) as tif):\n        imagej_metadata = tif.imagej_metadata\n    return imagej_metadata", "full_response": "\n    from tifffile import TiffFile\n    \n    with (TiffFile(image_filename) as tif):\n        imagej_metadata = tif.imagej_metadata\n    return imagej_metadata", "result": "passed", "passed": true}
{"task_id": "../test_cases/read_ome_metadata_from_ome_xml.ipynb", "completion": "\n    from ome_types import from_xml\n    ome = from_xml(img_path)\n    return ome.images[0]", "full_response": "\n    from ome_types import from_xml\n    ome = from_xml(img_path)\n    return ome.images[0]", "result": "failed: Could not parse XML from '../example_data/ome_xml_example.xml'", "passed": false}
{"task_id": "../test_cases/region_growing_segmentation.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.flood(image, point)", "full_response": "\n    import skimage\n    return skimage.segmentation.flood(image, point)", "result": "passed", "passed": true}
{"task_id": "../test_cases/register_timelapse.ipynb", "completion": "\n    from skimage import registration\n    import scipy.ndimage as ndi\n\n    new_video = video.copy()\n    ref_frame = new_video[-1]\n    for t in range(len(video) - 1, 0, -1):\n        mov_frame = video[t - 1]\n        shift, _, _ = registration.phase_cross_correlation(\n            ref_frame,\n            mov_frame,\n            upsample_factor=4,\n            normalization=None,\n        )\n        # replaces old ref_frame with shifted mov_frame\n        ref_frame = ndi.shift(mov_frame, shift, order=1)\n        new_video[t - 1] = ref_frame\n\n    return new_video", "full_response": "\n    from skimage import registration\n    import scipy.ndimage as ndi\n\n    new_video = video.copy()\n    ref_frame = new_video[-1]\n    for t in range(len(video) - 1, 0, -1):\n        mov_frame = video[t - 1]\n        shift, _, _ = registration.phase_cross_correlation(\n            ref_frame,\n            mov_frame,\n            upsample_factor=4,\n            normalization=None,\n        )\n        # replaces old ref_frame with shifted mov_frame\n        ref_frame = ndi.shift(mov_frame, shift, order=1)\n        new_video[t - 1] = ref_frame\n\n    return new_video", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_labels_on_edges.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.clear_border(label_image)", "full_response": "\n    import skimage\n    return skimage.segmentation.clear_border(label_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_noise_edge_preserving.ipynb", "completion": "\n    from scipy.ndimage import median_filter\n    filtered_image = median_filter(image, size=radius * 2 + 1)\n    return filtered_image", "full_response": "\n    from scipy.ndimage import median_filter\n    filtered_image = median_filter(image, size=radius * 2 + 1)\n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_small_labels.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.exclude_small_labels(label_image, maximum_size=size_threshold))", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.exclude_small_labels(label_image, maximum_size=size_threshold))", "result": "passed", "passed": true}
{"task_id": "../test_cases/reshape_array.ipynb", "completion": "\n    import numpy as np\n    \n    array = np.asarray(image)\n    array = np.transpose(array, axes=[2, 0, 1])\n    return array", "full_response": "\n    import numpy as np\n    \n    array = np.asarray(image)\n    array = np.transpose(array, axes=[2, 0, 1])\n    return array", "result": "passed", "passed": true}
{"task_id": "../test_cases/return_hello_world.ipynb", "completion": "\n    return \"hello world\"", "full_response": "\n    return \"hello world\"", "result": "passed", "passed": true}
{"task_id": "../test_cases/rgb_to_grey_image_transform.ipynb", "completion": "\n    rgb_sum = r + g + b\n    r = r / rgb_sum\n    g = g / rgb_sum\n    b = b / rgb_sum\n    \n    import numpy as np\n    channel_r = rgb_image[...,0]\n    channel_g = rgb_image[...,1]\n    channel_b = rgb_image[...,2]\n    grey_image = channel_r * r + \\\n                 channel_g * g + \\\n                 channel_b * b\n    \n    return grey_image", "full_response": "\n    rgb_sum = r + g + b\n    r = r / rgb_sum\n    g = g / rgb_sum\n    b = b / rgb_sum\n    \n    import numpy as np\n    channel_r = rgb_image[...,0]\n    channel_g = rgb_image[...,1]\n    channel_b = rgb_image[...,2]\n    grey_image = channel_r * r + \\\n                 channel_g * g + \\\n                 channel_b * b\n    \n    return grey_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/roi_imagej_to_ezomero.ipynb", "completion": "\n    list_of_tuples = list(dataframe.itertuples(index=False, name=None))\n    return list_of_tuples", "full_response": "\n    list_of_tuples = list(dataframe.itertuples(index=False, name=None))\n    return list_of_tuples", "result": "passed", "passed": true}
{"task_id": "../test_cases/rotate_image_by_90_degrees.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.rotate(image, angle_around_z_in_degrees=90))", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.rotate(image, angle_around_z_in_degrees=90))", "result": "passed", "passed": true}
{"task_id": "../test_cases/save_image_with_voxel_size.ipynb", "completion": "\n    from aicsimageio import AICSImage \n    from aicsimageio.types import PhysicalPixelSizes\n    from tempfile import tempdir\n    import os \n\n    image = AICSImage(image)\n    AICSImage.physical_pixel_sizes = PhysicalPixelSizes(Z=vz,Y=vy,X=vx)\n    img_path = os.path.join(tempdir, 'voxel_save_test.ome.tiff')\n    image.save(img_path)\n    return img_path", "full_response": "\n    from aicsimageio import AICSImage \n    from aicsimageio.types import PhysicalPixelSizes\n    from tempfile import tempdir\n    import os \n\n    image = AICSImage(image)\n    AICSImage.physical_pixel_sizes = PhysicalPixelSizes(Z=vz,Y=vy,X=vx)\n    img_path = os.path.join(tempdir, 'voxel_save_test.ome.tiff')\n    image.save(img_path)\n    return img_path", "result": "passed", "passed": true}
{"task_id": "../test_cases/scale_image_affine_transform.ipynb", "completion": "\n    from pyclesperanto_prototype import AffineTransform3D\n    import pyclesperanto_prototype as cle \n    import numpy as np\n    \n    output_img_shape =  (image.shape[0]*sy, image.shape[1]*sx)\n\n    transform = AffineTransform3D()\n    transform.center(image.shape)\n    transform.scale(scale_x = sx, scale_y = sy)\n    transform.center(output_img_shape,undo=True)\n    scaled_image = np.array(cle.affine_transform(image,transform=transform,auto_size=True))\n    return scaled_image, transform._matrix", "full_response": "\n    from pyclesperanto_prototype import AffineTransform3D\n    import pyclesperanto_prototype as cle \n    import numpy as np\n    \n    output_img_shape =  (image.shape[0]*sy, image.shape[1]*sx)\n\n    transform = AffineTransform3D()\n    transform.center(image.shape)\n    transform.scale(scale_x = sx, scale_y = sy)\n    transform.center(output_img_shape,undo=True)\n    scaled_image = np.array(cle.affine_transform(image,transform=transform,auto_size=True))\n    return scaled_image, transform._matrix", "result": "passed", "passed": true}
{"task_id": "../test_cases/select_coexpressing_cells.ipynb", "completion": "\n    import numpy as np\n    import pandas as pd\n    from skimage.measure import regionprops_table\n\n    df = pd.DataFrame(\n        regionprops_table(label_image, image, properties=(\"label\", \"area\", \"intensity_mean\"))\n    )\n    mean_cols = [c for c in df.columns if c.startswith(\"intensity_mean\")]\n    sum_cols = [f\"intensity_sum-{i}\" for i in range(len(mean_cols))]\n    \n    df[sum_cols] = df[mean_cols] * df[\"area\"].to_numpy()\n    \n    selected_ids = df.loc[(df[sum_cols] > threshold).all(axis=1), \"label\"].to_numpy()\n    \n    below_threshold_mask = np.isin(label_image, selected_ids, invert=False)\n    filtered_labels = label_image * below_threshold_mask\n\n    return filtered_labels", "full_response": "\n    import numpy as np\n    import pandas as pd\n    from skimage.measure import regionprops_table\n\n    df = pd.DataFrame(\n        regionprops_table(label_image, image, properties=(\"label\", \"area\", \"intensity_mean\"))\n    )\n    mean_cols = [c for c in df.columns if c.startswith(\"intensity_mean\")]\n    sum_cols = [f\"intensity_sum-{i}\" for i in range(len(mean_cols))]\n    \n    df[sum_cols] = df[mean_cols] * df[\"area\"].to_numpy()\n    \n    selected_ids = df.loc[(df[sum_cols] > threshold).all(axis=1), \"label\"].to_numpy()\n    \n    below_threshold_mask = np.isin(label_image, selected_ids, invert=False)\n    filtered_labels = label_image * below_threshold_mask\n\n    return filtered_labels", "result": "passed", "passed": true}
{"task_id": "../test_cases/stack_and_merge.ipynb", "completion": "\n    import numpy as np\n    stacked_image = np.stack((image1, image2), axis=0)\n    stitched_image = np.concatenate((stacked_image, image3), axis=2)\n    return stitched_image.shape", "full_response": "\n    import numpy as np\n    stacked_image = np.stack((image1, image2), axis=0)\n    stitched_image = np.concatenate((stacked_image, image3), axis=2)\n    return stitched_image.shape", "result": "passed", "passed": true}
{"task_id": "../test_cases/subsample_image.ipynb", "completion": "\n    return image[::n,::n]", "full_response": "\n    return image[::n,::n]", "result": "passed", "passed": true}
{"task_id": "../test_cases/subtract_background_tophat.ipynb", "completion": "\n    from skimage.morphology import white_tophat\n    from skimage.morphology import disk\n    filtered_image = white_tophat(image, footprint=disk(radius))\n    \n    return filtered_image", "full_response": "\n    from skimage.morphology import white_tophat\n    from skimage.morphology import disk\n    filtered_image = white_tophat(image, footprint=disk(radius))\n    \n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/sum_images.ipynb", "completion": "\n    return image1 + image2", "full_response": "\n    return image1 + image2", "result": "passed", "passed": true}
{"task_id": "../test_cases/sum_intensity_projection.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).sum(axis=0)", "full_response": "\n    import numpy as np\n    return np.asarray(image).sum(axis=0)", "result": "passed", "passed": true}
{"task_id": "../test_cases/tiled_image_processing.ipynb", "completion": "\n    import dask\n    import dask.array as da\n\n    tiles = da.from_array(image, chunks=(tile_size, tile_size))\n    \n    def procedure(image):\n        from scipy.ndimage import maximum_filter\n        return maximum_filter(image, size=radius*2+1)\n\n    # setup a lazy result (not computed yet)\n    tile_map = da.map_blocks(procedure, tiles)\n\n    # actually apply filter\n    result = tile_map.compute()\n\n    return result", "full_response": "\n    import dask\n    import dask.array as da\n\n    tiles = da.from_array(image, chunks=(tile_size, tile_size))\n    \n    def procedure(image):\n        from scipy.ndimage import maximum_filter\n        return maximum_filter(image, size=radius*2+1)\n\n    # setup a lazy result (not computed yet)\n    tile_map = da.map_blocks(procedure, tiles)\n\n    # actually apply filter\n    result = tile_map.compute()\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/translate_3d_image_along_vector.ipynb", "completion": "\n    from pyclesperanto_prototype import translate\n\n    # translate 3d image along t_x, t_y and t_z\n    return translate(image, translate_x = t_x, translate_y = t_y, translate_z = t_z)", "full_response": "\n    from pyclesperanto_prototype import translate\n\n    # translate 3d image along t_x, t_y and t_z\n    return translate(image, translate_x = t_x, translate_y = t_y, translate_z = t_z)", "result": "passed", "passed": true}
{"task_id": "../test_cases/transpose_image_axes.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).T", "full_response": "\n    import numpy as np\n    return np.asarray(image).T", "result": "passed", "passed": true}
{"task_id": "../test_cases/t_test.ipynb", "completion": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    return scipy.stats.ttest_rel(data1, data2)[1]\n    ", "full_response": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    return scipy.stats.ttest_rel(data1, data2)[1]\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_batch_process_folder_count_labels.ipynb", "completion": "\n    import os\n    from skimage.io import imread\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]\n    result = {}\n\n    for filename in file_list:\n        image = imread(folder_location + filename)\n\n        labels = np.unique(image).tolist()\n        labels.pop(0)\n\n        count = len(labels)\n\n        result[filename] = count\n\n    return result", "full_response": "\n    import os\n    from skimage.io import imread\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]\n    result = {}\n\n    for filename in file_list:\n        image = imread(folder_location + filename)\n\n        labels = np.unique(image).tolist()\n        labels.pop(0)\n\n        count = len(labels)\n\n        result[filename] = count\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_batch_process_folder_measure_intensity.ipynb", "completion": "\n    import os\n    import pandas as pd\n    from skimage.io import imread\n    from skimage.measure import regionprops\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(image_folder_location) if str(fn[-4:]) in supported_fileendings]\n\n    result = []\n\n    for filename in file_list:\n        image = imread(image_folder_location + filename)[...,0]\n        labels = imread(labels_folder_location + filename)\n\n        stats = regionprops(labels, intensity_image=image)\n\n        for s in stats:\n            result.append({\n                \"filename\":filename,\n                \"label\":s.label,\n                \"min_intensity\":s.min_intensity,\n                \"mean_intensity\":s.mean_intensity,\n                \"max_intensity\":s.max_intensity,\n            })\n\n    return pd.DataFrame(result)", "full_response": "\n    import os\n    import pandas as pd\n    from skimage.io import imread\n    from skimage.measure import regionprops\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(image_folder_location) if str(fn[-4:]) in supported_fileendings]\n\n    result = []\n\n    for filename in file_list:\n        image = imread(image_folder_location + filename)[...,0]\n        labels = imread(labels_folder_location + filename)\n\n        stats = regionprops(labels, intensity_image=image)\n\n        for s in stats:\n            result.append({\n                \"filename\":filename,\n                \"label\":s.label,\n                \"min_intensity\":s.min_intensity,\n                \"mean_intensity\":s.mean_intensity,\n                \"max_intensity\":s.max_intensity,\n            })\n\n    return pd.DataFrame(result)", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segmentation_counting.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    average_intensity = np.asarray(image).mean()\n    binary = image > average_intensity\n    labels = skimage.measure.label(binary)\n    return labels.max()", "full_response": "\n    import skimage\n    import numpy as np\n    average_intensity = np.asarray(image).mean()\n    binary = image > average_intensity\n    labels = skimage.measure.label(binary)\n    return labels.max()", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segmentation_measurement_summary.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n    label_image = skimage.measure.label(binary_image)\n    stats = skimage.measure.regionprops(label_image)\n    areas = [s.area for s in stats]\n    return np.mean(areas)", "full_response": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n    label_image = skimage.measure.label(binary_image)\n    stats = skimage.measure.regionprops(label_image)\n    areas = [s.area for s in stats]\n    return np.mean(areas)", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segment_measure_umap.ipynb", "completion": "\n    import numpy as np\n    import pandas as pd\n    import umap\n    from skimage.measure import label, regionprops_table\n\n    image = np.asarray(image)\n\n    # segment\n    binary = image > 0.5 * image.max()\n    labels = label(binary)\n\n    # measure\n    dataframe = pd.DataFrame(regionprops_table(labels, intensity_image=image, \n                                              properties=['area', 'perimeter', 'mean_intensity', \n                                                          'minor_axis_length', 'major_axis_length']))\n\n    # append UMAP\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    return dataframe", "full_response": "\n    import numpy as np\n    import pandas as pd\n    import umap\n    from skimage.measure import label, regionprops_table\n\n    image = np.asarray(image)\n\n    # segment\n    binary = image > 0.5 * image.max()\n    labels = label(binary)\n\n    # measure\n    dataframe = pd.DataFrame(regionprops_table(labels, intensity_image=image, \n                                              properties=['area', 'perimeter', 'mean_intensity', \n                                                          'minor_axis_length', 'major_axis_length']))\n\n    # append UMAP\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    return dataframe", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_watershed_segmentation_correction_measurement.ipynb", "completion": "\n    import skimage\n    blurred = skimage.filters.gaussian(image * 255, sigma=1)\n    minima = skimage.morphology.local_minima(blurred)\n    spots = skimage.measure.label(minima)\n    labels = skimage.segmentation.watershed(blurred, spots)\n    labels_without_border = skimage.segmentation.clear_border(labels)   \n    binary = labels_without_border > 0\n    return binary.sum()", "full_response": "\n    import skimage\n    blurred = skimage.filters.gaussian(image * 255, sigma=1)\n    minima = skimage.morphology.local_minima(blurred)\n    spots = skimage.measure.label(minima)\n    labels = skimage.segmentation.watershed(blurred, spots)\n    labels_without_border = skimage.segmentation.clear_border(labels)   \n    binary = labels_without_border > 0\n    return binary.sum()", "result": "passed", "passed": true}
{"task_id": "../test_cases/apply_otsu_threshold_and_count_positive_pixels.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n\n    result = np.sum(binary_image)\n\n    return result", "full_response": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n\n    result = np.sum(binary_image)\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/binary_closing.ipynb", "completion": "\n    import numpy as np\n    import skimage\n    size = radius * 2 + 1\n    return skimage.morphology.binary_closing(binary_image, footprint=np.ones((size, size)))", "full_response": "\n    import numpy as np\n    import skimage\n    size = radius * 2 + 1\n    return skimage.morphology.binary_closing(binary_image, footprint=np.ones((size, size)))", "result": "passed", "passed": true}
{"task_id": "../test_cases/binary_skeleton.ipynb", "completion": "\n    from skimage.morphology import skeletonize\n    return skeletonize(binary_image)", "full_response": "\n    from skimage.morphology import skeletonize\n    return skeletonize(binary_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/bland_altman.ipynb", "completion": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    dataframe['mean'] = (data1 + data2) / 2\n    dataframe['diff'] = data2 - data1\n    return dataframe", "full_response": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    dataframe['mean'] = (data1 + data2) / 2\n    dataframe['diff'] = data2 - data1\n    return dataframe", "result": "passed", "passed": true}
{"task_id": "../test_cases/combine_columns_of_tables.ipynb", "completion": "\n    import pandas as pd\n    return pd.merge(dataframe1, dataframe2, how='outer', on='label')", "full_response": "\n    import pandas as pd\n    return pd.merge(dataframe1, dataframe2, how='outer', on='label')", "result": "passed", "passed": true}
{"task_id": "../test_cases/convert_points_polygon.ipynb", "completion": "\n    from shapely import Polygon\n    polygon = Polygon(coordinates)\n    return polygon\n", "full_response": "\n    from shapely import Polygon\n    polygon = Polygon(coordinates)\n    return polygon\n", "result": "passed", "passed": true}
{"task_id": "../test_cases/convex_hull_measure_area.ipynb", "completion": "\n    import vedo\n    convex_hull = vedo.shapes.ConvexHull(point_cloud)\n    return convex_hull.area()", "full_response": "\n    import vedo\n    convex_hull = vedo.shapes.ConvexHull(point_cloud)\n    return convex_hull.area()", "result": "passed", "passed": true}
{"task_id": "../test_cases/convolve_images.ipynb", "completion": "\n    import scipy\n    return scipy.ndimage.convolve(image, kernel_image)\n    ", "full_response": "\n    import scipy\n    return scipy.ndimage.convolve(image, kernel_image)\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_number_of_touching_neighbors.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n\n    touch_matrix = cle.generate_touch_matrix(label_image)\n    cle.set_row(touch_matrix, 0, 0)\n    cle.set_column(touch_matrix, 0, 0)\n\n    return np.asarray(cle.sum_y_projection(touch_matrix))[0,1:].tolist()", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n\n    touch_matrix = cle.generate_touch_matrix(label_image)\n    cle.set_row(touch_matrix, 0, 0)\n    cle.set_column(touch_matrix, 0, 0)\n\n    return np.asarray(cle.sum_y_projection(touch_matrix))[0,1:].tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_objects_over_time.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import label\n    labels = [label(binary_image) for binary_image in binary_image_list]\n    return [len(np.unique(label)) - 1 for label in labels]", "full_response": "\n    import numpy as np\n    from skimage.measure import label\n    labels = [label(binary_image) for binary_image in binary_image_list]\n    return [len(np.unique(label)) - 1 for label in labels]", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_overlapping_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image_1, label_image_2, properties=('mean_intensity',))\n    return (pd.DataFrame(stats)['mean_intensity'] > 0).sum()", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image_1, label_image_2, properties=('mean_intensity',))\n    return (pd.DataFrame(stats)['mean_intensity'] > 0).sum()", "result": "passed", "passed": true}
{"task_id": "../test_cases/create_umap.ipynb", "completion": "\n    import umap\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    # no return value", "full_response": "\n    import umap\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    # no return value", "result": "passed", "passed": true}
{"task_id": "../test_cases/crop_quarter_image.ipynb", "completion": "\n    width = image.shape[1]\n    height = image.shape[0]\n\n    return image[:int(width/2),:int(height/2)]", "full_response": "\n    width = image.shape[1]\n    height = image.shape[0]\n\n    return image[:int(width/2),:int(height/2)]", "result": "passed", "passed": true}
{"task_id": "../test_cases/dataframe_column_rename.ipynb", "completion": "\n    for old_value, new_value in replacements.items():\n        df[column] = df[column].replace(old_value, new_value, regex=True)\n    return df", "full_response": "\n    for old_value, new_value in replacements.items():\n        df[column] = df[column].replace(old_value, new_value, regex=True)\n    return df", "result": "passed", "passed": true}
{"task_id": "../test_cases/deconvolve_image.ipynb", "completion": "\n    from scipy import fftpack\n\n    # adapted from: https://stackoverflow.com/questions/17473917/is-there-a-equivalent-of-scipy-signal-deconvolve-for-2d-arrays\n    star_fft = fftpack.fftshift(fftpack.fftn(image))\n    psf_fft = fftpack.fftshift(fftpack.fftn(kernel_image))\n    return fftpack.fftshift(fftpack.ifftn(fftpack.ifftshift(star_fft/psf_fft)))\n    ", "full_response": "\n    from scipy import fftpack\n\n    # adapted from: https://stackoverflow.com/questions/17473917/is-there-a-equivalent-of-scipy-signal-deconvolve-for-2d-arrays\n    star_fft = fftpack.fftshift(fftpack.fftn(image))\n    psf_fft = fftpack.fftshift(fftpack.fftn(kernel_image))\n    return fftpack.fftshift(fftpack.ifftn(fftpack.ifftshift(star_fft/psf_fft)))\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/detect_edges.ipynb", "completion": "\n    from scipy.ndimage import sobel\n    filtered_image = sobel(image)\n    return filtered_image", "full_response": "\n    from scipy.ndimage import sobel\n    filtered_image = sobel(image)\n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/detect_ellipse.ipynb", "completion": "\n    from skimage.transform import hough_ellipse\n    result = hough_ellipse(image,  accuracy=5, threshold=10)\n    result.sort(order='accumulator')\n    \n    # Estimated parameters for the ellipse\n    best = list(result[-1])\n    yc, xc, a, b = (int(round(x)) for x in best[1:5])\n    \n    return yc, xc", "full_response": "\n    from skimage.transform import hough_ellipse\n    result = hough_ellipse(image,  accuracy=5, threshold=10)\n    result.sort(order='accumulator')\n    \n    # Estimated parameters for the ellipse\n    best = list(result[-1])\n    yc, xc, a, b = (int(round(x)) for x in best[1:5])\n    \n    return yc, xc", "result": "passed", "passed": true}
{"task_id": "../test_cases/distance_between_maxima.ipynb", "completion": "\n    import numpy as np\n\n    im1 = np.asarray(image1)\n    im2 = np.asarray(image2)\n\n    x1,y1 = np.unravel_index(im1.argmax(), im1.shape)\n    x2,y2 = np.unravel_index(im2.argmax(), im2.shape)\n\n    distance = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n\n    return distance", "full_response": "\n    import numpy as np\n\n    im1 = np.asarray(image1)\n    im2 = np.asarray(image2)\n\n    x1,y1 = np.unravel_index(im1.argmax(), im1.shape)\n    x2,y2 = np.unravel_index(im2.argmax(), im2.shape)\n\n    distance = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n\n    return distance", "result": "passed", "passed": true}
{"task_id": "../test_cases/expand_labels_without_overlap.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.expand_labels(label_image, distance=radius)", "full_response": "\n    import skimage\n    return skimage.segmentation.expand_labels(label_image, distance=radius)", "result": "passed", "passed": true}
{"task_id": "../test_cases/extract_surface_measure_area.ipynb", "completion": "\n    import vedo\n    volume = vedo.Volume(binary_volume_image)\n    iso_surface = volume.isosurface()\n    return iso_surface.area()", "full_response": "\n    import vedo\n    volume = vedo.Volume(binary_volume_image)\n    iso_surface = volume.isosurface()\n    return iso_surface.area()", "result": "passed", "passed": true}
{"task_id": "../test_cases/fft_spectrum.ipynb", "completion": "\n        import numpy as np\n    \n        # computing padding tuple:\n        pad_width = ((padding, padding),)*nd_image.ndim\n    \n        # Padding:\n        image_padded = np.pad(nd_image, pad_width=pad_width, mode='symmetric')\n        \n        # prepare the apodization window in 1D:\n        from scipy import signal\n        window_tuple = (signal.windows.hamming(length+2*padding) for length in nd_image.shape)\n        \n        # prepare the apodization window in nD:\n        import functools\n        window = functools.reduce(np.multiply.outer, window_tuple)\n        \n        # Apodize:\n        image_padded_apodized = window*image_padded\n    \n        # Compute the Fourier transform of the image:\n        image_fft = np.fft.fftn(image_padded_apodized)\n        \n        # Shift the zero-frequency component to the center of the spectrum:\n        image_fft_shifted = np.fft.fftshift(image_fft)\n        \n        # Compute the magnitude spectrum:\n        magnitude_spectrum = np.log1p(np.abs(image_fft_shifted))\n            \n        return(magnitude_spectrum)\n    \n    import numpy as np   \n\n    # Test image:\n    image = np.ones((5, 6, 7), dtype=np.int16)\n\n    # Padding:\n    padding_width = 10\n\n    # running the candidate function:\n    magnitude_spectrum_candidate = candidate(image, padding_width)\n    \n    # Reference implementation:\n    magnitude_spectrum_reference = fft_spectrum_reference(image, padding_width)\n    \n    assert np.allclose(magnitude_spectrum_candidate, magnitude_spectrum_reference)", "full_response": "\n        import numpy as np\n    \n        # computing padding tuple:\n        pad_width = ((padding, padding),)*nd_image.ndim\n    \n        # Padding:\n        image_padded = np.pad(nd_image, pad_width=pad_width, mode='symmetric')\n        \n        # prepare the apodization window in 1D:\n        from scipy import signal\n        window_tuple = (signal.windows.hamming(length+2*padding) for length in nd_image.shape)\n        \n        # prepare the apodization window in nD:\n        import functools\n        window = functools.reduce(np.multiply.outer, window_tuple)\n        \n        # Apodize:\n        image_padded_apodized = window*image_padded\n    \n        # Compute the Fourier transform of the image:\n        image_fft = np.fft.fftn(image_padded_apodized)\n        \n        # Shift the zero-frequency component to the center of the spectrum:\n        image_fft_shifted = np.fft.fftshift(image_fft)\n        \n        # Compute the magnitude spectrum:\n        magnitude_spectrum = np.log1p(np.abs(image_fft_shifted))\n            \n        return(magnitude_spectrum)\n    \n    import numpy as np   \n\n    # Test image:\n    image = np.ones((5, 6, 7), dtype=np.int16)\n\n    # Padding:\n    padding_width = 10\n\n    # running the candidate function:\n    magnitude_spectrum_candidate = candidate(image, padding_width)\n    \n    # Reference implementation:\n    magnitude_spectrum_reference = fft_spectrum_reference(image, padding_width)\n    \n    assert np.allclose(magnitude_spectrum_candidate, magnitude_spectrum_reference)", "result": "timed out", "passed": false}
{"task_id": "../test_cases/find_closest_neighbors.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import centroid\n    \n    # Identify all centroid locations\n    label_count = np.max(label_image)\n    centroids = {}\n    for i in range(1, label_count + 1):\n        binary_image = (label_image == i)\n        centroids[i] = centroid(binary_image)\n    \n    # Find the closest top n\n    distances = [(other, np.linalg.norm(centroids[target_label] - centroids[other])) for other in centroids.keys() if other != target_label]\n    sorted_distances = sorted(distances, key = lambda pair: pair[1])\n    topn = [label for label, _ in sorted_distances[:n]]\n\n    return topn", "full_response": "\n    import numpy as np\n    from skimage.measure import centroid\n    \n    # Identify all centroid locations\n    label_count = np.max(label_image)\n    centroids = {}\n    for i in range(1, label_count + 1):\n        binary_image = (label_image == i)\n        centroids[i] = centroid(binary_image)\n    \n    # Find the closest top n\n    distances = [(other, np.linalg.norm(centroids[target_label] - centroids[other])) for other in centroids.keys() if other != target_label]\n    sorted_distances = sorted(distances, key = lambda pair: pair[1])\n    topn = [label for label, _ in sorted_distances[:n]]\n\n    return topn", "result": "passed", "passed": true}
{"task_id": "../test_cases/fit_circle.ipynb", "completion": "\n    import circle_fit as cf\n    xc, yc, r, _ = cf.least_squares_circle(list_of_2d_points)\n    return xc,yc,r", "full_response": "\n    import circle_fit as cf\n    xc, yc, r, _ = cf.least_squares_circle(list_of_2d_points)\n    return xc,yc,r", "result": "passed", "passed": true}
{"task_id": "../test_cases/fit_gaussian_to_spot.ipynb", "completion": "\n    import numpy as np\n    import scipy \n\n    image = np.asarray(image)\n    num_px = image.shape[0]\n    [xx, yy] = np.meshgrid(np.arange(0,num_px), np.arange(0,num_px))\n\n\n    def twoDGauss(x,y,ux,uy,sigma):\n        '''\n        Creates theoretical normalized 2D gaussian spot, centered around (ux,uy) \n        with standard deviation sigma, on grid specified by x and y\n        '''\n        p = 1/(2*np.pi*sigma**2) * np.exp(- ( (x-ux)**2+(y-uy)**2 ) / (2*sigma**2))\n        return p\n\n    def expected(x,y,params):   \n        '''\n        Creates simulated realistic Gaussian spot on x-y grid, with following\n        parameters = [x0,y0,sigma,bg,N], speficically:\n            - x0 = x-position of gaussian (px coord., first pixel is (0,0))\n            - y0 = y-positoin of gaussian (px coord.)\n            - sigma = stdev of gaussian (px coord)\n            - bg = number of photons in background\n            - N = number of photons in spot\n        '''\n        E = params[4] * twoDGauss(x,y,params[0],params[1],params[2]) + params[3]\n        return E\n\n    def SSE(params):\n        '''\n        Calculates sum-of-squared errors difference between 'image' and expected Gaussian defined by 'params'\n        This is essentially the cost-function that is minimized in the fit\n        '''\n        Expec = expected(xx,yy,params)\n        sse = np.sum((image -  Expec)**2)\n        return sse\n\n\n    #guess fit parameters:\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    sigma_guess = 2                 #assume sigma is 2 pixels\n    bg_guess = (np.sum(image) - np.sum(image[1:-1,1:-1]))/(4*num_px-4)           \n                                    #average of border pixels\n    N_guess = np.sum(image) - bg_guess * num_px**2\n                                    #sum of intensities, minus background\n    params_guess = [x_guess,x_guess,sigma_guess, bg_guess, N_guess]\n\n    #perform the fit\n    param = scipy.optimize.fmin(func=SSE,x0=params_guess, maxiter=10000,maxfun=10000,ftol=1e-5,disp=0)\n\n    xc_fit      = param[0]  #fitted x-position\n    yc_fit      = param[1]  #fitted y-position\n    sigma_fit   = param[2]  #fitted sigma\n\n    return (xc_fit, yc_fit, sigma_fit)", "full_response": "\n    import numpy as np\n    import scipy \n\n    image = np.asarray(image)\n    num_px = image.shape[0]\n    [xx, yy] = np.meshgrid(np.arange(0,num_px), np.arange(0,num_px))\n\n\n    def twoDGauss(x,y,ux,uy,sigma):\n        '''\n        Creates theoretical normalized 2D gaussian spot, centered around (ux,uy) \n        with standard deviation sigma, on grid specified by x and y\n        '''\n        p = 1/(2*np.pi*sigma**2) * np.exp(- ( (x-ux)**2+(y-uy)**2 ) / (2*sigma**2))\n        return p\n\n    def expected(x,y,params):   \n        '''\n        Creates simulated realistic Gaussian spot on x-y grid, with following\n        parameters = [x0,y0,sigma,bg,N], speficically:\n            - x0 = x-position of gaussian (px coord., first pixel is (0,0))\n            - y0 = y-positoin of gaussian (px coord.)\n            - sigma = stdev of gaussian (px coord)\n            - bg = number of photons in background\n            - N = number of photons in spot\n        '''\n        E = params[4] * twoDGauss(x,y,params[0],params[1],params[2]) + params[3]\n        return E\n\n    def SSE(params):\n        '''\n        Calculates sum-of-squared errors difference between 'image' and expected Gaussian defined by 'params'\n        This is essentially the cost-function that is minimized in the fit\n        '''\n        Expec = expected(xx,yy,params)\n        sse = np.sum((image -  Expec)**2)\n        return sse\n\n\n    #guess fit parameters:\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    sigma_guess = 2                 #assume sigma is 2 pixels\n    bg_guess = (np.sum(image) - np.sum(image[1:-1,1:-1]))/(4*num_px-4)           \n                                    #average of border pixels\n    N_guess = np.sum(image) - bg_guess * num_px**2\n                                    #sum of intensities, minus background\n    params_guess = [x_guess,x_guess,sigma_guess, bg_guess, N_guess]\n\n    #perform the fit\n    param = scipy.optimize.fmin(func=SSE,x0=params_guess, maxiter=10000,maxfun=10000,ftol=1e-5,disp=0)\n\n    xc_fit      = param[0]  #fitted x-position\n    yc_fit      = param[1]  #fitted y-position\n    sigma_fit   = param[2]  #fitted sigma\n\n    return (xc_fit, yc_fit, sigma_fit)", "result": "passed", "passed": true}
{"task_id": "../test_cases/flow_field_deformation.ipynb", "completion": "\n    import SimpleITK as sitk\n\n    target = sitk.GetImageFromArray(target)\n\n    displacement = sitk.DisplacementFieldTransform(2)\n    field_size = list(flow_field.shape[:2])\n    field_origin = [0, 0]\n    field_spacing = [1.0, 1.0]\n    field_direction = [1, 0, 0, 1]  # direction cosine matrix (row major order)\n\n    # Concatenate all the information into a single list\n    displacement.SetFixedParameters(\n        field_size + field_origin + field_spacing + field_direction\n    )\n    # Set the interpolator to nearest neighbor\n    displacement.SetInterpolator(sitk.sitkNearestNeighbor)\n\n    originalDisplacements = flow_field.reshape((-1, 2)).flatten()\n    displacement.SetParameters(originalDisplacements)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetTransform(displacement)\n    resampler.SetReferenceImage(target)\n    resampled = resampler.Execute(target)\n\n    return sitk.GetArrayFromImage(resampled)", "full_response": "\n    import SimpleITK as sitk\n\n    target = sitk.GetImageFromArray(target)\n\n    displacement = sitk.DisplacementFieldTransform(2)\n    field_size = list(flow_field.shape[:2])\n    field_origin = [0, 0]\n    field_spacing = [1.0, 1.0]\n    field_direction = [1, 0, 0, 1]  # direction cosine matrix (row major order)\n\n    # Concatenate all the information into a single list\n    displacement.SetFixedParameters(\n        field_size + field_origin + field_spacing + field_direction\n    )\n    # Set the interpolator to nearest neighbor\n    displacement.SetInterpolator(sitk.sitkNearestNeighbor)\n\n    originalDisplacements = flow_field.reshape((-1, 2)).flatten()\n    displacement.SetParameters(originalDisplacements)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetTransform(displacement)\n    resampler.SetReferenceImage(target)\n    resampled = resampler.Execute(target)\n\n    return sitk.GetArrayFromImage(resampled)", "result": "passed", "passed": true}
{"task_id": "../test_cases/generate_image_histogram.ipynb", "completion": "\n    import numpy as np\n    return np.histogram(image,bins=num_bins)[0]", "full_response": "\n    import numpy as np\n    return np.histogram(image,bins=num_bins)[0]", "result": "passed", "passed": true}
{"task_id": "../test_cases/identify_centroids.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import centroid\n    n = np.max(label_image)\n    out = {}\n    for i in range(1, n + 1):\n        binary_image = (label_image == i)\n        out[i] = centroid(binary_image)\n    return out", "full_response": "\n    import numpy as np\n    from skimage.measure import centroid\n    n = np.max(label_image)\n    out = {}\n    for i in range(1, n + 1):\n        binary_image = (label_image == i)\n        out[i] = centroid(binary_image)\n    return out", "result": "passed", "passed": true}
{"task_id": "../test_cases/interpolate_stack.ipynb", "completion": "\n    import numpy as np\n\n    return np.linspace(start_slice, end_slice, num)", "full_response": "\n    import numpy as np\n\n    return np.linspace(start_slice, end_slice, num)", "result": "passed", "passed": true}
{"task_id": "../test_cases/label_binary_image_and_count_labels.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    label_image = skimage.measure.label(binary_image)\n\n    return len(np.unique(label_image)) - 1", "full_response": "\n    import skimage\n    import numpy as np\n    label_image = skimage.measure.label(binary_image)\n\n    return len(np.unique(label_image)) - 1", "result": "passed", "passed": true}
{"task_id": "../test_cases/label_sequentially.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.relabel_sequential(label_image)[0]", "full_response": "\n    import skimage\n    return skimage.segmentation.relabel_sequential(label_image)[0]", "result": "passed", "passed": true}
{"task_id": "../test_cases/linear_intensity_profile.ipynb", "completion": "\n    from skimage.measure import profile_line\n    return profile_line(image, starting_point, ending_point)", "full_response": "\n    from skimage.measure import profile_line\n    return profile_line(image, starting_point, ending_point)", "result": "passed", "passed": true}
{"task_id": "../test_cases/list_image_files_in_folder.ipynb", "completion": "\n    import os\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    return [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]", "full_response": "\n    import os\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    return [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]", "result": "passed", "passed": true}
{"task_id": "../test_cases/load_tif_and_output_rgb.ipynb", "completion": "\n    from cv2 import imread, cvtColor, COLOR_BGR2RGB\n    image = imread(path_to_tif)\n    return cvtColor(image, COLOR_BGR2RGB)", "full_response": "\n    from cv2 import imread, cvtColor, COLOR_BGR2RGB\n    image = imread(path_to_tif)\n    return cvtColor(image, COLOR_BGR2RGB)", "result": "failed: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n", "passed": false}
{"task_id": "../test_cases/local_maxima_from_distance_transform.ipynb", "completion": "\n    import scipy.ndimage as ndi\n    import skimage.feature as skf\n    \n    distance_transform = ndi.distance_transform_edt(binary_image)\n    \n    image_max = ndi.maximum_filter(distance_transform, size=nms_window, mode='constant')\n    \n    # suppress non-maxima values by setting them to -1\n    mask = distance_transform == image_max\n    image_max[~mask] = -1\n    \n    local_maxima = skf.peak_local_max(image_max)\n\n    return local_maxima.tolist()", "full_response": "\n    import scipy.ndimage as ndi\n    import skimage.feature as skf\n    \n    distance_transform = ndi.distance_transform_edt(binary_image)\n    \n    image_max = ndi.maximum_filter(distance_transform, size=nms_window, mode='constant')\n    \n    # suppress non-maxima values by setting them to -1\n    mask = distance_transform == image_max\n    image_max[~mask] = -1\n    \n    local_maxima = skf.peak_local_max(image_max)\n\n    return local_maxima.tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/map_pixel_count_of_labels.ipynb", "completion": "\n    import pyclesperanto_prototype as cle\n    return cle.pixel_count_map(label_image)", "full_response": "\n    import pyclesperanto_prototype as cle\n    return cle.pixel_count_map(label_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/mask_image.ipynb", "completion": "\n    import numpy as np\n    return image * mask", "full_response": "\n    import numpy as np\n    return image * mask", "result": "passed", "passed": true}
{"task_id": "../test_cases/maximum_intensity_projection.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).max(axis=0)", "full_response": "\n    import numpy as np\n    return np.asarray(image).max(axis=0)", "result": "passed", "passed": true}
{"task_id": "../test_cases/mean_squared_error.ipynb", "completion": "\n    return ((image1 - image2)**2).mean()\n    # adapted from : https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy", "full_response": "\n    return ((image1 - image2)**2).mean()\n    # adapted from : https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy", "result": "passed", "passed": true}
{"task_id": "../test_cases/mean_std_column.ipynb", "completion": "\n    import numpy as np\n    data = dataframe[column]\n    return np.mean(data), np.std(data)", "full_response": "\n    import numpy as np\n    data = dataframe[column]\n    return np.mean(data), np.std(data)", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_aspect_ratio_of_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = pd.DataFrame(skimage.measure.regionprops_table(label_image, properties=('minor_axis_length', 'major_axis_length')))\n    stats['aspect_ratio'] = stats['major_axis_length'] / stats['minor_axis_length']\n    return stats", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = pd.DataFrame(skimage.measure.regionprops_table(label_image, properties=('minor_axis_length', 'major_axis_length')))\n    stats['aspect_ratio'] = stats['major_axis_length'] / stats['minor_axis_length']\n    return stats", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_intensity_of_labels.ipynb", "completion": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image, intensity_image)\n    return [s.mean_intensity for s in stats]", "full_response": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image, intensity_image)\n    return [s.mean_intensity for s in stats]", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_intensity_over_time.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image_list).mean(axis=(1,2)).tolist()", "full_response": "\n    import numpy as np\n    return np.asarray(image_list).mean(axis=(1,2)).tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_mean_image_intensity.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).mean()", "full_response": "\n    import numpy as np\n    return np.asarray(image).mean()", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_pixel_count_of_labels.ipynb", "completion": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image)\n    return [s.area for s in stats]", "full_response": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image)\n    return [s.area for s in stats]", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_properties_of_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\n    return pd.DataFrame(stats)", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\n    return pd.DataFrame(stats)", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_image_read_voxel_size.ipynb", "completion": "\n    from aicsimageio import AICSImage\n    aics_image = AICSImage(image_filename)\n\n    return aics_image.physical_pixel_sizes.Z, \\\n            aics_image.physical_pixel_sizes.Y, \\\n            aics_image.physical_pixel_sizes.X", "full_response": "\n    from aicsimageio import AICSImage\n    aics_image = AICSImage(image_filename)\n\n    return aics_image.physical_pixel_sizes.Z, \\\n            aics_image.physical_pixel_sizes.Y, \\\n            aics_image.physical_pixel_sizes.X", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_image_return_dimensions.ipynb", "completion": "\n    from skimage.io import imread\n    image = imread(image_file_location)\n    return image.shape", "full_response": "\n    from skimage.io import imread\n    image = imread(image_file_location)\n    return image.shape", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_nifti_image.ipynb", "completion": "\n    \n    import nibabel as nib\n    import numpy as nb\n\n    img = nib.load(image_file_location)\n    data = img.get_fdata()\n    return(data)", "full_response": "\n    \n    import nibabel as nib\n    import numpy as nb\n\n    img = nib.load(image_file_location)\n    data = img.get_fdata()\n    return(data)", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_zarr.ipynb", "completion": "\n    import zarr\n    array = zarr.load(zarr_file_location)\n    return array", "full_response": "\n    import zarr\n    array = zarr.load(zarr_file_location)\n    return array", "result": "passed", "passed": true}
{"task_id": "../test_cases/pair_wise_correlation_matrix.ipynb", "completion": "\n    return dataframe.corr()", "full_response": "\n    return dataframe.corr()", "result": "passed", "passed": true}
{"task_id": "../test_cases/radial_intensity_profile.ipynb", "completion": "\n    import numpy as np\n    y, x = np.indices((image.shape))\n    r = np.sqrt((x - xc)**2 + (y - yc)**2)\n    r = r.astype(int)\n    summed_values = np.bincount(r.ravel(), image.ravel())\n    number_of_pixels_at_r = np.bincount(r.ravel())\n    radial_profile = summed_values / number_of_pixels_at_r\n    return radial_profile ", "full_response": "\n    import numpy as np\n    y, x = np.indices((image.shape))\n    r = np.sqrt((x - xc)**2 + (y - yc)**2)\n    r = r.astype(int)\n    summed_values = np.bincount(r.ravel(), image.ravel())\n    number_of_pixels_at_r = np.bincount(r.ravel())\n    radial_profile = summed_values / number_of_pixels_at_r\n    return radial_profile ", "result": "passed", "passed": true}
{"task_id": "../test_cases/read_imagej_tif_metadata.ipynb", "completion": "\n    from tifffile import TiffFile\n    \n    with (TiffFile(image_filename) as tif):\n        imagej_metadata = tif.imagej_metadata\n    return imagej_metadata", "full_response": "\n    from tifffile import TiffFile\n    \n    with (TiffFile(image_filename) as tif):\n        imagej_metadata = tif.imagej_metadata\n    return imagej_metadata", "result": "passed", "passed": true}
{"task_id": "../test_cases/read_ome_metadata_from_ome_xml.ipynb", "completion": "\n    from ome_types import from_xml\n    ome = from_xml(img_path)\n    return ome.images[0]", "full_response": "\n    from ome_types import from_xml\n    ome = from_xml(img_path)\n    return ome.images[0]", "result": "failed: Could not parse XML from '../example_data/ome_xml_example.xml'", "passed": false}
{"task_id": "../test_cases/region_growing_segmentation.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.flood(image, point)", "full_response": "\n    import skimage\n    return skimage.segmentation.flood(image, point)", "result": "passed", "passed": true}
{"task_id": "../test_cases/register_timelapse.ipynb", "completion": "\n    from skimage import registration\n    import scipy.ndimage as ndi\n\n    new_video = video.copy()\n    ref_frame = new_video[-1]\n    for t in range(len(video) - 1, 0, -1):\n        mov_frame = video[t - 1]\n        shift, _, _ = registration.phase_cross_correlation(\n            ref_frame,\n            mov_frame,\n            upsample_factor=4,\n            normalization=None,\n        )\n        # replaces old ref_frame with shifted mov_frame\n        ref_frame = ndi.shift(mov_frame, shift, order=1)\n        new_video[t - 1] = ref_frame\n\n    return new_video", "full_response": "\n    from skimage import registration\n    import scipy.ndimage as ndi\n\n    new_video = video.copy()\n    ref_frame = new_video[-1]\n    for t in range(len(video) - 1, 0, -1):\n        mov_frame = video[t - 1]\n        shift, _, _ = registration.phase_cross_correlation(\n            ref_frame,\n            mov_frame,\n            upsample_factor=4,\n            normalization=None,\n        )\n        # replaces old ref_frame with shifted mov_frame\n        ref_frame = ndi.shift(mov_frame, shift, order=1)\n        new_video[t - 1] = ref_frame\n\n    return new_video", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_labels_on_edges.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.clear_border(label_image)", "full_response": "\n    import skimage\n    return skimage.segmentation.clear_border(label_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_noise_edge_preserving.ipynb", "completion": "\n    from scipy.ndimage import median_filter\n    filtered_image = median_filter(image, size=radius * 2 + 1)\n    return filtered_image", "full_response": "\n    from scipy.ndimage import median_filter\n    filtered_image = median_filter(image, size=radius * 2 + 1)\n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_small_labels.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.exclude_small_labels(label_image, maximum_size=size_threshold))", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.exclude_small_labels(label_image, maximum_size=size_threshold))", "result": "passed", "passed": true}
{"task_id": "../test_cases/reshape_array.ipynb", "completion": "\n    import numpy as np\n    \n    array = np.asarray(image)\n    array = np.transpose(array, axes=[2, 0, 1])\n    return array", "full_response": "\n    import numpy as np\n    \n    array = np.asarray(image)\n    array = np.transpose(array, axes=[2, 0, 1])\n    return array", "result": "passed", "passed": true}
{"task_id": "../test_cases/return_hello_world.ipynb", "completion": "\n    return \"hello world\"", "full_response": "\n    return \"hello world\"", "result": "passed", "passed": true}
{"task_id": "../test_cases/rgb_to_grey_image_transform.ipynb", "completion": "\n    rgb_sum = r + g + b\n    r = r / rgb_sum\n    g = g / rgb_sum\n    b = b / rgb_sum\n    \n    import numpy as np\n    channel_r = rgb_image[...,0]\n    channel_g = rgb_image[...,1]\n    channel_b = rgb_image[...,2]\n    grey_image = channel_r * r + \\\n                 channel_g * g + \\\n                 channel_b * b\n    \n    return grey_image", "full_response": "\n    rgb_sum = r + g + b\n    r = r / rgb_sum\n    g = g / rgb_sum\n    b = b / rgb_sum\n    \n    import numpy as np\n    channel_r = rgb_image[...,0]\n    channel_g = rgb_image[...,1]\n    channel_b = rgb_image[...,2]\n    grey_image = channel_r * r + \\\n                 channel_g * g + \\\n                 channel_b * b\n    \n    return grey_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/roi_imagej_to_ezomero.ipynb", "completion": "\n    list_of_tuples = list(dataframe.itertuples(index=False, name=None))\n    return list_of_tuples", "full_response": "\n    list_of_tuples = list(dataframe.itertuples(index=False, name=None))\n    return list_of_tuples", "result": "passed", "passed": true}
{"task_id": "../test_cases/rotate_image_by_90_degrees.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.rotate(image, angle_around_z_in_degrees=90))", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.rotate(image, angle_around_z_in_degrees=90))", "result": "passed", "passed": true}
{"task_id": "../test_cases/save_image_with_voxel_size.ipynb", "completion": "\n    from aicsimageio import AICSImage \n    from aicsimageio.types import PhysicalPixelSizes\n    from tempfile import tempdir\n    import os \n\n    image = AICSImage(image)\n    AICSImage.physical_pixel_sizes = PhysicalPixelSizes(Z=vz,Y=vy,X=vx)\n    img_path = os.path.join(tempdir, 'voxel_save_test.ome.tiff')\n    image.save(img_path)\n    return img_path", "full_response": "\n    from aicsimageio import AICSImage \n    from aicsimageio.types import PhysicalPixelSizes\n    from tempfile import tempdir\n    import os \n\n    image = AICSImage(image)\n    AICSImage.physical_pixel_sizes = PhysicalPixelSizes(Z=vz,Y=vy,X=vx)\n    img_path = os.path.join(tempdir, 'voxel_save_test.ome.tiff')\n    image.save(img_path)\n    return img_path", "result": "passed", "passed": true}
{"task_id": "../test_cases/scale_image_affine_transform.ipynb", "completion": "\n    from pyclesperanto_prototype import AffineTransform3D\n    import pyclesperanto_prototype as cle \n    import numpy as np\n    \n    output_img_shape =  (image.shape[0]*sy, image.shape[1]*sx)\n\n    transform = AffineTransform3D()\n    transform.center(image.shape)\n    transform.scale(scale_x = sx, scale_y = sy)\n    transform.center(output_img_shape,undo=True)\n    scaled_image = np.array(cle.affine_transform(image,transform=transform,auto_size=True))\n    return scaled_image, transform._matrix", "full_response": "\n    from pyclesperanto_prototype import AffineTransform3D\n    import pyclesperanto_prototype as cle \n    import numpy as np\n    \n    output_img_shape =  (image.shape[0]*sy, image.shape[1]*sx)\n\n    transform = AffineTransform3D()\n    transform.center(image.shape)\n    transform.scale(scale_x = sx, scale_y = sy)\n    transform.center(output_img_shape,undo=True)\n    scaled_image = np.array(cle.affine_transform(image,transform=transform,auto_size=True))\n    return scaled_image, transform._matrix", "result": "passed", "passed": true}
{"task_id": "../test_cases/select_coexpressing_cells.ipynb", "completion": "\n    import numpy as np\n    import pandas as pd\n    from skimage.measure import regionprops_table\n\n    df = pd.DataFrame(\n        regionprops_table(label_image, image, properties=(\"label\", \"area\", \"intensity_mean\"))\n    )\n    mean_cols = [c for c in df.columns if c.startswith(\"intensity_mean\")]\n    sum_cols = [f\"intensity_sum-{i}\" for i in range(len(mean_cols))]\n    \n    df[sum_cols] = df[mean_cols] * df[\"area\"].to_numpy()\n    \n    selected_ids = df.loc[(df[sum_cols] > threshold).all(axis=1), \"label\"].to_numpy()\n    \n    below_threshold_mask = np.isin(label_image, selected_ids, invert=False)\n    filtered_labels = label_image * below_threshold_mask\n\n    return filtered_labels", "full_response": "\n    import numpy as np\n    import pandas as pd\n    from skimage.measure import regionprops_table\n\n    df = pd.DataFrame(\n        regionprops_table(label_image, image, properties=(\"label\", \"area\", \"intensity_mean\"))\n    )\n    mean_cols = [c for c in df.columns if c.startswith(\"intensity_mean\")]\n    sum_cols = [f\"intensity_sum-{i}\" for i in range(len(mean_cols))]\n    \n    df[sum_cols] = df[mean_cols] * df[\"area\"].to_numpy()\n    \n    selected_ids = df.loc[(df[sum_cols] > threshold).all(axis=1), \"label\"].to_numpy()\n    \n    below_threshold_mask = np.isin(label_image, selected_ids, invert=False)\n    filtered_labels = label_image * below_threshold_mask\n\n    return filtered_labels", "result": "passed", "passed": true}
{"task_id": "../test_cases/stack_and_merge.ipynb", "completion": "\n    import numpy as np\n    stacked_image = np.stack((image1, image2), axis=0)\n    stitched_image = np.concatenate((stacked_image, image3), axis=2)\n    return stitched_image.shape", "full_response": "\n    import numpy as np\n    stacked_image = np.stack((image1, image2), axis=0)\n    stitched_image = np.concatenate((stacked_image, image3), axis=2)\n    return stitched_image.shape", "result": "passed", "passed": true}
{"task_id": "../test_cases/subsample_image.ipynb", "completion": "\n    return image[::n,::n]", "full_response": "\n    return image[::n,::n]", "result": "passed", "passed": true}
{"task_id": "../test_cases/subtract_background_tophat.ipynb", "completion": "\n    from skimage.morphology import white_tophat\n    from skimage.morphology import disk\n    filtered_image = white_tophat(image, footprint=disk(radius))\n    \n    return filtered_image", "full_response": "\n    from skimage.morphology import white_tophat\n    from skimage.morphology import disk\n    filtered_image = white_tophat(image, footprint=disk(radius))\n    \n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/sum_images.ipynb", "completion": "\n    return image1 + image2", "full_response": "\n    return image1 + image2", "result": "passed", "passed": true}
{"task_id": "../test_cases/sum_intensity_projection.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).sum(axis=0)", "full_response": "\n    import numpy as np\n    return np.asarray(image).sum(axis=0)", "result": "passed", "passed": true}
{"task_id": "../test_cases/tiled_image_processing.ipynb", "completion": "\n    import dask\n    import dask.array as da\n\n    tiles = da.from_array(image, chunks=(tile_size, tile_size))\n    \n    def procedure(image):\n        from scipy.ndimage import maximum_filter\n        return maximum_filter(image, size=radius*2+1)\n\n    # setup a lazy result (not computed yet)\n    tile_map = da.map_blocks(procedure, tiles)\n\n    # actually apply filter\n    result = tile_map.compute()\n\n    return result", "full_response": "\n    import dask\n    import dask.array as da\n\n    tiles = da.from_array(image, chunks=(tile_size, tile_size))\n    \n    def procedure(image):\n        from scipy.ndimage import maximum_filter\n        return maximum_filter(image, size=radius*2+1)\n\n    # setup a lazy result (not computed yet)\n    tile_map = da.map_blocks(procedure, tiles)\n\n    # actually apply filter\n    result = tile_map.compute()\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/translate_3d_image_along_vector.ipynb", "completion": "\n    from pyclesperanto_prototype import translate\n\n    # translate 3d image along t_x, t_y and t_z\n    return translate(image, translate_x = t_x, translate_y = t_y, translate_z = t_z)", "full_response": "\n    from pyclesperanto_prototype import translate\n\n    # translate 3d image along t_x, t_y and t_z\n    return translate(image, translate_x = t_x, translate_y = t_y, translate_z = t_z)", "result": "passed", "passed": true}
{"task_id": "../test_cases/transpose_image_axes.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).T", "full_response": "\n    import numpy as np\n    return np.asarray(image).T", "result": "passed", "passed": true}
{"task_id": "../test_cases/t_test.ipynb", "completion": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    return scipy.stats.ttest_rel(data1, data2)[1]\n    ", "full_response": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    return scipy.stats.ttest_rel(data1, data2)[1]\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_batch_process_folder_count_labels.ipynb", "completion": "\n    import os\n    from skimage.io import imread\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]\n    result = {}\n\n    for filename in file_list:\n        image = imread(folder_location + filename)\n\n        labels = np.unique(image).tolist()\n        labels.pop(0)\n\n        count = len(labels)\n\n        result[filename] = count\n\n    return result", "full_response": "\n    import os\n    from skimage.io import imread\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]\n    result = {}\n\n    for filename in file_list:\n        image = imread(folder_location + filename)\n\n        labels = np.unique(image).tolist()\n        labels.pop(0)\n\n        count = len(labels)\n\n        result[filename] = count\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_batch_process_folder_measure_intensity.ipynb", "completion": "\n    import os\n    import pandas as pd\n    from skimage.io import imread\n    from skimage.measure import regionprops\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(image_folder_location) if str(fn[-4:]) in supported_fileendings]\n\n    result = []\n\n    for filename in file_list:\n        image = imread(image_folder_location + filename)[...,0]\n        labels = imread(labels_folder_location + filename)\n\n        stats = regionprops(labels, intensity_image=image)\n\n        for s in stats:\n            result.append({\n                \"filename\":filename,\n                \"label\":s.label,\n                \"min_intensity\":s.min_intensity,\n                \"mean_intensity\":s.mean_intensity,\n                \"max_intensity\":s.max_intensity,\n            })\n\n    return pd.DataFrame(result)", "full_response": "\n    import os\n    import pandas as pd\n    from skimage.io import imread\n    from skimage.measure import regionprops\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(image_folder_location) if str(fn[-4:]) in supported_fileendings]\n\n    result = []\n\n    for filename in file_list:\n        image = imread(image_folder_location + filename)[...,0]\n        labels = imread(labels_folder_location + filename)\n\n        stats = regionprops(labels, intensity_image=image)\n\n        for s in stats:\n            result.append({\n                \"filename\":filename,\n                \"label\":s.label,\n                \"min_intensity\":s.min_intensity,\n                \"mean_intensity\":s.mean_intensity,\n                \"max_intensity\":s.max_intensity,\n            })\n\n    return pd.DataFrame(result)", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segmentation_counting.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    average_intensity = np.asarray(image).mean()\n    binary = image > average_intensity\n    labels = skimage.measure.label(binary)\n    return labels.max()", "full_response": "\n    import skimage\n    import numpy as np\n    average_intensity = np.asarray(image).mean()\n    binary = image > average_intensity\n    labels = skimage.measure.label(binary)\n    return labels.max()", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segmentation_measurement_summary.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n    label_image = skimage.measure.label(binary_image)\n    stats = skimage.measure.regionprops(label_image)\n    areas = [s.area for s in stats]\n    return np.mean(areas)", "full_response": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n    label_image = skimage.measure.label(binary_image)\n    stats = skimage.measure.regionprops(label_image)\n    areas = [s.area for s in stats]\n    return np.mean(areas)", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segment_measure_umap.ipynb", "completion": "\n    import numpy as np\n    import pandas as pd\n    import umap\n    from skimage.measure import label, regionprops_table\n\n    image = np.asarray(image)\n\n    # segment\n    binary = image > 0.5 * image.max()\n    labels = label(binary)\n\n    # measure\n    dataframe = pd.DataFrame(regionprops_table(labels, intensity_image=image, \n                                              properties=['area', 'perimeter', 'mean_intensity', \n                                                          'minor_axis_length', 'major_axis_length']))\n\n    # append UMAP\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    return dataframe", "full_response": "\n    import numpy as np\n    import pandas as pd\n    import umap\n    from skimage.measure import label, regionprops_table\n\n    image = np.asarray(image)\n\n    # segment\n    binary = image > 0.5 * image.max()\n    labels = label(binary)\n\n    # measure\n    dataframe = pd.DataFrame(regionprops_table(labels, intensity_image=image, \n                                              properties=['area', 'perimeter', 'mean_intensity', \n                                                          'minor_axis_length', 'major_axis_length']))\n\n    # append UMAP\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    return dataframe", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_watershed_segmentation_correction_measurement.ipynb", "completion": "\n    import skimage\n    blurred = skimage.filters.gaussian(image * 255, sigma=1)\n    minima = skimage.morphology.local_minima(blurred)\n    spots = skimage.measure.label(minima)\n    labels = skimage.segmentation.watershed(blurred, spots)\n    labels_without_border = skimage.segmentation.clear_border(labels)   \n    binary = labels_without_border > 0\n    return binary.sum()", "full_response": "\n    import skimage\n    blurred = skimage.filters.gaussian(image * 255, sigma=1)\n    minima = skimage.morphology.local_minima(blurred)\n    spots = skimage.measure.label(minima)\n    labels = skimage.segmentation.watershed(blurred, spots)\n    labels_without_border = skimage.segmentation.clear_border(labels)   \n    binary = labels_without_border > 0\n    return binary.sum()", "result": "passed", "passed": true}
{"task_id": "../test_cases/apply_otsu_threshold_and_count_positive_pixels.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n\n    result = np.sum(binary_image)\n\n    return result", "full_response": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n\n    result = np.sum(binary_image)\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/binary_closing.ipynb", "completion": "\n    import numpy as np\n    import skimage\n    size = radius * 2 + 1\n    return skimage.morphology.binary_closing(binary_image, footprint=np.ones((size, size)))", "full_response": "\n    import numpy as np\n    import skimage\n    size = radius * 2 + 1\n    return skimage.morphology.binary_closing(binary_image, footprint=np.ones((size, size)))", "result": "passed", "passed": true}
{"task_id": "../test_cases/binary_skeleton.ipynb", "completion": "\n    from skimage.morphology import skeletonize\n    return skeletonize(binary_image)", "full_response": "\n    from skimage.morphology import skeletonize\n    return skeletonize(binary_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/bland_altman.ipynb", "completion": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    dataframe['mean'] = (data1 + data2) / 2\n    dataframe['diff'] = data2 - data1\n    return dataframe", "full_response": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    dataframe['mean'] = (data1 + data2) / 2\n    dataframe['diff'] = data2 - data1\n    return dataframe", "result": "passed", "passed": true}
{"task_id": "../test_cases/combine_columns_of_tables.ipynb", "completion": "\n    import pandas as pd\n    return pd.merge(dataframe1, dataframe2, how='outer', on='label')", "full_response": "\n    import pandas as pd\n    return pd.merge(dataframe1, dataframe2, how='outer', on='label')", "result": "passed", "passed": true}
{"task_id": "../test_cases/convert_points_polygon.ipynb", "completion": "\n    from shapely import Polygon\n    polygon = Polygon(coordinates)\n    return polygon\n", "full_response": "\n    from shapely import Polygon\n    polygon = Polygon(coordinates)\n    return polygon\n", "result": "passed", "passed": true}
{"task_id": "../test_cases/convex_hull_measure_area.ipynb", "completion": "\n    import vedo\n    convex_hull = vedo.shapes.ConvexHull(point_cloud)\n    return convex_hull.area()", "full_response": "\n    import vedo\n    convex_hull = vedo.shapes.ConvexHull(point_cloud)\n    return convex_hull.area()", "result": "passed", "passed": true}
{"task_id": "../test_cases/convolve_images.ipynb", "completion": "\n    import scipy\n    return scipy.ndimage.convolve(image, kernel_image)\n    ", "full_response": "\n    import scipy\n    return scipy.ndimage.convolve(image, kernel_image)\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_number_of_touching_neighbors.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n\n    touch_matrix = cle.generate_touch_matrix(label_image)\n    cle.set_row(touch_matrix, 0, 0)\n    cle.set_column(touch_matrix, 0, 0)\n\n    return np.asarray(cle.sum_y_projection(touch_matrix))[0,1:].tolist()", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n\n    touch_matrix = cle.generate_touch_matrix(label_image)\n    cle.set_row(touch_matrix, 0, 0)\n    cle.set_column(touch_matrix, 0, 0)\n\n    return np.asarray(cle.sum_y_projection(touch_matrix))[0,1:].tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_objects_over_time.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import label\n    labels = [label(binary_image) for binary_image in binary_image_list]\n    return [len(np.unique(label)) - 1 for label in labels]", "full_response": "\n    import numpy as np\n    from skimage.measure import label\n    labels = [label(binary_image) for binary_image in binary_image_list]\n    return [len(np.unique(label)) - 1 for label in labels]", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_overlapping_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image_1, label_image_2, properties=('mean_intensity',))\n    return (pd.DataFrame(stats)['mean_intensity'] > 0).sum()", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image_1, label_image_2, properties=('mean_intensity',))\n    return (pd.DataFrame(stats)['mean_intensity'] > 0).sum()", "result": "passed", "passed": true}
{"task_id": "../test_cases/create_umap.ipynb", "completion": "\n    import umap\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    # no return value", "full_response": "\n    import umap\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    # no return value", "result": "passed", "passed": true}
{"task_id": "../test_cases/crop_quarter_image.ipynb", "completion": "\n    width = image.shape[1]\n    height = image.shape[0]\n\n    return image[:int(width/2),:int(height/2)]", "full_response": "\n    width = image.shape[1]\n    height = image.shape[0]\n\n    return image[:int(width/2),:int(height/2)]", "result": "passed", "passed": true}
{"task_id": "../test_cases/dataframe_column_rename.ipynb", "completion": "\n    for old_value, new_value in replacements.items():\n        df[column] = df[column].replace(old_value, new_value, regex=True)\n    return df", "full_response": "\n    for old_value, new_value in replacements.items():\n        df[column] = df[column].replace(old_value, new_value, regex=True)\n    return df", "result": "passed", "passed": true}
{"task_id": "../test_cases/deconvolve_image.ipynb", "completion": "\n    from scipy import fftpack\n\n    # adapted from: https://stackoverflow.com/questions/17473917/is-there-a-equivalent-of-scipy-signal-deconvolve-for-2d-arrays\n    star_fft = fftpack.fftshift(fftpack.fftn(image))\n    psf_fft = fftpack.fftshift(fftpack.fftn(kernel_image))\n    return fftpack.fftshift(fftpack.ifftn(fftpack.ifftshift(star_fft/psf_fft)))\n    ", "full_response": "\n    from scipy import fftpack\n\n    # adapted from: https://stackoverflow.com/questions/17473917/is-there-a-equivalent-of-scipy-signal-deconvolve-for-2d-arrays\n    star_fft = fftpack.fftshift(fftpack.fftn(image))\n    psf_fft = fftpack.fftshift(fftpack.fftn(kernel_image))\n    return fftpack.fftshift(fftpack.ifftn(fftpack.ifftshift(star_fft/psf_fft)))\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/detect_edges.ipynb", "completion": "\n    from scipy.ndimage import sobel\n    filtered_image = sobel(image)\n    return filtered_image", "full_response": "\n    from scipy.ndimage import sobel\n    filtered_image = sobel(image)\n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/detect_ellipse.ipynb", "completion": "\n    from skimage.transform import hough_ellipse\n    result = hough_ellipse(image,  accuracy=5, threshold=10)\n    result.sort(order='accumulator')\n    \n    # Estimated parameters for the ellipse\n    best = list(result[-1])\n    yc, xc, a, b = (int(round(x)) for x in best[1:5])\n    \n    return yc, xc", "full_response": "\n    from skimage.transform import hough_ellipse\n    result = hough_ellipse(image,  accuracy=5, threshold=10)\n    result.sort(order='accumulator')\n    \n    # Estimated parameters for the ellipse\n    best = list(result[-1])\n    yc, xc, a, b = (int(round(x)) for x in best[1:5])\n    \n    return yc, xc", "result": "passed", "passed": true}
{"task_id": "../test_cases/distance_between_maxima.ipynb", "completion": "\n    import numpy as np\n\n    im1 = np.asarray(image1)\n    im2 = np.asarray(image2)\n\n    x1,y1 = np.unravel_index(im1.argmax(), im1.shape)\n    x2,y2 = np.unravel_index(im2.argmax(), im2.shape)\n\n    distance = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n\n    return distance", "full_response": "\n    import numpy as np\n\n    im1 = np.asarray(image1)\n    im2 = np.asarray(image2)\n\n    x1,y1 = np.unravel_index(im1.argmax(), im1.shape)\n    x2,y2 = np.unravel_index(im2.argmax(), im2.shape)\n\n    distance = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n\n    return distance", "result": "passed", "passed": true}
{"task_id": "../test_cases/expand_labels_without_overlap.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.expand_labels(label_image, distance=radius)", "full_response": "\n    import skimage\n    return skimage.segmentation.expand_labels(label_image, distance=radius)", "result": "passed", "passed": true}
{"task_id": "../test_cases/extract_surface_measure_area.ipynb", "completion": "\n    import vedo\n    volume = vedo.Volume(binary_volume_image)\n    iso_surface = volume.isosurface()\n    return iso_surface.area()", "full_response": "\n    import vedo\n    volume = vedo.Volume(binary_volume_image)\n    iso_surface = volume.isosurface()\n    return iso_surface.area()", "result": "passed", "passed": true}
{"task_id": "../test_cases/fft_spectrum.ipynb", "completion": "\n        import numpy as np\n    \n        # computing padding tuple:\n        pad_width = ((padding, padding),)*nd_image.ndim\n    \n        # Padding:\n        image_padded = np.pad(nd_image, pad_width=pad_width, mode='symmetric')\n        \n        # prepare the apodization window in 1D:\n        from scipy import signal\n        window_tuple = (signal.windows.hamming(length+2*padding) for length in nd_image.shape)\n        \n        # prepare the apodization window in nD:\n        import functools\n        window = functools.reduce(np.multiply.outer, window_tuple)\n        \n        # Apodize:\n        image_padded_apodized = window*image_padded\n    \n        # Compute the Fourier transform of the image:\n        image_fft = np.fft.fftn(image_padded_apodized)\n        \n        # Shift the zero-frequency component to the center of the spectrum:\n        image_fft_shifted = np.fft.fftshift(image_fft)\n        \n        # Compute the magnitude spectrum:\n        magnitude_spectrum = np.log1p(np.abs(image_fft_shifted))\n            \n        return(magnitude_spectrum)\n    \n    import numpy as np   \n\n    # Test image:\n    image = np.ones((5, 6, 7), dtype=np.int16)\n\n    # Padding:\n    padding_width = 10\n\n    # running the candidate function:\n    magnitude_spectrum_candidate = candidate(image, padding_width)\n    \n    # Reference implementation:\n    magnitude_spectrum_reference = fft_spectrum_reference(image, padding_width)\n    \n    assert np.allclose(magnitude_spectrum_candidate, magnitude_spectrum_reference)", "full_response": "\n        import numpy as np\n    \n        # computing padding tuple:\n        pad_width = ((padding, padding),)*nd_image.ndim\n    \n        # Padding:\n        image_padded = np.pad(nd_image, pad_width=pad_width, mode='symmetric')\n        \n        # prepare the apodization window in 1D:\n        from scipy import signal\n        window_tuple = (signal.windows.hamming(length+2*padding) for length in nd_image.shape)\n        \n        # prepare the apodization window in nD:\n        import functools\n        window = functools.reduce(np.multiply.outer, window_tuple)\n        \n        # Apodize:\n        image_padded_apodized = window*image_padded\n    \n        # Compute the Fourier transform of the image:\n        image_fft = np.fft.fftn(image_padded_apodized)\n        \n        # Shift the zero-frequency component to the center of the spectrum:\n        image_fft_shifted = np.fft.fftshift(image_fft)\n        \n        # Compute the magnitude spectrum:\n        magnitude_spectrum = np.log1p(np.abs(image_fft_shifted))\n            \n        return(magnitude_spectrum)\n    \n    import numpy as np   \n\n    # Test image:\n    image = np.ones((5, 6, 7), dtype=np.int16)\n\n    # Padding:\n    padding_width = 10\n\n    # running the candidate function:\n    magnitude_spectrum_candidate = candidate(image, padding_width)\n    \n    # Reference implementation:\n    magnitude_spectrum_reference = fft_spectrum_reference(image, padding_width)\n    \n    assert np.allclose(magnitude_spectrum_candidate, magnitude_spectrum_reference)", "result": "timed out", "passed": false}
{"task_id": "../test_cases/find_closest_neighbors.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import centroid\n    \n    # Identify all centroid locations\n    label_count = np.max(label_image)\n    centroids = {}\n    for i in range(1, label_count + 1):\n        binary_image = (label_image == i)\n        centroids[i] = centroid(binary_image)\n    \n    # Find the closest top n\n    distances = [(other, np.linalg.norm(centroids[target_label] - centroids[other])) for other in centroids.keys() if other != target_label]\n    sorted_distances = sorted(distances, key = lambda pair: pair[1])\n    topn = [label for label, _ in sorted_distances[:n]]\n\n    return topn", "full_response": "\n    import numpy as np\n    from skimage.measure import centroid\n    \n    # Identify all centroid locations\n    label_count = np.max(label_image)\n    centroids = {}\n    for i in range(1, label_count + 1):\n        binary_image = (label_image == i)\n        centroids[i] = centroid(binary_image)\n    \n    # Find the closest top n\n    distances = [(other, np.linalg.norm(centroids[target_label] - centroids[other])) for other in centroids.keys() if other != target_label]\n    sorted_distances = sorted(distances, key = lambda pair: pair[1])\n    topn = [label for label, _ in sorted_distances[:n]]\n\n    return topn", "result": "passed", "passed": true}
{"task_id": "../test_cases/fit_circle.ipynb", "completion": "\n    import circle_fit as cf\n    xc, yc, r, _ = cf.least_squares_circle(list_of_2d_points)\n    return xc,yc,r", "full_response": "\n    import circle_fit as cf\n    xc, yc, r, _ = cf.least_squares_circle(list_of_2d_points)\n    return xc,yc,r", "result": "passed", "passed": true}
{"task_id": "../test_cases/fit_gaussian_to_spot.ipynb", "completion": "\n    import numpy as np\n    import scipy \n\n    image = np.asarray(image)\n    num_px = image.shape[0]\n    [xx, yy] = np.meshgrid(np.arange(0,num_px), np.arange(0,num_px))\n\n\n    def twoDGauss(x,y,ux,uy,sigma):\n        '''\n        Creates theoretical normalized 2D gaussian spot, centered around (ux,uy) \n        with standard deviation sigma, on grid specified by x and y\n        '''\n        p = 1/(2*np.pi*sigma**2) * np.exp(- ( (x-ux)**2+(y-uy)**2 ) / (2*sigma**2))\n        return p\n\n    def expected(x,y,params):   \n        '''\n        Creates simulated realistic Gaussian spot on x-y grid, with following\n        parameters = [x0,y0,sigma,bg,N], speficically:\n            - x0 = x-position of gaussian (px coord., first pixel is (0,0))\n            - y0 = y-positoin of gaussian (px coord.)\n            - sigma = stdev of gaussian (px coord)\n            - bg = number of photons in background\n            - N = number of photons in spot\n        '''\n        E = params[4] * twoDGauss(x,y,params[0],params[1],params[2]) + params[3]\n        return E\n\n    def SSE(params):\n        '''\n        Calculates sum-of-squared errors difference between 'image' and expected Gaussian defined by 'params'\n        This is essentially the cost-function that is minimized in the fit\n        '''\n        Expec = expected(xx,yy,params)\n        sse = np.sum((image -  Expec)**2)\n        return sse\n\n\n    #guess fit parameters:\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    sigma_guess = 2                 #assume sigma is 2 pixels\n    bg_guess = (np.sum(image) - np.sum(image[1:-1,1:-1]))/(4*num_px-4)           \n                                    #average of border pixels\n    N_guess = np.sum(image) - bg_guess * num_px**2\n                                    #sum of intensities, minus background\n    params_guess = [x_guess,x_guess,sigma_guess, bg_guess, N_guess]\n\n    #perform the fit\n    param = scipy.optimize.fmin(func=SSE,x0=params_guess, maxiter=10000,maxfun=10000,ftol=1e-5,disp=0)\n\n    xc_fit      = param[0]  #fitted x-position\n    yc_fit      = param[1]  #fitted y-position\n    sigma_fit   = param[2]  #fitted sigma\n\n    return (xc_fit, yc_fit, sigma_fit)", "full_response": "\n    import numpy as np\n    import scipy \n\n    image = np.asarray(image)\n    num_px = image.shape[0]\n    [xx, yy] = np.meshgrid(np.arange(0,num_px), np.arange(0,num_px))\n\n\n    def twoDGauss(x,y,ux,uy,sigma):\n        '''\n        Creates theoretical normalized 2D gaussian spot, centered around (ux,uy) \n        with standard deviation sigma, on grid specified by x and y\n        '''\n        p = 1/(2*np.pi*sigma**2) * np.exp(- ( (x-ux)**2+(y-uy)**2 ) / (2*sigma**2))\n        return p\n\n    def expected(x,y,params):   \n        '''\n        Creates simulated realistic Gaussian spot on x-y grid, with following\n        parameters = [x0,y0,sigma,bg,N], speficically:\n            - x0 = x-position of gaussian (px coord., first pixel is (0,0))\n            - y0 = y-positoin of gaussian (px coord.)\n            - sigma = stdev of gaussian (px coord)\n            - bg = number of photons in background\n            - N = number of photons in spot\n        '''\n        E = params[4] * twoDGauss(x,y,params[0],params[1],params[2]) + params[3]\n        return E\n\n    def SSE(params):\n        '''\n        Calculates sum-of-squared errors difference between 'image' and expected Gaussian defined by 'params'\n        This is essentially the cost-function that is minimized in the fit\n        '''\n        Expec = expected(xx,yy,params)\n        sse = np.sum((image -  Expec)**2)\n        return sse\n\n\n    #guess fit parameters:\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    sigma_guess = 2                 #assume sigma is 2 pixels\n    bg_guess = (np.sum(image) - np.sum(image[1:-1,1:-1]))/(4*num_px-4)           \n                                    #average of border pixels\n    N_guess = np.sum(image) - bg_guess * num_px**2\n                                    #sum of intensities, minus background\n    params_guess = [x_guess,x_guess,sigma_guess, bg_guess, N_guess]\n\n    #perform the fit\n    param = scipy.optimize.fmin(func=SSE,x0=params_guess, maxiter=10000,maxfun=10000,ftol=1e-5,disp=0)\n\n    xc_fit      = param[0]  #fitted x-position\n    yc_fit      = param[1]  #fitted y-position\n    sigma_fit   = param[2]  #fitted sigma\n\n    return (xc_fit, yc_fit, sigma_fit)", "result": "passed", "passed": true}
{"task_id": "../test_cases/flow_field_deformation.ipynb", "completion": "\n    import SimpleITK as sitk\n\n    target = sitk.GetImageFromArray(target)\n\n    displacement = sitk.DisplacementFieldTransform(2)\n    field_size = list(flow_field.shape[:2])\n    field_origin = [0, 0]\n    field_spacing = [1.0, 1.0]\n    field_direction = [1, 0, 0, 1]  # direction cosine matrix (row major order)\n\n    # Concatenate all the information into a single list\n    displacement.SetFixedParameters(\n        field_size + field_origin + field_spacing + field_direction\n    )\n    # Set the interpolator to nearest neighbor\n    displacement.SetInterpolator(sitk.sitkNearestNeighbor)\n\n    originalDisplacements = flow_field.reshape((-1, 2)).flatten()\n    displacement.SetParameters(originalDisplacements)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetTransform(displacement)\n    resampler.SetReferenceImage(target)\n    resampled = resampler.Execute(target)\n\n    return sitk.GetArrayFromImage(resampled)", "full_response": "\n    import SimpleITK as sitk\n\n    target = sitk.GetImageFromArray(target)\n\n    displacement = sitk.DisplacementFieldTransform(2)\n    field_size = list(flow_field.shape[:2])\n    field_origin = [0, 0]\n    field_spacing = [1.0, 1.0]\n    field_direction = [1, 0, 0, 1]  # direction cosine matrix (row major order)\n\n    # Concatenate all the information into a single list\n    displacement.SetFixedParameters(\n        field_size + field_origin + field_spacing + field_direction\n    )\n    # Set the interpolator to nearest neighbor\n    displacement.SetInterpolator(sitk.sitkNearestNeighbor)\n\n    originalDisplacements = flow_field.reshape((-1, 2)).flatten()\n    displacement.SetParameters(originalDisplacements)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetTransform(displacement)\n    resampler.SetReferenceImage(target)\n    resampled = resampler.Execute(target)\n\n    return sitk.GetArrayFromImage(resampled)", "result": "passed", "passed": true}
{"task_id": "../test_cases/generate_image_histogram.ipynb", "completion": "\n    import numpy as np\n    return np.histogram(image,bins=num_bins)[0]", "full_response": "\n    import numpy as np\n    return np.histogram(image,bins=num_bins)[0]", "result": "passed", "passed": true}
{"task_id": "../test_cases/identify_centroids.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import centroid\n    n = np.max(label_image)\n    out = {}\n    for i in range(1, n + 1):\n        binary_image = (label_image == i)\n        out[i] = centroid(binary_image)\n    return out", "full_response": "\n    import numpy as np\n    from skimage.measure import centroid\n    n = np.max(label_image)\n    out = {}\n    for i in range(1, n + 1):\n        binary_image = (label_image == i)\n        out[i] = centroid(binary_image)\n    return out", "result": "passed", "passed": true}
{"task_id": "../test_cases/interpolate_stack.ipynb", "completion": "\n    import numpy as np\n\n    return np.linspace(start_slice, end_slice, num)", "full_response": "\n    import numpy as np\n\n    return np.linspace(start_slice, end_slice, num)", "result": "passed", "passed": true}
{"task_id": "../test_cases/label_binary_image_and_count_labels.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    label_image = skimage.measure.label(binary_image)\n\n    return len(np.unique(label_image)) - 1", "full_response": "\n    import skimage\n    import numpy as np\n    label_image = skimage.measure.label(binary_image)\n\n    return len(np.unique(label_image)) - 1", "result": "passed", "passed": true}
{"task_id": "../test_cases/label_sequentially.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.relabel_sequential(label_image)[0]", "full_response": "\n    import skimage\n    return skimage.segmentation.relabel_sequential(label_image)[0]", "result": "passed", "passed": true}
{"task_id": "../test_cases/linear_intensity_profile.ipynb", "completion": "\n    from skimage.measure import profile_line\n    return profile_line(image, starting_point, ending_point)", "full_response": "\n    from skimage.measure import profile_line\n    return profile_line(image, starting_point, ending_point)", "result": "passed", "passed": true}
{"task_id": "../test_cases/list_image_files_in_folder.ipynb", "completion": "\n    import os\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    return [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]", "full_response": "\n    import os\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    return [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]", "result": "passed", "passed": true}
{"task_id": "../test_cases/load_tif_and_output_rgb.ipynb", "completion": "\n    from cv2 import imread, cvtColor, COLOR_BGR2RGB\n    image = imread(path_to_tif)\n    return cvtColor(image, COLOR_BGR2RGB)", "full_response": "\n    from cv2 import imread, cvtColor, COLOR_BGR2RGB\n    image = imread(path_to_tif)\n    return cvtColor(image, COLOR_BGR2RGB)", "result": "failed: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n", "passed": false}
{"task_id": "../test_cases/local_maxima_from_distance_transform.ipynb", "completion": "\n    import scipy.ndimage as ndi\n    import skimage.feature as skf\n    \n    distance_transform = ndi.distance_transform_edt(binary_image)\n    \n    image_max = ndi.maximum_filter(distance_transform, size=nms_window, mode='constant')\n    \n    # suppress non-maxima values by setting them to -1\n    mask = distance_transform == image_max\n    image_max[~mask] = -1\n    \n    local_maxima = skf.peak_local_max(image_max)\n\n    return local_maxima.tolist()", "full_response": "\n    import scipy.ndimage as ndi\n    import skimage.feature as skf\n    \n    distance_transform = ndi.distance_transform_edt(binary_image)\n    \n    image_max = ndi.maximum_filter(distance_transform, size=nms_window, mode='constant')\n    \n    # suppress non-maxima values by setting them to -1\n    mask = distance_transform == image_max\n    image_max[~mask] = -1\n    \n    local_maxima = skf.peak_local_max(image_max)\n\n    return local_maxima.tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/map_pixel_count_of_labels.ipynb", "completion": "\n    import pyclesperanto_prototype as cle\n    return cle.pixel_count_map(label_image)", "full_response": "\n    import pyclesperanto_prototype as cle\n    return cle.pixel_count_map(label_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/mask_image.ipynb", "completion": "\n    import numpy as np\n    return image * mask", "full_response": "\n    import numpy as np\n    return image * mask", "result": "passed", "passed": true}
{"task_id": "../test_cases/maximum_intensity_projection.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).max(axis=0)", "full_response": "\n    import numpy as np\n    return np.asarray(image).max(axis=0)", "result": "passed", "passed": true}
{"task_id": "../test_cases/mean_squared_error.ipynb", "completion": "\n    return ((image1 - image2)**2).mean()\n    # adapted from : https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy", "full_response": "\n    return ((image1 - image2)**2).mean()\n    # adapted from : https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy", "result": "passed", "passed": true}
{"task_id": "../test_cases/mean_std_column.ipynb", "completion": "\n    import numpy as np\n    data = dataframe[column]\n    return np.mean(data), np.std(data)", "full_response": "\n    import numpy as np\n    data = dataframe[column]\n    return np.mean(data), np.std(data)", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_aspect_ratio_of_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = pd.DataFrame(skimage.measure.regionprops_table(label_image, properties=('minor_axis_length', 'major_axis_length')))\n    stats['aspect_ratio'] = stats['major_axis_length'] / stats['minor_axis_length']\n    return stats", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = pd.DataFrame(skimage.measure.regionprops_table(label_image, properties=('minor_axis_length', 'major_axis_length')))\n    stats['aspect_ratio'] = stats['major_axis_length'] / stats['minor_axis_length']\n    return stats", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_intensity_of_labels.ipynb", "completion": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image, intensity_image)\n    return [s.mean_intensity for s in stats]", "full_response": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image, intensity_image)\n    return [s.mean_intensity for s in stats]", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_intensity_over_time.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image_list).mean(axis=(1,2)).tolist()", "full_response": "\n    import numpy as np\n    return np.asarray(image_list).mean(axis=(1,2)).tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_mean_image_intensity.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).mean()", "full_response": "\n    import numpy as np\n    return np.asarray(image).mean()", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_pixel_count_of_labels.ipynb", "completion": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image)\n    return [s.area for s in stats]", "full_response": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image)\n    return [s.area for s in stats]", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_properties_of_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\n    return pd.DataFrame(stats)", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\n    return pd.DataFrame(stats)", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_image_read_voxel_size.ipynb", "completion": "\n    from aicsimageio import AICSImage\n    aics_image = AICSImage(image_filename)\n\n    return aics_image.physical_pixel_sizes.Z, \\\n            aics_image.physical_pixel_sizes.Y, \\\n            aics_image.physical_pixel_sizes.X", "full_response": "\n    from aicsimageio import AICSImage\n    aics_image = AICSImage(image_filename)\n\n    return aics_image.physical_pixel_sizes.Z, \\\n            aics_image.physical_pixel_sizes.Y, \\\n            aics_image.physical_pixel_sizes.X", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_image_return_dimensions.ipynb", "completion": "\n    from skimage.io import imread\n    image = imread(image_file_location)\n    return image.shape", "full_response": "\n    from skimage.io import imread\n    image = imread(image_file_location)\n    return image.shape", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_nifti_image.ipynb", "completion": "\n    \n    import nibabel as nib\n    import numpy as nb\n\n    img = nib.load(image_file_location)\n    data = img.get_fdata()\n    return(data)", "full_response": "\n    \n    import nibabel as nib\n    import numpy as nb\n\n    img = nib.load(image_file_location)\n    data = img.get_fdata()\n    return(data)", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_zarr.ipynb", "completion": "\n    import zarr\n    array = zarr.load(zarr_file_location)\n    return array", "full_response": "\n    import zarr\n    array = zarr.load(zarr_file_location)\n    return array", "result": "passed", "passed": true}
{"task_id": "../test_cases/pair_wise_correlation_matrix.ipynb", "completion": "\n    return dataframe.corr()", "full_response": "\n    return dataframe.corr()", "result": "passed", "passed": true}
{"task_id": "../test_cases/radial_intensity_profile.ipynb", "completion": "\n    import numpy as np\n    y, x = np.indices((image.shape))\n    r = np.sqrt((x - xc)**2 + (y - yc)**2)\n    r = r.astype(int)\n    summed_values = np.bincount(r.ravel(), image.ravel())\n    number_of_pixels_at_r = np.bincount(r.ravel())\n    radial_profile = summed_values / number_of_pixels_at_r\n    return radial_profile ", "full_response": "\n    import numpy as np\n    y, x = np.indices((image.shape))\n    r = np.sqrt((x - xc)**2 + (y - yc)**2)\n    r = r.astype(int)\n    summed_values = np.bincount(r.ravel(), image.ravel())\n    number_of_pixels_at_r = np.bincount(r.ravel())\n    radial_profile = summed_values / number_of_pixels_at_r\n    return radial_profile ", "result": "passed", "passed": true}
{"task_id": "../test_cases/read_imagej_tif_metadata.ipynb", "completion": "\n    from tifffile import TiffFile\n    \n    with (TiffFile(image_filename) as tif):\n        imagej_metadata = tif.imagej_metadata\n    return imagej_metadata", "full_response": "\n    from tifffile import TiffFile\n    \n    with (TiffFile(image_filename) as tif):\n        imagej_metadata = tif.imagej_metadata\n    return imagej_metadata", "result": "passed", "passed": true}
{"task_id": "../test_cases/read_ome_metadata_from_ome_xml.ipynb", "completion": "\n    from ome_types import from_xml\n    ome = from_xml(img_path)\n    return ome.images[0]", "full_response": "\n    from ome_types import from_xml\n    ome = from_xml(img_path)\n    return ome.images[0]", "result": "failed: Could not parse XML from '../example_data/ome_xml_example.xml'", "passed": false}
{"task_id": "../test_cases/region_growing_segmentation.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.flood(image, point)", "full_response": "\n    import skimage\n    return skimage.segmentation.flood(image, point)", "result": "passed", "passed": true}
{"task_id": "../test_cases/register_timelapse.ipynb", "completion": "\n    from skimage import registration\n    import scipy.ndimage as ndi\n\n    new_video = video.copy()\n    ref_frame = new_video[-1]\n    for t in range(len(video) - 1, 0, -1):\n        mov_frame = video[t - 1]\n        shift, _, _ = registration.phase_cross_correlation(\n            ref_frame,\n            mov_frame,\n            upsample_factor=4,\n            normalization=None,\n        )\n        # replaces old ref_frame with shifted mov_frame\n        ref_frame = ndi.shift(mov_frame, shift, order=1)\n        new_video[t - 1] = ref_frame\n\n    return new_video", "full_response": "\n    from skimage import registration\n    import scipy.ndimage as ndi\n\n    new_video = video.copy()\n    ref_frame = new_video[-1]\n    for t in range(len(video) - 1, 0, -1):\n        mov_frame = video[t - 1]\n        shift, _, _ = registration.phase_cross_correlation(\n            ref_frame,\n            mov_frame,\n            upsample_factor=4,\n            normalization=None,\n        )\n        # replaces old ref_frame with shifted mov_frame\n        ref_frame = ndi.shift(mov_frame, shift, order=1)\n        new_video[t - 1] = ref_frame\n\n    return new_video", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_labels_on_edges.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.clear_border(label_image)", "full_response": "\n    import skimage\n    return skimage.segmentation.clear_border(label_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_noise_edge_preserving.ipynb", "completion": "\n    from scipy.ndimage import median_filter\n    filtered_image = median_filter(image, size=radius * 2 + 1)\n    return filtered_image", "full_response": "\n    from scipy.ndimage import median_filter\n    filtered_image = median_filter(image, size=radius * 2 + 1)\n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_small_labels.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.exclude_small_labels(label_image, maximum_size=size_threshold))", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.exclude_small_labels(label_image, maximum_size=size_threshold))", "result": "passed", "passed": true}
{"task_id": "../test_cases/reshape_array.ipynb", "completion": "\n    import numpy as np\n    \n    array = np.asarray(image)\n    array = np.transpose(array, axes=[2, 0, 1])\n    return array", "full_response": "\n    import numpy as np\n    \n    array = np.asarray(image)\n    array = np.transpose(array, axes=[2, 0, 1])\n    return array", "result": "passed", "passed": true}
{"task_id": "../test_cases/return_hello_world.ipynb", "completion": "\n    return \"hello world\"", "full_response": "\n    return \"hello world\"", "result": "passed", "passed": true}
{"task_id": "../test_cases/rgb_to_grey_image_transform.ipynb", "completion": "\n    rgb_sum = r + g + b\n    r = r / rgb_sum\n    g = g / rgb_sum\n    b = b / rgb_sum\n    \n    import numpy as np\n    channel_r = rgb_image[...,0]\n    channel_g = rgb_image[...,1]\n    channel_b = rgb_image[...,2]\n    grey_image = channel_r * r + \\\n                 channel_g * g + \\\n                 channel_b * b\n    \n    return grey_image", "full_response": "\n    rgb_sum = r + g + b\n    r = r / rgb_sum\n    g = g / rgb_sum\n    b = b / rgb_sum\n    \n    import numpy as np\n    channel_r = rgb_image[...,0]\n    channel_g = rgb_image[...,1]\n    channel_b = rgb_image[...,2]\n    grey_image = channel_r * r + \\\n                 channel_g * g + \\\n                 channel_b * b\n    \n    return grey_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/roi_imagej_to_ezomero.ipynb", "completion": "\n    list_of_tuples = list(dataframe.itertuples(index=False, name=None))\n    return list_of_tuples", "full_response": "\n    list_of_tuples = list(dataframe.itertuples(index=False, name=None))\n    return list_of_tuples", "result": "passed", "passed": true}
{"task_id": "../test_cases/rotate_image_by_90_degrees.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.rotate(image, angle_around_z_in_degrees=90))", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.rotate(image, angle_around_z_in_degrees=90))", "result": "passed", "passed": true}
{"task_id": "../test_cases/save_image_with_voxel_size.ipynb", "completion": "\n    from aicsimageio import AICSImage \n    from aicsimageio.types import PhysicalPixelSizes\n    from tempfile import tempdir\n    import os \n\n    image = AICSImage(image)\n    AICSImage.physical_pixel_sizes = PhysicalPixelSizes(Z=vz,Y=vy,X=vx)\n    img_path = os.path.join(tempdir, 'voxel_save_test.ome.tiff')\n    image.save(img_path)\n    return img_path", "full_response": "\n    from aicsimageio import AICSImage \n    from aicsimageio.types import PhysicalPixelSizes\n    from tempfile import tempdir\n    import os \n\n    image = AICSImage(image)\n    AICSImage.physical_pixel_sizes = PhysicalPixelSizes(Z=vz,Y=vy,X=vx)\n    img_path = os.path.join(tempdir, 'voxel_save_test.ome.tiff')\n    image.save(img_path)\n    return img_path", "result": "passed", "passed": true}
{"task_id": "../test_cases/scale_image_affine_transform.ipynb", "completion": "\n    from pyclesperanto_prototype import AffineTransform3D\n    import pyclesperanto_prototype as cle \n    import numpy as np\n    \n    output_img_shape =  (image.shape[0]*sy, image.shape[1]*sx)\n\n    transform = AffineTransform3D()\n    transform.center(image.shape)\n    transform.scale(scale_x = sx, scale_y = sy)\n    transform.center(output_img_shape,undo=True)\n    scaled_image = np.array(cle.affine_transform(image,transform=transform,auto_size=True))\n    return scaled_image, transform._matrix", "full_response": "\n    from pyclesperanto_prototype import AffineTransform3D\n    import pyclesperanto_prototype as cle \n    import numpy as np\n    \n    output_img_shape =  (image.shape[0]*sy, image.shape[1]*sx)\n\n    transform = AffineTransform3D()\n    transform.center(image.shape)\n    transform.scale(scale_x = sx, scale_y = sy)\n    transform.center(output_img_shape,undo=True)\n    scaled_image = np.array(cle.affine_transform(image,transform=transform,auto_size=True))\n    return scaled_image, transform._matrix", "result": "passed", "passed": true}
{"task_id": "../test_cases/select_coexpressing_cells.ipynb", "completion": "\n    import numpy as np\n    import pandas as pd\n    from skimage.measure import regionprops_table\n\n    df = pd.DataFrame(\n        regionprops_table(label_image, image, properties=(\"label\", \"area\", \"intensity_mean\"))\n    )\n    mean_cols = [c for c in df.columns if c.startswith(\"intensity_mean\")]\n    sum_cols = [f\"intensity_sum-{i}\" for i in range(len(mean_cols))]\n    \n    df[sum_cols] = df[mean_cols] * df[\"area\"].to_numpy()\n    \n    selected_ids = df.loc[(df[sum_cols] > threshold).all(axis=1), \"label\"].to_numpy()\n    \n    below_threshold_mask = np.isin(label_image, selected_ids, invert=False)\n    filtered_labels = label_image * below_threshold_mask\n\n    return filtered_labels", "full_response": "\n    import numpy as np\n    import pandas as pd\n    from skimage.measure import regionprops_table\n\n    df = pd.DataFrame(\n        regionprops_table(label_image, image, properties=(\"label\", \"area\", \"intensity_mean\"))\n    )\n    mean_cols = [c for c in df.columns if c.startswith(\"intensity_mean\")]\n    sum_cols = [f\"intensity_sum-{i}\" for i in range(len(mean_cols))]\n    \n    df[sum_cols] = df[mean_cols] * df[\"area\"].to_numpy()\n    \n    selected_ids = df.loc[(df[sum_cols] > threshold).all(axis=1), \"label\"].to_numpy()\n    \n    below_threshold_mask = np.isin(label_image, selected_ids, invert=False)\n    filtered_labels = label_image * below_threshold_mask\n\n    return filtered_labels", "result": "passed", "passed": true}
{"task_id": "../test_cases/stack_and_merge.ipynb", "completion": "\n    import numpy as np\n    stacked_image = np.stack((image1, image2), axis=0)\n    stitched_image = np.concatenate((stacked_image, image3), axis=2)\n    return stitched_image.shape", "full_response": "\n    import numpy as np\n    stacked_image = np.stack((image1, image2), axis=0)\n    stitched_image = np.concatenate((stacked_image, image3), axis=2)\n    return stitched_image.shape", "result": "passed", "passed": true}
{"task_id": "../test_cases/subsample_image.ipynb", "completion": "\n    return image[::n,::n]", "full_response": "\n    return image[::n,::n]", "result": "passed", "passed": true}
{"task_id": "../test_cases/subtract_background_tophat.ipynb", "completion": "\n    from skimage.morphology import white_tophat\n    from skimage.morphology import disk\n    filtered_image = white_tophat(image, footprint=disk(radius))\n    \n    return filtered_image", "full_response": "\n    from skimage.morphology import white_tophat\n    from skimage.morphology import disk\n    filtered_image = white_tophat(image, footprint=disk(radius))\n    \n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/sum_images.ipynb", "completion": "\n    return image1 + image2", "full_response": "\n    return image1 + image2", "result": "passed", "passed": true}
{"task_id": "../test_cases/sum_intensity_projection.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).sum(axis=0)", "full_response": "\n    import numpy as np\n    return np.asarray(image).sum(axis=0)", "result": "passed", "passed": true}
{"task_id": "../test_cases/tiled_image_processing.ipynb", "completion": "\n    import dask\n    import dask.array as da\n\n    tiles = da.from_array(image, chunks=(tile_size, tile_size))\n    \n    def procedure(image):\n        from scipy.ndimage import maximum_filter\n        return maximum_filter(image, size=radius*2+1)\n\n    # setup a lazy result (not computed yet)\n    tile_map = da.map_blocks(procedure, tiles)\n\n    # actually apply filter\n    result = tile_map.compute()\n\n    return result", "full_response": "\n    import dask\n    import dask.array as da\n\n    tiles = da.from_array(image, chunks=(tile_size, tile_size))\n    \n    def procedure(image):\n        from scipy.ndimage import maximum_filter\n        return maximum_filter(image, size=radius*2+1)\n\n    # setup a lazy result (not computed yet)\n    tile_map = da.map_blocks(procedure, tiles)\n\n    # actually apply filter\n    result = tile_map.compute()\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/translate_3d_image_along_vector.ipynb", "completion": "\n    from pyclesperanto_prototype import translate\n\n    # translate 3d image along t_x, t_y and t_z\n    return translate(image, translate_x = t_x, translate_y = t_y, translate_z = t_z)", "full_response": "\n    from pyclesperanto_prototype import translate\n\n    # translate 3d image along t_x, t_y and t_z\n    return translate(image, translate_x = t_x, translate_y = t_y, translate_z = t_z)", "result": "passed", "passed": true}
{"task_id": "../test_cases/transpose_image_axes.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).T", "full_response": "\n    import numpy as np\n    return np.asarray(image).T", "result": "passed", "passed": true}
{"task_id": "../test_cases/t_test.ipynb", "completion": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    return scipy.stats.ttest_rel(data1, data2)[1]\n    ", "full_response": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    return scipy.stats.ttest_rel(data1, data2)[1]\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_batch_process_folder_count_labels.ipynb", "completion": "\n    import os\n    from skimage.io import imread\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]\n    result = {}\n\n    for filename in file_list:\n        image = imread(folder_location + filename)\n\n        labels = np.unique(image).tolist()\n        labels.pop(0)\n\n        count = len(labels)\n\n        result[filename] = count\n\n    return result", "full_response": "\n    import os\n    from skimage.io import imread\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]\n    result = {}\n\n    for filename in file_list:\n        image = imread(folder_location + filename)\n\n        labels = np.unique(image).tolist()\n        labels.pop(0)\n\n        count = len(labels)\n\n        result[filename] = count\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_batch_process_folder_measure_intensity.ipynb", "completion": "\n    import os\n    import pandas as pd\n    from skimage.io import imread\n    from skimage.measure import regionprops\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(image_folder_location) if str(fn[-4:]) in supported_fileendings]\n\n    result = []\n\n    for filename in file_list:\n        image = imread(image_folder_location + filename)[...,0]\n        labels = imread(labels_folder_location + filename)\n\n        stats = regionprops(labels, intensity_image=image)\n\n        for s in stats:\n            result.append({\n                \"filename\":filename,\n                \"label\":s.label,\n                \"min_intensity\":s.min_intensity,\n                \"mean_intensity\":s.mean_intensity,\n                \"max_intensity\":s.max_intensity,\n            })\n\n    return pd.DataFrame(result)", "full_response": "\n    import os\n    import pandas as pd\n    from skimage.io import imread\n    from skimage.measure import regionprops\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(image_folder_location) if str(fn[-4:]) in supported_fileendings]\n\n    result = []\n\n    for filename in file_list:\n        image = imread(image_folder_location + filename)[...,0]\n        labels = imread(labels_folder_location + filename)\n\n        stats = regionprops(labels, intensity_image=image)\n\n        for s in stats:\n            result.append({\n                \"filename\":filename,\n                \"label\":s.label,\n                \"min_intensity\":s.min_intensity,\n                \"mean_intensity\":s.mean_intensity,\n                \"max_intensity\":s.max_intensity,\n            })\n\n    return pd.DataFrame(result)", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segmentation_counting.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    average_intensity = np.asarray(image).mean()\n    binary = image > average_intensity\n    labels = skimage.measure.label(binary)\n    return labels.max()", "full_response": "\n    import skimage\n    import numpy as np\n    average_intensity = np.asarray(image).mean()\n    binary = image > average_intensity\n    labels = skimage.measure.label(binary)\n    return labels.max()", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segmentation_measurement_summary.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n    label_image = skimage.measure.label(binary_image)\n    stats = skimage.measure.regionprops(label_image)\n    areas = [s.area for s in stats]\n    return np.mean(areas)", "full_response": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n    label_image = skimage.measure.label(binary_image)\n    stats = skimage.measure.regionprops(label_image)\n    areas = [s.area for s in stats]\n    return np.mean(areas)", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segment_measure_umap.ipynb", "completion": "\n    import numpy as np\n    import pandas as pd\n    import umap\n    from skimage.measure import label, regionprops_table\n\n    image = np.asarray(image)\n\n    # segment\n    binary = image > 0.5 * image.max()\n    labels = label(binary)\n\n    # measure\n    dataframe = pd.DataFrame(regionprops_table(labels, intensity_image=image, \n                                              properties=['area', 'perimeter', 'mean_intensity', \n                                                          'minor_axis_length', 'major_axis_length']))\n\n    # append UMAP\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    return dataframe", "full_response": "\n    import numpy as np\n    import pandas as pd\n    import umap\n    from skimage.measure import label, regionprops_table\n\n    image = np.asarray(image)\n\n    # segment\n    binary = image > 0.5 * image.max()\n    labels = label(binary)\n\n    # measure\n    dataframe = pd.DataFrame(regionprops_table(labels, intensity_image=image, \n                                              properties=['area', 'perimeter', 'mean_intensity', \n                                                          'minor_axis_length', 'major_axis_length']))\n\n    # append UMAP\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    return dataframe", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_watershed_segmentation_correction_measurement.ipynb", "completion": "\n    import skimage\n    blurred = skimage.filters.gaussian(image * 255, sigma=1)\n    minima = skimage.morphology.local_minima(blurred)\n    spots = skimage.measure.label(minima)\n    labels = skimage.segmentation.watershed(blurred, spots)\n    labels_without_border = skimage.segmentation.clear_border(labels)   \n    binary = labels_without_border > 0\n    return binary.sum()", "full_response": "\n    import skimage\n    blurred = skimage.filters.gaussian(image * 255, sigma=1)\n    minima = skimage.morphology.local_minima(blurred)\n    spots = skimage.measure.label(minima)\n    labels = skimage.segmentation.watershed(blurred, spots)\n    labels_without_border = skimage.segmentation.clear_border(labels)   \n    binary = labels_without_border > 0\n    return binary.sum()", "result": "passed", "passed": true}
{"task_id": "../test_cases/apply_otsu_threshold_and_count_positive_pixels.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n\n    result = np.sum(binary_image)\n\n    return result", "full_response": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n\n    result = np.sum(binary_image)\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/binary_closing.ipynb", "completion": "\n    import numpy as np\n    import skimage\n    size = radius * 2 + 1\n    return skimage.morphology.binary_closing(binary_image, footprint=np.ones((size, size)))", "full_response": "\n    import numpy as np\n    import skimage\n    size = radius * 2 + 1\n    return skimage.morphology.binary_closing(binary_image, footprint=np.ones((size, size)))", "result": "passed", "passed": true}
{"task_id": "../test_cases/binary_skeleton.ipynb", "completion": "\n    from skimage.morphology import skeletonize\n    return skeletonize(binary_image)", "full_response": "\n    from skimage.morphology import skeletonize\n    return skeletonize(binary_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/bland_altman.ipynb", "completion": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    dataframe['mean'] = (data1 + data2) / 2\n    dataframe['diff'] = data2 - data1\n    return dataframe", "full_response": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    dataframe['mean'] = (data1 + data2) / 2\n    dataframe['diff'] = data2 - data1\n    return dataframe", "result": "passed", "passed": true}
{"task_id": "../test_cases/combine_columns_of_tables.ipynb", "completion": "\n    import pandas as pd\n    return pd.merge(dataframe1, dataframe2, how='outer', on='label')", "full_response": "\n    import pandas as pd\n    return pd.merge(dataframe1, dataframe2, how='outer', on='label')", "result": "passed", "passed": true}
{"task_id": "../test_cases/convert_points_polygon.ipynb", "completion": "\n    from shapely import Polygon\n    polygon = Polygon(coordinates)\n    return polygon\n", "full_response": "\n    from shapely import Polygon\n    polygon = Polygon(coordinates)\n    return polygon\n", "result": "passed", "passed": true}
{"task_id": "../test_cases/convex_hull_measure_area.ipynb", "completion": "\n    import vedo\n    convex_hull = vedo.shapes.ConvexHull(point_cloud)\n    return convex_hull.area()", "full_response": "\n    import vedo\n    convex_hull = vedo.shapes.ConvexHull(point_cloud)\n    return convex_hull.area()", "result": "passed", "passed": true}
{"task_id": "../test_cases/convolve_images.ipynb", "completion": "\n    import scipy\n    return scipy.ndimage.convolve(image, kernel_image)\n    ", "full_response": "\n    import scipy\n    return scipy.ndimage.convolve(image, kernel_image)\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_number_of_touching_neighbors.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n\n    touch_matrix = cle.generate_touch_matrix(label_image)\n    cle.set_row(touch_matrix, 0, 0)\n    cle.set_column(touch_matrix, 0, 0)\n\n    return np.asarray(cle.sum_y_projection(touch_matrix))[0,1:].tolist()", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n\n    touch_matrix = cle.generate_touch_matrix(label_image)\n    cle.set_row(touch_matrix, 0, 0)\n    cle.set_column(touch_matrix, 0, 0)\n\n    return np.asarray(cle.sum_y_projection(touch_matrix))[0,1:].tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_objects_over_time.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import label\n    labels = [label(binary_image) for binary_image in binary_image_list]\n    return [len(np.unique(label)) - 1 for label in labels]", "full_response": "\n    import numpy as np\n    from skimage.measure import label\n    labels = [label(binary_image) for binary_image in binary_image_list]\n    return [len(np.unique(label)) - 1 for label in labels]", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_overlapping_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image_1, label_image_2, properties=('mean_intensity',))\n    return (pd.DataFrame(stats)['mean_intensity'] > 0).sum()", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image_1, label_image_2, properties=('mean_intensity',))\n    return (pd.DataFrame(stats)['mean_intensity'] > 0).sum()", "result": "passed", "passed": true}
{"task_id": "../test_cases/create_umap.ipynb", "completion": "\n    import umap\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    # no return value", "full_response": "\n    import umap\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    # no return value", "result": "passed", "passed": true}
{"task_id": "../test_cases/crop_quarter_image.ipynb", "completion": "\n    width = image.shape[1]\n    height = image.shape[0]\n\n    return image[:int(width/2),:int(height/2)]", "full_response": "\n    width = image.shape[1]\n    height = image.shape[0]\n\n    return image[:int(width/2),:int(height/2)]", "result": "passed", "passed": true}
{"task_id": "../test_cases/dataframe_column_rename.ipynb", "completion": "\n    for old_value, new_value in replacements.items():\n        df[column] = df[column].replace(old_value, new_value, regex=True)\n    return df", "full_response": "\n    for old_value, new_value in replacements.items():\n        df[column] = df[column].replace(old_value, new_value, regex=True)\n    return df", "result": "passed", "passed": true}
{"task_id": "../test_cases/deconvolve_image.ipynb", "completion": "\n    from scipy import fftpack\n\n    # adapted from: https://stackoverflow.com/questions/17473917/is-there-a-equivalent-of-scipy-signal-deconvolve-for-2d-arrays\n    star_fft = fftpack.fftshift(fftpack.fftn(image))\n    psf_fft = fftpack.fftshift(fftpack.fftn(kernel_image))\n    return fftpack.fftshift(fftpack.ifftn(fftpack.ifftshift(star_fft/psf_fft)))\n    ", "full_response": "\n    from scipy import fftpack\n\n    # adapted from: https://stackoverflow.com/questions/17473917/is-there-a-equivalent-of-scipy-signal-deconvolve-for-2d-arrays\n    star_fft = fftpack.fftshift(fftpack.fftn(image))\n    psf_fft = fftpack.fftshift(fftpack.fftn(kernel_image))\n    return fftpack.fftshift(fftpack.ifftn(fftpack.ifftshift(star_fft/psf_fft)))\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/detect_edges.ipynb", "completion": "\n    from scipy.ndimage import sobel\n    filtered_image = sobel(image)\n    return filtered_image", "full_response": "\n    from scipy.ndimage import sobel\n    filtered_image = sobel(image)\n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/detect_ellipse.ipynb", "completion": "\n    from skimage.transform import hough_ellipse\n    result = hough_ellipse(image,  accuracy=5, threshold=10)\n    result.sort(order='accumulator')\n    \n    # Estimated parameters for the ellipse\n    best = list(result[-1])\n    yc, xc, a, b = (int(round(x)) for x in best[1:5])\n    \n    return yc, xc", "full_response": "\n    from skimage.transform import hough_ellipse\n    result = hough_ellipse(image,  accuracy=5, threshold=10)\n    result.sort(order='accumulator')\n    \n    # Estimated parameters for the ellipse\n    best = list(result[-1])\n    yc, xc, a, b = (int(round(x)) for x in best[1:5])\n    \n    return yc, xc", "result": "passed", "passed": true}
{"task_id": "../test_cases/distance_between_maxima.ipynb", "completion": "\n    import numpy as np\n\n    im1 = np.asarray(image1)\n    im2 = np.asarray(image2)\n\n    x1,y1 = np.unravel_index(im1.argmax(), im1.shape)\n    x2,y2 = np.unravel_index(im2.argmax(), im2.shape)\n\n    distance = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n\n    return distance", "full_response": "\n    import numpy as np\n\n    im1 = np.asarray(image1)\n    im2 = np.asarray(image2)\n\n    x1,y1 = np.unravel_index(im1.argmax(), im1.shape)\n    x2,y2 = np.unravel_index(im2.argmax(), im2.shape)\n\n    distance = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n\n    return distance", "result": "passed", "passed": true}
{"task_id": "../test_cases/expand_labels_without_overlap.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.expand_labels(label_image, distance=radius)", "full_response": "\n    import skimage\n    return skimage.segmentation.expand_labels(label_image, distance=radius)", "result": "passed", "passed": true}
{"task_id": "../test_cases/extract_surface_measure_area.ipynb", "completion": "\n    import vedo\n    volume = vedo.Volume(binary_volume_image)\n    iso_surface = volume.isosurface()\n    return iso_surface.area()", "full_response": "\n    import vedo\n    volume = vedo.Volume(binary_volume_image)\n    iso_surface = volume.isosurface()\n    return iso_surface.area()", "result": "passed", "passed": true}
{"task_id": "../test_cases/fft_spectrum.ipynb", "completion": "\n        import numpy as np\n    \n        # computing padding tuple:\n        pad_width = ((padding, padding),)*nd_image.ndim\n    \n        # Padding:\n        image_padded = np.pad(nd_image, pad_width=pad_width, mode='symmetric')\n        \n        # prepare the apodization window in 1D:\n        from scipy import signal\n        window_tuple = (signal.windows.hamming(length+2*padding) for length in nd_image.shape)\n        \n        # prepare the apodization window in nD:\n        import functools\n        window = functools.reduce(np.multiply.outer, window_tuple)\n        \n        # Apodize:\n        image_padded_apodized = window*image_padded\n    \n        # Compute the Fourier transform of the image:\n        image_fft = np.fft.fftn(image_padded_apodized)\n        \n        # Shift the zero-frequency component to the center of the spectrum:\n        image_fft_shifted = np.fft.fftshift(image_fft)\n        \n        # Compute the magnitude spectrum:\n        magnitude_spectrum = np.log1p(np.abs(image_fft_shifted))\n            \n        return(magnitude_spectrum)\n    \n    import numpy as np   \n\n    # Test image:\n    image = np.ones((5, 6, 7), dtype=np.int16)\n\n    # Padding:\n    padding_width = 10\n\n    # running the candidate function:\n    magnitude_spectrum_candidate = candidate(image, padding_width)\n    \n    # Reference implementation:\n    magnitude_spectrum_reference = fft_spectrum_reference(image, padding_width)\n    \n    assert np.allclose(magnitude_spectrum_candidate, magnitude_spectrum_reference)", "full_response": "\n        import numpy as np\n    \n        # computing padding tuple:\n        pad_width = ((padding, padding),)*nd_image.ndim\n    \n        # Padding:\n        image_padded = np.pad(nd_image, pad_width=pad_width, mode='symmetric')\n        \n        # prepare the apodization window in 1D:\n        from scipy import signal\n        window_tuple = (signal.windows.hamming(length+2*padding) for length in nd_image.shape)\n        \n        # prepare the apodization window in nD:\n        import functools\n        window = functools.reduce(np.multiply.outer, window_tuple)\n        \n        # Apodize:\n        image_padded_apodized = window*image_padded\n    \n        # Compute the Fourier transform of the image:\n        image_fft = np.fft.fftn(image_padded_apodized)\n        \n        # Shift the zero-frequency component to the center of the spectrum:\n        image_fft_shifted = np.fft.fftshift(image_fft)\n        \n        # Compute the magnitude spectrum:\n        magnitude_spectrum = np.log1p(np.abs(image_fft_shifted))\n            \n        return(magnitude_spectrum)\n    \n    import numpy as np   \n\n    # Test image:\n    image = np.ones((5, 6, 7), dtype=np.int16)\n\n    # Padding:\n    padding_width = 10\n\n    # running the candidate function:\n    magnitude_spectrum_candidate = candidate(image, padding_width)\n    \n    # Reference implementation:\n    magnitude_spectrum_reference = fft_spectrum_reference(image, padding_width)\n    \n    assert np.allclose(magnitude_spectrum_candidate, magnitude_spectrum_reference)", "result": "timed out", "passed": false}
{"task_id": "../test_cases/find_closest_neighbors.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import centroid\n    \n    # Identify all centroid locations\n    label_count = np.max(label_image)\n    centroids = {}\n    for i in range(1, label_count + 1):\n        binary_image = (label_image == i)\n        centroids[i] = centroid(binary_image)\n    \n    # Find the closest top n\n    distances = [(other, np.linalg.norm(centroids[target_label] - centroids[other])) for other in centroids.keys() if other != target_label]\n    sorted_distances = sorted(distances, key = lambda pair: pair[1])\n    topn = [label for label, _ in sorted_distances[:n]]\n\n    return topn", "full_response": "\n    import numpy as np\n    from skimage.measure import centroid\n    \n    # Identify all centroid locations\n    label_count = np.max(label_image)\n    centroids = {}\n    for i in range(1, label_count + 1):\n        binary_image = (label_image == i)\n        centroids[i] = centroid(binary_image)\n    \n    # Find the closest top n\n    distances = [(other, np.linalg.norm(centroids[target_label] - centroids[other])) for other in centroids.keys() if other != target_label]\n    sorted_distances = sorted(distances, key = lambda pair: pair[1])\n    topn = [label for label, _ in sorted_distances[:n]]\n\n    return topn", "result": "passed", "passed": true}
{"task_id": "../test_cases/fit_circle.ipynb", "completion": "\n    import circle_fit as cf\n    xc, yc, r, _ = cf.least_squares_circle(list_of_2d_points)\n    return xc,yc,r", "full_response": "\n    import circle_fit as cf\n    xc, yc, r, _ = cf.least_squares_circle(list_of_2d_points)\n    return xc,yc,r", "result": "passed", "passed": true}
{"task_id": "../test_cases/fit_gaussian_to_spot.ipynb", "completion": "\n    import numpy as np\n    import scipy \n\n    image = np.asarray(image)\n    num_px = image.shape[0]\n    [xx, yy] = np.meshgrid(np.arange(0,num_px), np.arange(0,num_px))\n\n\n    def twoDGauss(x,y,ux,uy,sigma):\n        '''\n        Creates theoretical normalized 2D gaussian spot, centered around (ux,uy) \n        with standard deviation sigma, on grid specified by x and y\n        '''\n        p = 1/(2*np.pi*sigma**2) * np.exp(- ( (x-ux)**2+(y-uy)**2 ) / (2*sigma**2))\n        return p\n\n    def expected(x,y,params):   \n        '''\n        Creates simulated realistic Gaussian spot on x-y grid, with following\n        parameters = [x0,y0,sigma,bg,N], speficically:\n            - x0 = x-position of gaussian (px coord., first pixel is (0,0))\n            - y0 = y-positoin of gaussian (px coord.)\n            - sigma = stdev of gaussian (px coord)\n            - bg = number of photons in background\n            - N = number of photons in spot\n        '''\n        E = params[4] * twoDGauss(x,y,params[0],params[1],params[2]) + params[3]\n        return E\n\n    def SSE(params):\n        '''\n        Calculates sum-of-squared errors difference between 'image' and expected Gaussian defined by 'params'\n        This is essentially the cost-function that is minimized in the fit\n        '''\n        Expec = expected(xx,yy,params)\n        sse = np.sum((image -  Expec)**2)\n        return sse\n\n\n    #guess fit parameters:\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    sigma_guess = 2                 #assume sigma is 2 pixels\n    bg_guess = (np.sum(image) - np.sum(image[1:-1,1:-1]))/(4*num_px-4)           \n                                    #average of border pixels\n    N_guess = np.sum(image) - bg_guess * num_px**2\n                                    #sum of intensities, minus background\n    params_guess = [x_guess,x_guess,sigma_guess, bg_guess, N_guess]\n\n    #perform the fit\n    param = scipy.optimize.fmin(func=SSE,x0=params_guess, maxiter=10000,maxfun=10000,ftol=1e-5,disp=0)\n\n    xc_fit      = param[0]  #fitted x-position\n    yc_fit      = param[1]  #fitted y-position\n    sigma_fit   = param[2]  #fitted sigma\n\n    return (xc_fit, yc_fit, sigma_fit)", "full_response": "\n    import numpy as np\n    import scipy \n\n    image = np.asarray(image)\n    num_px = image.shape[0]\n    [xx, yy] = np.meshgrid(np.arange(0,num_px), np.arange(0,num_px))\n\n\n    def twoDGauss(x,y,ux,uy,sigma):\n        '''\n        Creates theoretical normalized 2D gaussian spot, centered around (ux,uy) \n        with standard deviation sigma, on grid specified by x and y\n        '''\n        p = 1/(2*np.pi*sigma**2) * np.exp(- ( (x-ux)**2+(y-uy)**2 ) / (2*sigma**2))\n        return p\n\n    def expected(x,y,params):   \n        '''\n        Creates simulated realistic Gaussian spot on x-y grid, with following\n        parameters = [x0,y0,sigma,bg,N], speficically:\n            - x0 = x-position of gaussian (px coord., first pixel is (0,0))\n            - y0 = y-positoin of gaussian (px coord.)\n            - sigma = stdev of gaussian (px coord)\n            - bg = number of photons in background\n            - N = number of photons in spot\n        '''\n        E = params[4] * twoDGauss(x,y,params[0],params[1],params[2]) + params[3]\n        return E\n\n    def SSE(params):\n        '''\n        Calculates sum-of-squared errors difference between 'image' and expected Gaussian defined by 'params'\n        This is essentially the cost-function that is minimized in the fit\n        '''\n        Expec = expected(xx,yy,params)\n        sse = np.sum((image -  Expec)**2)\n        return sse\n\n\n    #guess fit parameters:\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    sigma_guess = 2                 #assume sigma is 2 pixels\n    bg_guess = (np.sum(image) - np.sum(image[1:-1,1:-1]))/(4*num_px-4)           \n                                    #average of border pixels\n    N_guess = np.sum(image) - bg_guess * num_px**2\n                                    #sum of intensities, minus background\n    params_guess = [x_guess,x_guess,sigma_guess, bg_guess, N_guess]\n\n    #perform the fit\n    param = scipy.optimize.fmin(func=SSE,x0=params_guess, maxiter=10000,maxfun=10000,ftol=1e-5,disp=0)\n\n    xc_fit      = param[0]  #fitted x-position\n    yc_fit      = param[1]  #fitted y-position\n    sigma_fit   = param[2]  #fitted sigma\n\n    return (xc_fit, yc_fit, sigma_fit)", "result": "passed", "passed": true}
{"task_id": "../test_cases/flow_field_deformation.ipynb", "completion": "\n    import SimpleITK as sitk\n\n    target = sitk.GetImageFromArray(target)\n\n    displacement = sitk.DisplacementFieldTransform(2)\n    field_size = list(flow_field.shape[:2])\n    field_origin = [0, 0]\n    field_spacing = [1.0, 1.0]\n    field_direction = [1, 0, 0, 1]  # direction cosine matrix (row major order)\n\n    # Concatenate all the information into a single list\n    displacement.SetFixedParameters(\n        field_size + field_origin + field_spacing + field_direction\n    )\n    # Set the interpolator to nearest neighbor\n    displacement.SetInterpolator(sitk.sitkNearestNeighbor)\n\n    originalDisplacements = flow_field.reshape((-1, 2)).flatten()\n    displacement.SetParameters(originalDisplacements)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetTransform(displacement)\n    resampler.SetReferenceImage(target)\n    resampled = resampler.Execute(target)\n\n    return sitk.GetArrayFromImage(resampled)", "full_response": "\n    import SimpleITK as sitk\n\n    target = sitk.GetImageFromArray(target)\n\n    displacement = sitk.DisplacementFieldTransform(2)\n    field_size = list(flow_field.shape[:2])\n    field_origin = [0, 0]\n    field_spacing = [1.0, 1.0]\n    field_direction = [1, 0, 0, 1]  # direction cosine matrix (row major order)\n\n    # Concatenate all the information into a single list\n    displacement.SetFixedParameters(\n        field_size + field_origin + field_spacing + field_direction\n    )\n    # Set the interpolator to nearest neighbor\n    displacement.SetInterpolator(sitk.sitkNearestNeighbor)\n\n    originalDisplacements = flow_field.reshape((-1, 2)).flatten()\n    displacement.SetParameters(originalDisplacements)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetTransform(displacement)\n    resampler.SetReferenceImage(target)\n    resampled = resampler.Execute(target)\n\n    return sitk.GetArrayFromImage(resampled)", "result": "passed", "passed": true}
{"task_id": "../test_cases/generate_image_histogram.ipynb", "completion": "\n    import numpy as np\n    return np.histogram(image,bins=num_bins)[0]", "full_response": "\n    import numpy as np\n    return np.histogram(image,bins=num_bins)[0]", "result": "passed", "passed": true}
{"task_id": "../test_cases/identify_centroids.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import centroid\n    n = np.max(label_image)\n    out = {}\n    for i in range(1, n + 1):\n        binary_image = (label_image == i)\n        out[i] = centroid(binary_image)\n    return out", "full_response": "\n    import numpy as np\n    from skimage.measure import centroid\n    n = np.max(label_image)\n    out = {}\n    for i in range(1, n + 1):\n        binary_image = (label_image == i)\n        out[i] = centroid(binary_image)\n    return out", "result": "passed", "passed": true}
{"task_id": "../test_cases/interpolate_stack.ipynb", "completion": "\n    import numpy as np\n\n    return np.linspace(start_slice, end_slice, num)", "full_response": "\n    import numpy as np\n\n    return np.linspace(start_slice, end_slice, num)", "result": "passed", "passed": true}
{"task_id": "../test_cases/label_binary_image_and_count_labels.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    label_image = skimage.measure.label(binary_image)\n\n    return len(np.unique(label_image)) - 1", "full_response": "\n    import skimage\n    import numpy as np\n    label_image = skimage.measure.label(binary_image)\n\n    return len(np.unique(label_image)) - 1", "result": "passed", "passed": true}
{"task_id": "../test_cases/label_sequentially.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.relabel_sequential(label_image)[0]", "full_response": "\n    import skimage\n    return skimage.segmentation.relabel_sequential(label_image)[0]", "result": "passed", "passed": true}
{"task_id": "../test_cases/linear_intensity_profile.ipynb", "completion": "\n    from skimage.measure import profile_line\n    return profile_line(image, starting_point, ending_point)", "full_response": "\n    from skimage.measure import profile_line\n    return profile_line(image, starting_point, ending_point)", "result": "passed", "passed": true}
{"task_id": "../test_cases/list_image_files_in_folder.ipynb", "completion": "\n    import os\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    return [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]", "full_response": "\n    import os\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    return [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]", "result": "passed", "passed": true}
{"task_id": "../test_cases/load_tif_and_output_rgb.ipynb", "completion": "\n    from cv2 import imread, cvtColor, COLOR_BGR2RGB\n    image = imread(path_to_tif)\n    return cvtColor(image, COLOR_BGR2RGB)", "full_response": "\n    from cv2 import imread, cvtColor, COLOR_BGR2RGB\n    image = imread(path_to_tif)\n    return cvtColor(image, COLOR_BGR2RGB)", "result": "failed: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n", "passed": false}
{"task_id": "../test_cases/local_maxima_from_distance_transform.ipynb", "completion": "\n    import scipy.ndimage as ndi\n    import skimage.feature as skf\n    \n    distance_transform = ndi.distance_transform_edt(binary_image)\n    \n    image_max = ndi.maximum_filter(distance_transform, size=nms_window, mode='constant')\n    \n    # suppress non-maxima values by setting them to -1\n    mask = distance_transform == image_max\n    image_max[~mask] = -1\n    \n    local_maxima = skf.peak_local_max(image_max)\n\n    return local_maxima.tolist()", "full_response": "\n    import scipy.ndimage as ndi\n    import skimage.feature as skf\n    \n    distance_transform = ndi.distance_transform_edt(binary_image)\n    \n    image_max = ndi.maximum_filter(distance_transform, size=nms_window, mode='constant')\n    \n    # suppress non-maxima values by setting them to -1\n    mask = distance_transform == image_max\n    image_max[~mask] = -1\n    \n    local_maxima = skf.peak_local_max(image_max)\n\n    return local_maxima.tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/map_pixel_count_of_labels.ipynb", "completion": "\n    import pyclesperanto_prototype as cle\n    return cle.pixel_count_map(label_image)", "full_response": "\n    import pyclesperanto_prototype as cle\n    return cle.pixel_count_map(label_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/mask_image.ipynb", "completion": "\n    import numpy as np\n    return image * mask", "full_response": "\n    import numpy as np\n    return image * mask", "result": "passed", "passed": true}
{"task_id": "../test_cases/maximum_intensity_projection.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).max(axis=0)", "full_response": "\n    import numpy as np\n    return np.asarray(image).max(axis=0)", "result": "passed", "passed": true}
{"task_id": "../test_cases/mean_squared_error.ipynb", "completion": "\n    return ((image1 - image2)**2).mean()\n    # adapted from : https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy", "full_response": "\n    return ((image1 - image2)**2).mean()\n    # adapted from : https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy", "result": "passed", "passed": true}
{"task_id": "../test_cases/mean_std_column.ipynb", "completion": "\n    import numpy as np\n    data = dataframe[column]\n    return np.mean(data), np.std(data)", "full_response": "\n    import numpy as np\n    data = dataframe[column]\n    return np.mean(data), np.std(data)", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_aspect_ratio_of_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = pd.DataFrame(skimage.measure.regionprops_table(label_image, properties=('minor_axis_length', 'major_axis_length')))\n    stats['aspect_ratio'] = stats['major_axis_length'] / stats['minor_axis_length']\n    return stats", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = pd.DataFrame(skimage.measure.regionprops_table(label_image, properties=('minor_axis_length', 'major_axis_length')))\n    stats['aspect_ratio'] = stats['major_axis_length'] / stats['minor_axis_length']\n    return stats", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_intensity_of_labels.ipynb", "completion": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image, intensity_image)\n    return [s.mean_intensity for s in stats]", "full_response": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image, intensity_image)\n    return [s.mean_intensity for s in stats]", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_intensity_over_time.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image_list).mean(axis=(1,2)).tolist()", "full_response": "\n    import numpy as np\n    return np.asarray(image_list).mean(axis=(1,2)).tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_mean_image_intensity.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).mean()", "full_response": "\n    import numpy as np\n    return np.asarray(image).mean()", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_pixel_count_of_labels.ipynb", "completion": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image)\n    return [s.area for s in stats]", "full_response": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image)\n    return [s.area for s in stats]", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_properties_of_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\n    return pd.DataFrame(stats)", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\n    return pd.DataFrame(stats)", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_image_read_voxel_size.ipynb", "completion": "\n    from aicsimageio import AICSImage\n    aics_image = AICSImage(image_filename)\n\n    return aics_image.physical_pixel_sizes.Z, \\\n            aics_image.physical_pixel_sizes.Y, \\\n            aics_image.physical_pixel_sizes.X", "full_response": "\n    from aicsimageio import AICSImage\n    aics_image = AICSImage(image_filename)\n\n    return aics_image.physical_pixel_sizes.Z, \\\n            aics_image.physical_pixel_sizes.Y, \\\n            aics_image.physical_pixel_sizes.X", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_image_return_dimensions.ipynb", "completion": "\n    from skimage.io import imread\n    image = imread(image_file_location)\n    return image.shape", "full_response": "\n    from skimage.io import imread\n    image = imread(image_file_location)\n    return image.shape", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_nifti_image.ipynb", "completion": "\n    \n    import nibabel as nib\n    import numpy as nb\n\n    img = nib.load(image_file_location)\n    data = img.get_fdata()\n    return(data)", "full_response": "\n    \n    import nibabel as nib\n    import numpy as nb\n\n    img = nib.load(image_file_location)\n    data = img.get_fdata()\n    return(data)", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_zarr.ipynb", "completion": "\n    import zarr\n    array = zarr.load(zarr_file_location)\n    return array", "full_response": "\n    import zarr\n    array = zarr.load(zarr_file_location)\n    return array", "result": "passed", "passed": true}
{"task_id": "../test_cases/pair_wise_correlation_matrix.ipynb", "completion": "\n    return dataframe.corr()", "full_response": "\n    return dataframe.corr()", "result": "passed", "passed": true}
{"task_id": "../test_cases/radial_intensity_profile.ipynb", "completion": "\n    import numpy as np\n    y, x = np.indices((image.shape))\n    r = np.sqrt((x - xc)**2 + (y - yc)**2)\n    r = r.astype(int)\n    summed_values = np.bincount(r.ravel(), image.ravel())\n    number_of_pixels_at_r = np.bincount(r.ravel())\n    radial_profile = summed_values / number_of_pixels_at_r\n    return radial_profile ", "full_response": "\n    import numpy as np\n    y, x = np.indices((image.shape))\n    r = np.sqrt((x - xc)**2 + (y - yc)**2)\n    r = r.astype(int)\n    summed_values = np.bincount(r.ravel(), image.ravel())\n    number_of_pixels_at_r = np.bincount(r.ravel())\n    radial_profile = summed_values / number_of_pixels_at_r\n    return radial_profile ", "result": "passed", "passed": true}
{"task_id": "../test_cases/read_imagej_tif_metadata.ipynb", "completion": "\n    from tifffile import TiffFile\n    \n    with (TiffFile(image_filename) as tif):\n        imagej_metadata = tif.imagej_metadata\n    return imagej_metadata", "full_response": "\n    from tifffile import TiffFile\n    \n    with (TiffFile(image_filename) as tif):\n        imagej_metadata = tif.imagej_metadata\n    return imagej_metadata", "result": "passed", "passed": true}
{"task_id": "../test_cases/read_ome_metadata_from_ome_xml.ipynb", "completion": "\n    from ome_types import from_xml\n    ome = from_xml(img_path)\n    return ome.images[0]", "full_response": "\n    from ome_types import from_xml\n    ome = from_xml(img_path)\n    return ome.images[0]", "result": "failed: Could not parse XML from '../example_data/ome_xml_example.xml'", "passed": false}
{"task_id": "../test_cases/region_growing_segmentation.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.flood(image, point)", "full_response": "\n    import skimage\n    return skimage.segmentation.flood(image, point)", "result": "passed", "passed": true}
{"task_id": "../test_cases/register_timelapse.ipynb", "completion": "\n    from skimage import registration\n    import scipy.ndimage as ndi\n\n    new_video = video.copy()\n    ref_frame = new_video[-1]\n    for t in range(len(video) - 1, 0, -1):\n        mov_frame = video[t - 1]\n        shift, _, _ = registration.phase_cross_correlation(\n            ref_frame,\n            mov_frame,\n            upsample_factor=4,\n            normalization=None,\n        )\n        # replaces old ref_frame with shifted mov_frame\n        ref_frame = ndi.shift(mov_frame, shift, order=1)\n        new_video[t - 1] = ref_frame\n\n    return new_video", "full_response": "\n    from skimage import registration\n    import scipy.ndimage as ndi\n\n    new_video = video.copy()\n    ref_frame = new_video[-1]\n    for t in range(len(video) - 1, 0, -1):\n        mov_frame = video[t - 1]\n        shift, _, _ = registration.phase_cross_correlation(\n            ref_frame,\n            mov_frame,\n            upsample_factor=4,\n            normalization=None,\n        )\n        # replaces old ref_frame with shifted mov_frame\n        ref_frame = ndi.shift(mov_frame, shift, order=1)\n        new_video[t - 1] = ref_frame\n\n    return new_video", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_labels_on_edges.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.clear_border(label_image)", "full_response": "\n    import skimage\n    return skimage.segmentation.clear_border(label_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_noise_edge_preserving.ipynb", "completion": "\n    from scipy.ndimage import median_filter\n    filtered_image = median_filter(image, size=radius * 2 + 1)\n    return filtered_image", "full_response": "\n    from scipy.ndimage import median_filter\n    filtered_image = median_filter(image, size=radius * 2 + 1)\n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_small_labels.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.exclude_small_labels(label_image, maximum_size=size_threshold))", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.exclude_small_labels(label_image, maximum_size=size_threshold))", "result": "passed", "passed": true}
{"task_id": "../test_cases/reshape_array.ipynb", "completion": "\n    import numpy as np\n    \n    array = np.asarray(image)\n    array = np.transpose(array, axes=[2, 0, 1])\n    return array", "full_response": "\n    import numpy as np\n    \n    array = np.asarray(image)\n    array = np.transpose(array, axes=[2, 0, 1])\n    return array", "result": "passed", "passed": true}
{"task_id": "../test_cases/return_hello_world.ipynb", "completion": "\n    return \"hello world\"", "full_response": "\n    return \"hello world\"", "result": "passed", "passed": true}
{"task_id": "../test_cases/rgb_to_grey_image_transform.ipynb", "completion": "\n    rgb_sum = r + g + b\n    r = r / rgb_sum\n    g = g / rgb_sum\n    b = b / rgb_sum\n    \n    import numpy as np\n    channel_r = rgb_image[...,0]\n    channel_g = rgb_image[...,1]\n    channel_b = rgb_image[...,2]\n    grey_image = channel_r * r + \\\n                 channel_g * g + \\\n                 channel_b * b\n    \n    return grey_image", "full_response": "\n    rgb_sum = r + g + b\n    r = r / rgb_sum\n    g = g / rgb_sum\n    b = b / rgb_sum\n    \n    import numpy as np\n    channel_r = rgb_image[...,0]\n    channel_g = rgb_image[...,1]\n    channel_b = rgb_image[...,2]\n    grey_image = channel_r * r + \\\n                 channel_g * g + \\\n                 channel_b * b\n    \n    return grey_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/roi_imagej_to_ezomero.ipynb", "completion": "\n    list_of_tuples = list(dataframe.itertuples(index=False, name=None))\n    return list_of_tuples", "full_response": "\n    list_of_tuples = list(dataframe.itertuples(index=False, name=None))\n    return list_of_tuples", "result": "passed", "passed": true}
{"task_id": "../test_cases/rotate_image_by_90_degrees.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.rotate(image, angle_around_z_in_degrees=90))", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.rotate(image, angle_around_z_in_degrees=90))", "result": "passed", "passed": true}
{"task_id": "../test_cases/save_image_with_voxel_size.ipynb", "completion": "\n    from aicsimageio import AICSImage \n    from aicsimageio.types import PhysicalPixelSizes\n    from tempfile import tempdir\n    import os \n\n    image = AICSImage(image)\n    AICSImage.physical_pixel_sizes = PhysicalPixelSizes(Z=vz,Y=vy,X=vx)\n    img_path = os.path.join(tempdir, 'voxel_save_test.ome.tiff')\n    image.save(img_path)\n    return img_path", "full_response": "\n    from aicsimageio import AICSImage \n    from aicsimageio.types import PhysicalPixelSizes\n    from tempfile import tempdir\n    import os \n\n    image = AICSImage(image)\n    AICSImage.physical_pixel_sizes = PhysicalPixelSizes(Z=vz,Y=vy,X=vx)\n    img_path = os.path.join(tempdir, 'voxel_save_test.ome.tiff')\n    image.save(img_path)\n    return img_path", "result": "passed", "passed": true}
{"task_id": "../test_cases/scale_image_affine_transform.ipynb", "completion": "\n    from pyclesperanto_prototype import AffineTransform3D\n    import pyclesperanto_prototype as cle \n    import numpy as np\n    \n    output_img_shape =  (image.shape[0]*sy, image.shape[1]*sx)\n\n    transform = AffineTransform3D()\n    transform.center(image.shape)\n    transform.scale(scale_x = sx, scale_y = sy)\n    transform.center(output_img_shape,undo=True)\n    scaled_image = np.array(cle.affine_transform(image,transform=transform,auto_size=True))\n    return scaled_image, transform._matrix", "full_response": "\n    from pyclesperanto_prototype import AffineTransform3D\n    import pyclesperanto_prototype as cle \n    import numpy as np\n    \n    output_img_shape =  (image.shape[0]*sy, image.shape[1]*sx)\n\n    transform = AffineTransform3D()\n    transform.center(image.shape)\n    transform.scale(scale_x = sx, scale_y = sy)\n    transform.center(output_img_shape,undo=True)\n    scaled_image = np.array(cle.affine_transform(image,transform=transform,auto_size=True))\n    return scaled_image, transform._matrix", "result": "passed", "passed": true}
{"task_id": "../test_cases/select_coexpressing_cells.ipynb", "completion": "\n    import numpy as np\n    import pandas as pd\n    from skimage.measure import regionprops_table\n\n    df = pd.DataFrame(\n        regionprops_table(label_image, image, properties=(\"label\", \"area\", \"intensity_mean\"))\n    )\n    mean_cols = [c for c in df.columns if c.startswith(\"intensity_mean\")]\n    sum_cols = [f\"intensity_sum-{i}\" for i in range(len(mean_cols))]\n    \n    df[sum_cols] = df[mean_cols] * df[\"area\"].to_numpy()\n    \n    selected_ids = df.loc[(df[sum_cols] > threshold).all(axis=1), \"label\"].to_numpy()\n    \n    below_threshold_mask = np.isin(label_image, selected_ids, invert=False)\n    filtered_labels = label_image * below_threshold_mask\n\n    return filtered_labels", "full_response": "\n    import numpy as np\n    import pandas as pd\n    from skimage.measure import regionprops_table\n\n    df = pd.DataFrame(\n        regionprops_table(label_image, image, properties=(\"label\", \"area\", \"intensity_mean\"))\n    )\n    mean_cols = [c for c in df.columns if c.startswith(\"intensity_mean\")]\n    sum_cols = [f\"intensity_sum-{i}\" for i in range(len(mean_cols))]\n    \n    df[sum_cols] = df[mean_cols] * df[\"area\"].to_numpy()\n    \n    selected_ids = df.loc[(df[sum_cols] > threshold).all(axis=1), \"label\"].to_numpy()\n    \n    below_threshold_mask = np.isin(label_image, selected_ids, invert=False)\n    filtered_labels = label_image * below_threshold_mask\n\n    return filtered_labels", "result": "passed", "passed": true}
{"task_id": "../test_cases/stack_and_merge.ipynb", "completion": "\n    import numpy as np\n    stacked_image = np.stack((image1, image2), axis=0)\n    stitched_image = np.concatenate((stacked_image, image3), axis=2)\n    return stitched_image.shape", "full_response": "\n    import numpy as np\n    stacked_image = np.stack((image1, image2), axis=0)\n    stitched_image = np.concatenate((stacked_image, image3), axis=2)\n    return stitched_image.shape", "result": "passed", "passed": true}
{"task_id": "../test_cases/subsample_image.ipynb", "completion": "\n    return image[::n,::n]", "full_response": "\n    return image[::n,::n]", "result": "passed", "passed": true}
{"task_id": "../test_cases/subtract_background_tophat.ipynb", "completion": "\n    from skimage.morphology import white_tophat\n    from skimage.morphology import disk\n    filtered_image = white_tophat(image, footprint=disk(radius))\n    \n    return filtered_image", "full_response": "\n    from skimage.morphology import white_tophat\n    from skimage.morphology import disk\n    filtered_image = white_tophat(image, footprint=disk(radius))\n    \n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/sum_images.ipynb", "completion": "\n    return image1 + image2", "full_response": "\n    return image1 + image2", "result": "passed", "passed": true}
{"task_id": "../test_cases/sum_intensity_projection.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).sum(axis=0)", "full_response": "\n    import numpy as np\n    return np.asarray(image).sum(axis=0)", "result": "passed", "passed": true}
{"task_id": "../test_cases/tiled_image_processing.ipynb", "completion": "\n    import dask\n    import dask.array as da\n\n    tiles = da.from_array(image, chunks=(tile_size, tile_size))\n    \n    def procedure(image):\n        from scipy.ndimage import maximum_filter\n        return maximum_filter(image, size=radius*2+1)\n\n    # setup a lazy result (not computed yet)\n    tile_map = da.map_blocks(procedure, tiles)\n\n    # actually apply filter\n    result = tile_map.compute()\n\n    return result", "full_response": "\n    import dask\n    import dask.array as da\n\n    tiles = da.from_array(image, chunks=(tile_size, tile_size))\n    \n    def procedure(image):\n        from scipy.ndimage import maximum_filter\n        return maximum_filter(image, size=radius*2+1)\n\n    # setup a lazy result (not computed yet)\n    tile_map = da.map_blocks(procedure, tiles)\n\n    # actually apply filter\n    result = tile_map.compute()\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/translate_3d_image_along_vector.ipynb", "completion": "\n    from pyclesperanto_prototype import translate\n\n    # translate 3d image along t_x, t_y and t_z\n    return translate(image, translate_x = t_x, translate_y = t_y, translate_z = t_z)", "full_response": "\n    from pyclesperanto_prototype import translate\n\n    # translate 3d image along t_x, t_y and t_z\n    return translate(image, translate_x = t_x, translate_y = t_y, translate_z = t_z)", "result": "passed", "passed": true}
{"task_id": "../test_cases/transpose_image_axes.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).T", "full_response": "\n    import numpy as np\n    return np.asarray(image).T", "result": "passed", "passed": true}
{"task_id": "../test_cases/t_test.ipynb", "completion": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    return scipy.stats.ttest_rel(data1, data2)[1]\n    ", "full_response": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    return scipy.stats.ttest_rel(data1, data2)[1]\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_batch_process_folder_count_labels.ipynb", "completion": "\n    import os\n    from skimage.io import imread\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]\n    result = {}\n\n    for filename in file_list:\n        image = imread(folder_location + filename)\n\n        labels = np.unique(image).tolist()\n        labels.pop(0)\n\n        count = len(labels)\n\n        result[filename] = count\n\n    return result", "full_response": "\n    import os\n    from skimage.io import imread\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]\n    result = {}\n\n    for filename in file_list:\n        image = imread(folder_location + filename)\n\n        labels = np.unique(image).tolist()\n        labels.pop(0)\n\n        count = len(labels)\n\n        result[filename] = count\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_batch_process_folder_measure_intensity.ipynb", "completion": "\n    import os\n    import pandas as pd\n    from skimage.io import imread\n    from skimage.measure import regionprops\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(image_folder_location) if str(fn[-4:]) in supported_fileendings]\n\n    result = []\n\n    for filename in file_list:\n        image = imread(image_folder_location + filename)[...,0]\n        labels = imread(labels_folder_location + filename)\n\n        stats = regionprops(labels, intensity_image=image)\n\n        for s in stats:\n            result.append({\n                \"filename\":filename,\n                \"label\":s.label,\n                \"min_intensity\":s.min_intensity,\n                \"mean_intensity\":s.mean_intensity,\n                \"max_intensity\":s.max_intensity,\n            })\n\n    return pd.DataFrame(result)", "full_response": "\n    import os\n    import pandas as pd\n    from skimage.io import imread\n    from skimage.measure import regionprops\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(image_folder_location) if str(fn[-4:]) in supported_fileendings]\n\n    result = []\n\n    for filename in file_list:\n        image = imread(image_folder_location + filename)[...,0]\n        labels = imread(labels_folder_location + filename)\n\n        stats = regionprops(labels, intensity_image=image)\n\n        for s in stats:\n            result.append({\n                \"filename\":filename,\n                \"label\":s.label,\n                \"min_intensity\":s.min_intensity,\n                \"mean_intensity\":s.mean_intensity,\n                \"max_intensity\":s.max_intensity,\n            })\n\n    return pd.DataFrame(result)", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segmentation_counting.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    average_intensity = np.asarray(image).mean()\n    binary = image > average_intensity\n    labels = skimage.measure.label(binary)\n    return labels.max()", "full_response": "\n    import skimage\n    import numpy as np\n    average_intensity = np.asarray(image).mean()\n    binary = image > average_intensity\n    labels = skimage.measure.label(binary)\n    return labels.max()", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segmentation_measurement_summary.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n    label_image = skimage.measure.label(binary_image)\n    stats = skimage.measure.regionprops(label_image)\n    areas = [s.area for s in stats]\n    return np.mean(areas)", "full_response": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n    label_image = skimage.measure.label(binary_image)\n    stats = skimage.measure.regionprops(label_image)\n    areas = [s.area for s in stats]\n    return np.mean(areas)", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segment_measure_umap.ipynb", "completion": "\n    import numpy as np\n    import pandas as pd\n    import umap\n    from skimage.measure import label, regionprops_table\n\n    image = np.asarray(image)\n\n    # segment\n    binary = image > 0.5 * image.max()\n    labels = label(binary)\n\n    # measure\n    dataframe = pd.DataFrame(regionprops_table(labels, intensity_image=image, \n                                              properties=['area', 'perimeter', 'mean_intensity', \n                                                          'minor_axis_length', 'major_axis_length']))\n\n    # append UMAP\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    return dataframe", "full_response": "\n    import numpy as np\n    import pandas as pd\n    import umap\n    from skimage.measure import label, regionprops_table\n\n    image = np.asarray(image)\n\n    # segment\n    binary = image > 0.5 * image.max()\n    labels = label(binary)\n\n    # measure\n    dataframe = pd.DataFrame(regionprops_table(labels, intensity_image=image, \n                                              properties=['area', 'perimeter', 'mean_intensity', \n                                                          'minor_axis_length', 'major_axis_length']))\n\n    # append UMAP\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    return dataframe", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_watershed_segmentation_correction_measurement.ipynb", "completion": "\n    import skimage\n    blurred = skimage.filters.gaussian(image * 255, sigma=1)\n    minima = skimage.morphology.local_minima(blurred)\n    spots = skimage.measure.label(minima)\n    labels = skimage.segmentation.watershed(blurred, spots)\n    labels_without_border = skimage.segmentation.clear_border(labels)   \n    binary = labels_without_border > 0\n    return binary.sum()", "full_response": "\n    import skimage\n    blurred = skimage.filters.gaussian(image * 255, sigma=1)\n    minima = skimage.morphology.local_minima(blurred)\n    spots = skimage.measure.label(minima)\n    labels = skimage.segmentation.watershed(blurred, spots)\n    labels_without_border = skimage.segmentation.clear_border(labels)   \n    binary = labels_without_border > 0\n    return binary.sum()", "result": "passed", "passed": true}
{"task_id": "../test_cases/apply_otsu_threshold_and_count_positive_pixels.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n\n    result = np.sum(binary_image)\n\n    return result", "full_response": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n\n    result = np.sum(binary_image)\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/binary_closing.ipynb", "completion": "\n    import numpy as np\n    import skimage\n    size = radius * 2 + 1\n    return skimage.morphology.binary_closing(binary_image, footprint=np.ones((size, size)))", "full_response": "\n    import numpy as np\n    import skimage\n    size = radius * 2 + 1\n    return skimage.morphology.binary_closing(binary_image, footprint=np.ones((size, size)))", "result": "passed", "passed": true}
{"task_id": "../test_cases/binary_skeleton.ipynb", "completion": "\n    from skimage.morphology import skeletonize\n    return skeletonize(binary_image)", "full_response": "\n    from skimage.morphology import skeletonize\n    return skeletonize(binary_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/bland_altman.ipynb", "completion": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    dataframe['mean'] = (data1 + data2) / 2\n    dataframe['diff'] = data2 - data1\n    return dataframe", "full_response": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    dataframe['mean'] = (data1 + data2) / 2\n    dataframe['diff'] = data2 - data1\n    return dataframe", "result": "passed", "passed": true}
{"task_id": "../test_cases/combine_columns_of_tables.ipynb", "completion": "\n    import pandas as pd\n    return pd.merge(dataframe1, dataframe2, how='outer', on='label')", "full_response": "\n    import pandas as pd\n    return pd.merge(dataframe1, dataframe2, how='outer', on='label')", "result": "passed", "passed": true}
{"task_id": "../test_cases/convert_points_polygon.ipynb", "completion": "\n    from shapely import Polygon\n    polygon = Polygon(coordinates)\n    return polygon\n", "full_response": "\n    from shapely import Polygon\n    polygon = Polygon(coordinates)\n    return polygon\n", "result": "passed", "passed": true}
{"task_id": "../test_cases/convex_hull_measure_area.ipynb", "completion": "\n    import vedo\n    convex_hull = vedo.shapes.ConvexHull(point_cloud)\n    return convex_hull.area()", "full_response": "\n    import vedo\n    convex_hull = vedo.shapes.ConvexHull(point_cloud)\n    return convex_hull.area()", "result": "passed", "passed": true}
{"task_id": "../test_cases/convolve_images.ipynb", "completion": "\n    import scipy\n    return scipy.ndimage.convolve(image, kernel_image)\n    ", "full_response": "\n    import scipy\n    return scipy.ndimage.convolve(image, kernel_image)\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_number_of_touching_neighbors.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n\n    touch_matrix = cle.generate_touch_matrix(label_image)\n    cle.set_row(touch_matrix, 0, 0)\n    cle.set_column(touch_matrix, 0, 0)\n\n    return np.asarray(cle.sum_y_projection(touch_matrix))[0,1:].tolist()", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n\n    touch_matrix = cle.generate_touch_matrix(label_image)\n    cle.set_row(touch_matrix, 0, 0)\n    cle.set_column(touch_matrix, 0, 0)\n\n    return np.asarray(cle.sum_y_projection(touch_matrix))[0,1:].tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_objects_over_time.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import label\n    labels = [label(binary_image) for binary_image in binary_image_list]\n    return [len(np.unique(label)) - 1 for label in labels]", "full_response": "\n    import numpy as np\n    from skimage.measure import label\n    labels = [label(binary_image) for binary_image in binary_image_list]\n    return [len(np.unique(label)) - 1 for label in labels]", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_overlapping_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image_1, label_image_2, properties=('mean_intensity',))\n    return (pd.DataFrame(stats)['mean_intensity'] > 0).sum()", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image_1, label_image_2, properties=('mean_intensity',))\n    return (pd.DataFrame(stats)['mean_intensity'] > 0).sum()", "result": "passed", "passed": true}
{"task_id": "../test_cases/create_umap.ipynb", "completion": "\n    import umap\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    # no return value", "full_response": "\n    import umap\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    # no return value", "result": "passed", "passed": true}
{"task_id": "../test_cases/crop_quarter_image.ipynb", "completion": "\n    width = image.shape[1]\n    height = image.shape[0]\n\n    return image[:int(width/2),:int(height/2)]", "full_response": "\n    width = image.shape[1]\n    height = image.shape[0]\n\n    return image[:int(width/2),:int(height/2)]", "result": "passed", "passed": true}
{"task_id": "../test_cases/dataframe_column_rename.ipynb", "completion": "\n    for old_value, new_value in replacements.items():\n        df[column] = df[column].replace(old_value, new_value, regex=True)\n    return df", "full_response": "\n    for old_value, new_value in replacements.items():\n        df[column] = df[column].replace(old_value, new_value, regex=True)\n    return df", "result": "passed", "passed": true}
{"task_id": "../test_cases/deconvolve_image.ipynb", "completion": "\n    from scipy import fftpack\n\n    # adapted from: https://stackoverflow.com/questions/17473917/is-there-a-equivalent-of-scipy-signal-deconvolve-for-2d-arrays\n    star_fft = fftpack.fftshift(fftpack.fftn(image))\n    psf_fft = fftpack.fftshift(fftpack.fftn(kernel_image))\n    return fftpack.fftshift(fftpack.ifftn(fftpack.ifftshift(star_fft/psf_fft)))\n    ", "full_response": "\n    from scipy import fftpack\n\n    # adapted from: https://stackoverflow.com/questions/17473917/is-there-a-equivalent-of-scipy-signal-deconvolve-for-2d-arrays\n    star_fft = fftpack.fftshift(fftpack.fftn(image))\n    psf_fft = fftpack.fftshift(fftpack.fftn(kernel_image))\n    return fftpack.fftshift(fftpack.ifftn(fftpack.ifftshift(star_fft/psf_fft)))\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/detect_edges.ipynb", "completion": "\n    from scipy.ndimage import sobel\n    filtered_image = sobel(image)\n    return filtered_image", "full_response": "\n    from scipy.ndimage import sobel\n    filtered_image = sobel(image)\n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/detect_ellipse.ipynb", "completion": "\n    from skimage.transform import hough_ellipse\n    result = hough_ellipse(image,  accuracy=5, threshold=10)\n    result.sort(order='accumulator')\n    \n    # Estimated parameters for the ellipse\n    best = list(result[-1])\n    yc, xc, a, b = (int(round(x)) for x in best[1:5])\n    \n    return yc, xc", "full_response": "\n    from skimage.transform import hough_ellipse\n    result = hough_ellipse(image,  accuracy=5, threshold=10)\n    result.sort(order='accumulator')\n    \n    # Estimated parameters for the ellipse\n    best = list(result[-1])\n    yc, xc, a, b = (int(round(x)) for x in best[1:5])\n    \n    return yc, xc", "result": "passed", "passed": true}
{"task_id": "../test_cases/distance_between_maxima.ipynb", "completion": "\n    import numpy as np\n\n    im1 = np.asarray(image1)\n    im2 = np.asarray(image2)\n\n    x1,y1 = np.unravel_index(im1.argmax(), im1.shape)\n    x2,y2 = np.unravel_index(im2.argmax(), im2.shape)\n\n    distance = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n\n    return distance", "full_response": "\n    import numpy as np\n\n    im1 = np.asarray(image1)\n    im2 = np.asarray(image2)\n\n    x1,y1 = np.unravel_index(im1.argmax(), im1.shape)\n    x2,y2 = np.unravel_index(im2.argmax(), im2.shape)\n\n    distance = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n\n    return distance", "result": "passed", "passed": true}
{"task_id": "../test_cases/expand_labels_without_overlap.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.expand_labels(label_image, distance=radius)", "full_response": "\n    import skimage\n    return skimage.segmentation.expand_labels(label_image, distance=radius)", "result": "passed", "passed": true}
{"task_id": "../test_cases/extract_surface_measure_area.ipynb", "completion": "\n    import vedo\n    volume = vedo.Volume(binary_volume_image)\n    iso_surface = volume.isosurface()\n    return iso_surface.area()", "full_response": "\n    import vedo\n    volume = vedo.Volume(binary_volume_image)\n    iso_surface = volume.isosurface()\n    return iso_surface.area()", "result": "passed", "passed": true}
{"task_id": "../test_cases/fft_spectrum.ipynb", "completion": "\n        import numpy as np\n    \n        # computing padding tuple:\n        pad_width = ((padding, padding),)*nd_image.ndim\n    \n        # Padding:\n        image_padded = np.pad(nd_image, pad_width=pad_width, mode='symmetric')\n        \n        # prepare the apodization window in 1D:\n        from scipy import signal\n        window_tuple = (signal.windows.hamming(length+2*padding) for length in nd_image.shape)\n        \n        # prepare the apodization window in nD:\n        import functools\n        window = functools.reduce(np.multiply.outer, window_tuple)\n        \n        # Apodize:\n        image_padded_apodized = window*image_padded\n    \n        # Compute the Fourier transform of the image:\n        image_fft = np.fft.fftn(image_padded_apodized)\n        \n        # Shift the zero-frequency component to the center of the spectrum:\n        image_fft_shifted = np.fft.fftshift(image_fft)\n        \n        # Compute the magnitude spectrum:\n        magnitude_spectrum = np.log1p(np.abs(image_fft_shifted))\n            \n        return(magnitude_spectrum)\n    \n    import numpy as np   \n\n    # Test image:\n    image = np.ones((5, 6, 7), dtype=np.int16)\n\n    # Padding:\n    padding_width = 10\n\n    # running the candidate function:\n    magnitude_spectrum_candidate = candidate(image, padding_width)\n    \n    # Reference implementation:\n    magnitude_spectrum_reference = fft_spectrum_reference(image, padding_width)\n    \n    assert np.allclose(magnitude_spectrum_candidate, magnitude_spectrum_reference)", "full_response": "\n        import numpy as np\n    \n        # computing padding tuple:\n        pad_width = ((padding, padding),)*nd_image.ndim\n    \n        # Padding:\n        image_padded = np.pad(nd_image, pad_width=pad_width, mode='symmetric')\n        \n        # prepare the apodization window in 1D:\n        from scipy import signal\n        window_tuple = (signal.windows.hamming(length+2*padding) for length in nd_image.shape)\n        \n        # prepare the apodization window in nD:\n        import functools\n        window = functools.reduce(np.multiply.outer, window_tuple)\n        \n        # Apodize:\n        image_padded_apodized = window*image_padded\n    \n        # Compute the Fourier transform of the image:\n        image_fft = np.fft.fftn(image_padded_apodized)\n        \n        # Shift the zero-frequency component to the center of the spectrum:\n        image_fft_shifted = np.fft.fftshift(image_fft)\n        \n        # Compute the magnitude spectrum:\n        magnitude_spectrum = np.log1p(np.abs(image_fft_shifted))\n            \n        return(magnitude_spectrum)\n    \n    import numpy as np   \n\n    # Test image:\n    image = np.ones((5, 6, 7), dtype=np.int16)\n\n    # Padding:\n    padding_width = 10\n\n    # running the candidate function:\n    magnitude_spectrum_candidate = candidate(image, padding_width)\n    \n    # Reference implementation:\n    magnitude_spectrum_reference = fft_spectrum_reference(image, padding_width)\n    \n    assert np.allclose(magnitude_spectrum_candidate, magnitude_spectrum_reference)", "result": "timed out", "passed": false}
{"task_id": "../test_cases/find_closest_neighbors.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import centroid\n    \n    # Identify all centroid locations\n    label_count = np.max(label_image)\n    centroids = {}\n    for i in range(1, label_count + 1):\n        binary_image = (label_image == i)\n        centroids[i] = centroid(binary_image)\n    \n    # Find the closest top n\n    distances = [(other, np.linalg.norm(centroids[target_label] - centroids[other])) for other in centroids.keys() if other != target_label]\n    sorted_distances = sorted(distances, key = lambda pair: pair[1])\n    topn = [label for label, _ in sorted_distances[:n]]\n\n    return topn", "full_response": "\n    import numpy as np\n    from skimage.measure import centroid\n    \n    # Identify all centroid locations\n    label_count = np.max(label_image)\n    centroids = {}\n    for i in range(1, label_count + 1):\n        binary_image = (label_image == i)\n        centroids[i] = centroid(binary_image)\n    \n    # Find the closest top n\n    distances = [(other, np.linalg.norm(centroids[target_label] - centroids[other])) for other in centroids.keys() if other != target_label]\n    sorted_distances = sorted(distances, key = lambda pair: pair[1])\n    topn = [label for label, _ in sorted_distances[:n]]\n\n    return topn", "result": "passed", "passed": true}
{"task_id": "../test_cases/fit_circle.ipynb", "completion": "\n    import circle_fit as cf\n    xc, yc, r, _ = cf.least_squares_circle(list_of_2d_points)\n    return xc,yc,r", "full_response": "\n    import circle_fit as cf\n    xc, yc, r, _ = cf.least_squares_circle(list_of_2d_points)\n    return xc,yc,r", "result": "passed", "passed": true}
{"task_id": "../test_cases/fit_gaussian_to_spot.ipynb", "completion": "\n    import numpy as np\n    import scipy \n\n    image = np.asarray(image)\n    num_px = image.shape[0]\n    [xx, yy] = np.meshgrid(np.arange(0,num_px), np.arange(0,num_px))\n\n\n    def twoDGauss(x,y,ux,uy,sigma):\n        '''\n        Creates theoretical normalized 2D gaussian spot, centered around (ux,uy) \n        with standard deviation sigma, on grid specified by x and y\n        '''\n        p = 1/(2*np.pi*sigma**2) * np.exp(- ( (x-ux)**2+(y-uy)**2 ) / (2*sigma**2))\n        return p\n\n    def expected(x,y,params):   \n        '''\n        Creates simulated realistic Gaussian spot on x-y grid, with following\n        parameters = [x0,y0,sigma,bg,N], speficically:\n            - x0 = x-position of gaussian (px coord., first pixel is (0,0))\n            - y0 = y-positoin of gaussian (px coord.)\n            - sigma = stdev of gaussian (px coord)\n            - bg = number of photons in background\n            - N = number of photons in spot\n        '''\n        E = params[4] * twoDGauss(x,y,params[0],params[1],params[2]) + params[3]\n        return E\n\n    def SSE(params):\n        '''\n        Calculates sum-of-squared errors difference between 'image' and expected Gaussian defined by 'params'\n        This is essentially the cost-function that is minimized in the fit\n        '''\n        Expec = expected(xx,yy,params)\n        sse = np.sum((image -  Expec)**2)\n        return sse\n\n\n    #guess fit parameters:\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    sigma_guess = 2                 #assume sigma is 2 pixels\n    bg_guess = (np.sum(image) - np.sum(image[1:-1,1:-1]))/(4*num_px-4)           \n                                    #average of border pixels\n    N_guess = np.sum(image) - bg_guess * num_px**2\n                                    #sum of intensities, minus background\n    params_guess = [x_guess,x_guess,sigma_guess, bg_guess, N_guess]\n\n    #perform the fit\n    param = scipy.optimize.fmin(func=SSE,x0=params_guess, maxiter=10000,maxfun=10000,ftol=1e-5,disp=0)\n\n    xc_fit      = param[0]  #fitted x-position\n    yc_fit      = param[1]  #fitted y-position\n    sigma_fit   = param[2]  #fitted sigma\n\n    return (xc_fit, yc_fit, sigma_fit)", "full_response": "\n    import numpy as np\n    import scipy \n\n    image = np.asarray(image)\n    num_px = image.shape[0]\n    [xx, yy] = np.meshgrid(np.arange(0,num_px), np.arange(0,num_px))\n\n\n    def twoDGauss(x,y,ux,uy,sigma):\n        '''\n        Creates theoretical normalized 2D gaussian spot, centered around (ux,uy) \n        with standard deviation sigma, on grid specified by x and y\n        '''\n        p = 1/(2*np.pi*sigma**2) * np.exp(- ( (x-ux)**2+(y-uy)**2 ) / (2*sigma**2))\n        return p\n\n    def expected(x,y,params):   \n        '''\n        Creates simulated realistic Gaussian spot on x-y grid, with following\n        parameters = [x0,y0,sigma,bg,N], speficically:\n            - x0 = x-position of gaussian (px coord., first pixel is (0,0))\n            - y0 = y-positoin of gaussian (px coord.)\n            - sigma = stdev of gaussian (px coord)\n            - bg = number of photons in background\n            - N = number of photons in spot\n        '''\n        E = params[4] * twoDGauss(x,y,params[0],params[1],params[2]) + params[3]\n        return E\n\n    def SSE(params):\n        '''\n        Calculates sum-of-squared errors difference between 'image' and expected Gaussian defined by 'params'\n        This is essentially the cost-function that is minimized in the fit\n        '''\n        Expec = expected(xx,yy,params)\n        sse = np.sum((image -  Expec)**2)\n        return sse\n\n\n    #guess fit parameters:\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    sigma_guess = 2                 #assume sigma is 2 pixels\n    bg_guess = (np.sum(image) - np.sum(image[1:-1,1:-1]))/(4*num_px-4)           \n                                    #average of border pixels\n    N_guess = np.sum(image) - bg_guess * num_px**2\n                                    #sum of intensities, minus background\n    params_guess = [x_guess,x_guess,sigma_guess, bg_guess, N_guess]\n\n    #perform the fit\n    param = scipy.optimize.fmin(func=SSE,x0=params_guess, maxiter=10000,maxfun=10000,ftol=1e-5,disp=0)\n\n    xc_fit      = param[0]  #fitted x-position\n    yc_fit      = param[1]  #fitted y-position\n    sigma_fit   = param[2]  #fitted sigma\n\n    return (xc_fit, yc_fit, sigma_fit)", "result": "passed", "passed": true}
{"task_id": "../test_cases/flow_field_deformation.ipynb", "completion": "\n    import SimpleITK as sitk\n\n    target = sitk.GetImageFromArray(target)\n\n    displacement = sitk.DisplacementFieldTransform(2)\n    field_size = list(flow_field.shape[:2])\n    field_origin = [0, 0]\n    field_spacing = [1.0, 1.0]\n    field_direction = [1, 0, 0, 1]  # direction cosine matrix (row major order)\n\n    # Concatenate all the information into a single list\n    displacement.SetFixedParameters(\n        field_size + field_origin + field_spacing + field_direction\n    )\n    # Set the interpolator to nearest neighbor\n    displacement.SetInterpolator(sitk.sitkNearestNeighbor)\n\n    originalDisplacements = flow_field.reshape((-1, 2)).flatten()\n    displacement.SetParameters(originalDisplacements)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetTransform(displacement)\n    resampler.SetReferenceImage(target)\n    resampled = resampler.Execute(target)\n\n    return sitk.GetArrayFromImage(resampled)", "full_response": "\n    import SimpleITK as sitk\n\n    target = sitk.GetImageFromArray(target)\n\n    displacement = sitk.DisplacementFieldTransform(2)\n    field_size = list(flow_field.shape[:2])\n    field_origin = [0, 0]\n    field_spacing = [1.0, 1.0]\n    field_direction = [1, 0, 0, 1]  # direction cosine matrix (row major order)\n\n    # Concatenate all the information into a single list\n    displacement.SetFixedParameters(\n        field_size + field_origin + field_spacing + field_direction\n    )\n    # Set the interpolator to nearest neighbor\n    displacement.SetInterpolator(sitk.sitkNearestNeighbor)\n\n    originalDisplacements = flow_field.reshape((-1, 2)).flatten()\n    displacement.SetParameters(originalDisplacements)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetTransform(displacement)\n    resampler.SetReferenceImage(target)\n    resampled = resampler.Execute(target)\n\n    return sitk.GetArrayFromImage(resampled)", "result": "passed", "passed": true}
{"task_id": "../test_cases/generate_image_histogram.ipynb", "completion": "\n    import numpy as np\n    return np.histogram(image,bins=num_bins)[0]", "full_response": "\n    import numpy as np\n    return np.histogram(image,bins=num_bins)[0]", "result": "passed", "passed": true}
{"task_id": "../test_cases/identify_centroids.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import centroid\n    n = np.max(label_image)\n    out = {}\n    for i in range(1, n + 1):\n        binary_image = (label_image == i)\n        out[i] = centroid(binary_image)\n    return out", "full_response": "\n    import numpy as np\n    from skimage.measure import centroid\n    n = np.max(label_image)\n    out = {}\n    for i in range(1, n + 1):\n        binary_image = (label_image == i)\n        out[i] = centroid(binary_image)\n    return out", "result": "passed", "passed": true}
{"task_id": "../test_cases/interpolate_stack.ipynb", "completion": "\n    import numpy as np\n\n    return np.linspace(start_slice, end_slice, num)", "full_response": "\n    import numpy as np\n\n    return np.linspace(start_slice, end_slice, num)", "result": "passed", "passed": true}
{"task_id": "../test_cases/label_binary_image_and_count_labels.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    label_image = skimage.measure.label(binary_image)\n\n    return len(np.unique(label_image)) - 1", "full_response": "\n    import skimage\n    import numpy as np\n    label_image = skimage.measure.label(binary_image)\n\n    return len(np.unique(label_image)) - 1", "result": "passed", "passed": true}
{"task_id": "../test_cases/label_sequentially.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.relabel_sequential(label_image)[0]", "full_response": "\n    import skimage\n    return skimage.segmentation.relabel_sequential(label_image)[0]", "result": "passed", "passed": true}
{"task_id": "../test_cases/linear_intensity_profile.ipynb", "completion": "\n    from skimage.measure import profile_line\n    return profile_line(image, starting_point, ending_point)", "full_response": "\n    from skimage.measure import profile_line\n    return profile_line(image, starting_point, ending_point)", "result": "passed", "passed": true}
{"task_id": "../test_cases/list_image_files_in_folder.ipynb", "completion": "\n    import os\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    return [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]", "full_response": "\n    import os\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    return [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]", "result": "passed", "passed": true}
{"task_id": "../test_cases/load_tif_and_output_rgb.ipynb", "completion": "\n    from cv2 import imread, cvtColor, COLOR_BGR2RGB\n    image = imread(path_to_tif)\n    return cvtColor(image, COLOR_BGR2RGB)", "full_response": "\n    from cv2 import imread, cvtColor, COLOR_BGR2RGB\n    image = imread(path_to_tif)\n    return cvtColor(image, COLOR_BGR2RGB)", "result": "failed: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n", "passed": false}
{"task_id": "../test_cases/local_maxima_from_distance_transform.ipynb", "completion": "\n    import scipy.ndimage as ndi\n    import skimage.feature as skf\n    \n    distance_transform = ndi.distance_transform_edt(binary_image)\n    \n    image_max = ndi.maximum_filter(distance_transform, size=nms_window, mode='constant')\n    \n    # suppress non-maxima values by setting them to -1\n    mask = distance_transform == image_max\n    image_max[~mask] = -1\n    \n    local_maxima = skf.peak_local_max(image_max)\n\n    return local_maxima.tolist()", "full_response": "\n    import scipy.ndimage as ndi\n    import skimage.feature as skf\n    \n    distance_transform = ndi.distance_transform_edt(binary_image)\n    \n    image_max = ndi.maximum_filter(distance_transform, size=nms_window, mode='constant')\n    \n    # suppress non-maxima values by setting them to -1\n    mask = distance_transform == image_max\n    image_max[~mask] = -1\n    \n    local_maxima = skf.peak_local_max(image_max)\n\n    return local_maxima.tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/map_pixel_count_of_labels.ipynb", "completion": "\n    import pyclesperanto_prototype as cle\n    return cle.pixel_count_map(label_image)", "full_response": "\n    import pyclesperanto_prototype as cle\n    return cle.pixel_count_map(label_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/mask_image.ipynb", "completion": "\n    import numpy as np\n    return image * mask", "full_response": "\n    import numpy as np\n    return image * mask", "result": "passed", "passed": true}
{"task_id": "../test_cases/maximum_intensity_projection.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).max(axis=0)", "full_response": "\n    import numpy as np\n    return np.asarray(image).max(axis=0)", "result": "passed", "passed": true}
{"task_id": "../test_cases/mean_squared_error.ipynb", "completion": "\n    return ((image1 - image2)**2).mean()\n    # adapted from : https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy", "full_response": "\n    return ((image1 - image2)**2).mean()\n    # adapted from : https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy", "result": "passed", "passed": true}
{"task_id": "../test_cases/mean_std_column.ipynb", "completion": "\n    import numpy as np\n    data = dataframe[column]\n    return np.mean(data), np.std(data)", "full_response": "\n    import numpy as np\n    data = dataframe[column]\n    return np.mean(data), np.std(data)", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_aspect_ratio_of_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = pd.DataFrame(skimage.measure.regionprops_table(label_image, properties=('minor_axis_length', 'major_axis_length')))\n    stats['aspect_ratio'] = stats['major_axis_length'] / stats['minor_axis_length']\n    return stats", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = pd.DataFrame(skimage.measure.regionprops_table(label_image, properties=('minor_axis_length', 'major_axis_length')))\n    stats['aspect_ratio'] = stats['major_axis_length'] / stats['minor_axis_length']\n    return stats", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_intensity_of_labels.ipynb", "completion": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image, intensity_image)\n    return [s.mean_intensity for s in stats]", "full_response": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image, intensity_image)\n    return [s.mean_intensity for s in stats]", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_intensity_over_time.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image_list).mean(axis=(1,2)).tolist()", "full_response": "\n    import numpy as np\n    return np.asarray(image_list).mean(axis=(1,2)).tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_mean_image_intensity.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).mean()", "full_response": "\n    import numpy as np\n    return np.asarray(image).mean()", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_pixel_count_of_labels.ipynb", "completion": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image)\n    return [s.area for s in stats]", "full_response": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image)\n    return [s.area for s in stats]", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_properties_of_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\n    return pd.DataFrame(stats)", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\n    return pd.DataFrame(stats)", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_image_read_voxel_size.ipynb", "completion": "\n    from aicsimageio import AICSImage\n    aics_image = AICSImage(image_filename)\n\n    return aics_image.physical_pixel_sizes.Z, \\\n            aics_image.physical_pixel_sizes.Y, \\\n            aics_image.physical_pixel_sizes.X", "full_response": "\n    from aicsimageio import AICSImage\n    aics_image = AICSImage(image_filename)\n\n    return aics_image.physical_pixel_sizes.Z, \\\n            aics_image.physical_pixel_sizes.Y, \\\n            aics_image.physical_pixel_sizes.X", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_image_return_dimensions.ipynb", "completion": "\n    from skimage.io import imread\n    image = imread(image_file_location)\n    return image.shape", "full_response": "\n    from skimage.io import imread\n    image = imread(image_file_location)\n    return image.shape", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_nifti_image.ipynb", "completion": "\n    \n    import nibabel as nib\n    import numpy as nb\n\n    img = nib.load(image_file_location)\n    data = img.get_fdata()\n    return(data)", "full_response": "\n    \n    import nibabel as nib\n    import numpy as nb\n\n    img = nib.load(image_file_location)\n    data = img.get_fdata()\n    return(data)", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_zarr.ipynb", "completion": "\n    import zarr\n    array = zarr.load(zarr_file_location)\n    return array", "full_response": "\n    import zarr\n    array = zarr.load(zarr_file_location)\n    return array", "result": "passed", "passed": true}
{"task_id": "../test_cases/pair_wise_correlation_matrix.ipynb", "completion": "\n    return dataframe.corr()", "full_response": "\n    return dataframe.corr()", "result": "passed", "passed": true}
{"task_id": "../test_cases/radial_intensity_profile.ipynb", "completion": "\n    import numpy as np\n    y, x = np.indices((image.shape))\n    r = np.sqrt((x - xc)**2 + (y - yc)**2)\n    r = r.astype(int)\n    summed_values = np.bincount(r.ravel(), image.ravel())\n    number_of_pixels_at_r = np.bincount(r.ravel())\n    radial_profile = summed_values / number_of_pixels_at_r\n    return radial_profile ", "full_response": "\n    import numpy as np\n    y, x = np.indices((image.shape))\n    r = np.sqrt((x - xc)**2 + (y - yc)**2)\n    r = r.astype(int)\n    summed_values = np.bincount(r.ravel(), image.ravel())\n    number_of_pixels_at_r = np.bincount(r.ravel())\n    radial_profile = summed_values / number_of_pixels_at_r\n    return radial_profile ", "result": "passed", "passed": true}
{"task_id": "../test_cases/read_imagej_tif_metadata.ipynb", "completion": "\n    from tifffile import TiffFile\n    \n    with (TiffFile(image_filename) as tif):\n        imagej_metadata = tif.imagej_metadata\n    return imagej_metadata", "full_response": "\n    from tifffile import TiffFile\n    \n    with (TiffFile(image_filename) as tif):\n        imagej_metadata = tif.imagej_metadata\n    return imagej_metadata", "result": "passed", "passed": true}
{"task_id": "../test_cases/read_ome_metadata_from_ome_xml.ipynb", "completion": "\n    from ome_types import from_xml\n    ome = from_xml(img_path)\n    return ome.images[0]", "full_response": "\n    from ome_types import from_xml\n    ome = from_xml(img_path)\n    return ome.images[0]", "result": "failed: Could not parse XML from '../example_data/ome_xml_example.xml'", "passed": false}
{"task_id": "../test_cases/region_growing_segmentation.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.flood(image, point)", "full_response": "\n    import skimage\n    return skimage.segmentation.flood(image, point)", "result": "passed", "passed": true}
{"task_id": "../test_cases/register_timelapse.ipynb", "completion": "\n    from skimage import registration\n    import scipy.ndimage as ndi\n\n    new_video = video.copy()\n    ref_frame = new_video[-1]\n    for t in range(len(video) - 1, 0, -1):\n        mov_frame = video[t - 1]\n        shift, _, _ = registration.phase_cross_correlation(\n            ref_frame,\n            mov_frame,\n            upsample_factor=4,\n            normalization=None,\n        )\n        # replaces old ref_frame with shifted mov_frame\n        ref_frame = ndi.shift(mov_frame, shift, order=1)\n        new_video[t - 1] = ref_frame\n\n    return new_video", "full_response": "\n    from skimage import registration\n    import scipy.ndimage as ndi\n\n    new_video = video.copy()\n    ref_frame = new_video[-1]\n    for t in range(len(video) - 1, 0, -1):\n        mov_frame = video[t - 1]\n        shift, _, _ = registration.phase_cross_correlation(\n            ref_frame,\n            mov_frame,\n            upsample_factor=4,\n            normalization=None,\n        )\n        # replaces old ref_frame with shifted mov_frame\n        ref_frame = ndi.shift(mov_frame, shift, order=1)\n        new_video[t - 1] = ref_frame\n\n    return new_video", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_labels_on_edges.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.clear_border(label_image)", "full_response": "\n    import skimage\n    return skimage.segmentation.clear_border(label_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_noise_edge_preserving.ipynb", "completion": "\n    from scipy.ndimage import median_filter\n    filtered_image = median_filter(image, size=radius * 2 + 1)\n    return filtered_image", "full_response": "\n    from scipy.ndimage import median_filter\n    filtered_image = median_filter(image, size=radius * 2 + 1)\n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_small_labels.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.exclude_small_labels(label_image, maximum_size=size_threshold))", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.exclude_small_labels(label_image, maximum_size=size_threshold))", "result": "passed", "passed": true}
{"task_id": "../test_cases/reshape_array.ipynb", "completion": "\n    import numpy as np\n    \n    array = np.asarray(image)\n    array = np.transpose(array, axes=[2, 0, 1])\n    return array", "full_response": "\n    import numpy as np\n    \n    array = np.asarray(image)\n    array = np.transpose(array, axes=[2, 0, 1])\n    return array", "result": "passed", "passed": true}
{"task_id": "../test_cases/return_hello_world.ipynb", "completion": "\n    return \"hello world\"", "full_response": "\n    return \"hello world\"", "result": "passed", "passed": true}
{"task_id": "../test_cases/rgb_to_grey_image_transform.ipynb", "completion": "\n    rgb_sum = r + g + b\n    r = r / rgb_sum\n    g = g / rgb_sum\n    b = b / rgb_sum\n    \n    import numpy as np\n    channel_r = rgb_image[...,0]\n    channel_g = rgb_image[...,1]\n    channel_b = rgb_image[...,2]\n    grey_image = channel_r * r + \\\n                 channel_g * g + \\\n                 channel_b * b\n    \n    return grey_image", "full_response": "\n    rgb_sum = r + g + b\n    r = r / rgb_sum\n    g = g / rgb_sum\n    b = b / rgb_sum\n    \n    import numpy as np\n    channel_r = rgb_image[...,0]\n    channel_g = rgb_image[...,1]\n    channel_b = rgb_image[...,2]\n    grey_image = channel_r * r + \\\n                 channel_g * g + \\\n                 channel_b * b\n    \n    return grey_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/roi_imagej_to_ezomero.ipynb", "completion": "\n    list_of_tuples = list(dataframe.itertuples(index=False, name=None))\n    return list_of_tuples", "full_response": "\n    list_of_tuples = list(dataframe.itertuples(index=False, name=None))\n    return list_of_tuples", "result": "passed", "passed": true}
{"task_id": "../test_cases/rotate_image_by_90_degrees.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.rotate(image, angle_around_z_in_degrees=90))", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.rotate(image, angle_around_z_in_degrees=90))", "result": "passed", "passed": true}
{"task_id": "../test_cases/save_image_with_voxel_size.ipynb", "completion": "\n    from aicsimageio import AICSImage \n    from aicsimageio.types import PhysicalPixelSizes\n    from tempfile import tempdir\n    import os \n\n    image = AICSImage(image)\n    AICSImage.physical_pixel_sizes = PhysicalPixelSizes(Z=vz,Y=vy,X=vx)\n    img_path = os.path.join(tempdir, 'voxel_save_test.ome.tiff')\n    image.save(img_path)\n    return img_path", "full_response": "\n    from aicsimageio import AICSImage \n    from aicsimageio.types import PhysicalPixelSizes\n    from tempfile import tempdir\n    import os \n\n    image = AICSImage(image)\n    AICSImage.physical_pixel_sizes = PhysicalPixelSizes(Z=vz,Y=vy,X=vx)\n    img_path = os.path.join(tempdir, 'voxel_save_test.ome.tiff')\n    image.save(img_path)\n    return img_path", "result": "passed", "passed": true}
{"task_id": "../test_cases/scale_image_affine_transform.ipynb", "completion": "\n    from pyclesperanto_prototype import AffineTransform3D\n    import pyclesperanto_prototype as cle \n    import numpy as np\n    \n    output_img_shape =  (image.shape[0]*sy, image.shape[1]*sx)\n\n    transform = AffineTransform3D()\n    transform.center(image.shape)\n    transform.scale(scale_x = sx, scale_y = sy)\n    transform.center(output_img_shape,undo=True)\n    scaled_image = np.array(cle.affine_transform(image,transform=transform,auto_size=True))\n    return scaled_image, transform._matrix", "full_response": "\n    from pyclesperanto_prototype import AffineTransform3D\n    import pyclesperanto_prototype as cle \n    import numpy as np\n    \n    output_img_shape =  (image.shape[0]*sy, image.shape[1]*sx)\n\n    transform = AffineTransform3D()\n    transform.center(image.shape)\n    transform.scale(scale_x = sx, scale_y = sy)\n    transform.center(output_img_shape,undo=True)\n    scaled_image = np.array(cle.affine_transform(image,transform=transform,auto_size=True))\n    return scaled_image, transform._matrix", "result": "passed", "passed": true}
{"task_id": "../test_cases/select_coexpressing_cells.ipynb", "completion": "\n    import numpy as np\n    import pandas as pd\n    from skimage.measure import regionprops_table\n\n    df = pd.DataFrame(\n        regionprops_table(label_image, image, properties=(\"label\", \"area\", \"intensity_mean\"))\n    )\n    mean_cols = [c for c in df.columns if c.startswith(\"intensity_mean\")]\n    sum_cols = [f\"intensity_sum-{i}\" for i in range(len(mean_cols))]\n    \n    df[sum_cols] = df[mean_cols] * df[\"area\"].to_numpy()\n    \n    selected_ids = df.loc[(df[sum_cols] > threshold).all(axis=1), \"label\"].to_numpy()\n    \n    below_threshold_mask = np.isin(label_image, selected_ids, invert=False)\n    filtered_labels = label_image * below_threshold_mask\n\n    return filtered_labels", "full_response": "\n    import numpy as np\n    import pandas as pd\n    from skimage.measure import regionprops_table\n\n    df = pd.DataFrame(\n        regionprops_table(label_image, image, properties=(\"label\", \"area\", \"intensity_mean\"))\n    )\n    mean_cols = [c for c in df.columns if c.startswith(\"intensity_mean\")]\n    sum_cols = [f\"intensity_sum-{i}\" for i in range(len(mean_cols))]\n    \n    df[sum_cols] = df[mean_cols] * df[\"area\"].to_numpy()\n    \n    selected_ids = df.loc[(df[sum_cols] > threshold).all(axis=1), \"label\"].to_numpy()\n    \n    below_threshold_mask = np.isin(label_image, selected_ids, invert=False)\n    filtered_labels = label_image * below_threshold_mask\n\n    return filtered_labels", "result": "passed", "passed": true}
{"task_id": "../test_cases/stack_and_merge.ipynb", "completion": "\n    import numpy as np\n    stacked_image = np.stack((image1, image2), axis=0)\n    stitched_image = np.concatenate((stacked_image, image3), axis=2)\n    return stitched_image.shape", "full_response": "\n    import numpy as np\n    stacked_image = np.stack((image1, image2), axis=0)\n    stitched_image = np.concatenate((stacked_image, image3), axis=2)\n    return stitched_image.shape", "result": "passed", "passed": true}
{"task_id": "../test_cases/subsample_image.ipynb", "completion": "\n    return image[::n,::n]", "full_response": "\n    return image[::n,::n]", "result": "passed", "passed": true}
{"task_id": "../test_cases/subtract_background_tophat.ipynb", "completion": "\n    from skimage.morphology import white_tophat\n    from skimage.morphology import disk\n    filtered_image = white_tophat(image, footprint=disk(radius))\n    \n    return filtered_image", "full_response": "\n    from skimage.morphology import white_tophat\n    from skimage.morphology import disk\n    filtered_image = white_tophat(image, footprint=disk(radius))\n    \n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/sum_images.ipynb", "completion": "\n    return image1 + image2", "full_response": "\n    return image1 + image2", "result": "passed", "passed": true}
{"task_id": "../test_cases/sum_intensity_projection.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).sum(axis=0)", "full_response": "\n    import numpy as np\n    return np.asarray(image).sum(axis=0)", "result": "passed", "passed": true}
{"task_id": "../test_cases/tiled_image_processing.ipynb", "completion": "\n    import dask\n    import dask.array as da\n\n    tiles = da.from_array(image, chunks=(tile_size, tile_size))\n    \n    def procedure(image):\n        from scipy.ndimage import maximum_filter\n        return maximum_filter(image, size=radius*2+1)\n\n    # setup a lazy result (not computed yet)\n    tile_map = da.map_blocks(procedure, tiles)\n\n    # actually apply filter\n    result = tile_map.compute()\n\n    return result", "full_response": "\n    import dask\n    import dask.array as da\n\n    tiles = da.from_array(image, chunks=(tile_size, tile_size))\n    \n    def procedure(image):\n        from scipy.ndimage import maximum_filter\n        return maximum_filter(image, size=radius*2+1)\n\n    # setup a lazy result (not computed yet)\n    tile_map = da.map_blocks(procedure, tiles)\n\n    # actually apply filter\n    result = tile_map.compute()\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/translate_3d_image_along_vector.ipynb", "completion": "\n    from pyclesperanto_prototype import translate\n\n    # translate 3d image along t_x, t_y and t_z\n    return translate(image, translate_x = t_x, translate_y = t_y, translate_z = t_z)", "full_response": "\n    from pyclesperanto_prototype import translate\n\n    # translate 3d image along t_x, t_y and t_z\n    return translate(image, translate_x = t_x, translate_y = t_y, translate_z = t_z)", "result": "passed", "passed": true}
{"task_id": "../test_cases/transpose_image_axes.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).T", "full_response": "\n    import numpy as np\n    return np.asarray(image).T", "result": "passed", "passed": true}
{"task_id": "../test_cases/t_test.ipynb", "completion": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    return scipy.stats.ttest_rel(data1, data2)[1]\n    ", "full_response": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    return scipy.stats.ttest_rel(data1, data2)[1]\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_batch_process_folder_count_labels.ipynb", "completion": "\n    import os\n    from skimage.io import imread\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]\n    result = {}\n\n    for filename in file_list:\n        image = imread(folder_location + filename)\n\n        labels = np.unique(image).tolist()\n        labels.pop(0)\n\n        count = len(labels)\n\n        result[filename] = count\n\n    return result", "full_response": "\n    import os\n    from skimage.io import imread\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]\n    result = {}\n\n    for filename in file_list:\n        image = imread(folder_location + filename)\n\n        labels = np.unique(image).tolist()\n        labels.pop(0)\n\n        count = len(labels)\n\n        result[filename] = count\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_batch_process_folder_measure_intensity.ipynb", "completion": "\n    import os\n    import pandas as pd\n    from skimage.io import imread\n    from skimage.measure import regionprops\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(image_folder_location) if str(fn[-4:]) in supported_fileendings]\n\n    result = []\n\n    for filename in file_list:\n        image = imread(image_folder_location + filename)[...,0]\n        labels = imread(labels_folder_location + filename)\n\n        stats = regionprops(labels, intensity_image=image)\n\n        for s in stats:\n            result.append({\n                \"filename\":filename,\n                \"label\":s.label,\n                \"min_intensity\":s.min_intensity,\n                \"mean_intensity\":s.mean_intensity,\n                \"max_intensity\":s.max_intensity,\n            })\n\n    return pd.DataFrame(result)", "full_response": "\n    import os\n    import pandas as pd\n    from skimage.io import imread\n    from skimage.measure import regionprops\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(image_folder_location) if str(fn[-4:]) in supported_fileendings]\n\n    result = []\n\n    for filename in file_list:\n        image = imread(image_folder_location + filename)[...,0]\n        labels = imread(labels_folder_location + filename)\n\n        stats = regionprops(labels, intensity_image=image)\n\n        for s in stats:\n            result.append({\n                \"filename\":filename,\n                \"label\":s.label,\n                \"min_intensity\":s.min_intensity,\n                \"mean_intensity\":s.mean_intensity,\n                \"max_intensity\":s.max_intensity,\n            })\n\n    return pd.DataFrame(result)", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segmentation_counting.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    average_intensity = np.asarray(image).mean()\n    binary = image > average_intensity\n    labels = skimage.measure.label(binary)\n    return labels.max()", "full_response": "\n    import skimage\n    import numpy as np\n    average_intensity = np.asarray(image).mean()\n    binary = image > average_intensity\n    labels = skimage.measure.label(binary)\n    return labels.max()", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segmentation_measurement_summary.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n    label_image = skimage.measure.label(binary_image)\n    stats = skimage.measure.regionprops(label_image)\n    areas = [s.area for s in stats]\n    return np.mean(areas)", "full_response": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n    label_image = skimage.measure.label(binary_image)\n    stats = skimage.measure.regionprops(label_image)\n    areas = [s.area for s in stats]\n    return np.mean(areas)", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segment_measure_umap.ipynb", "completion": "\n    import numpy as np\n    import pandas as pd\n    import umap\n    from skimage.measure import label, regionprops_table\n\n    image = np.asarray(image)\n\n    # segment\n    binary = image > 0.5 * image.max()\n    labels = label(binary)\n\n    # measure\n    dataframe = pd.DataFrame(regionprops_table(labels, intensity_image=image, \n                                              properties=['area', 'perimeter', 'mean_intensity', \n                                                          'minor_axis_length', 'major_axis_length']))\n\n    # append UMAP\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    return dataframe", "full_response": "\n    import numpy as np\n    import pandas as pd\n    import umap\n    from skimage.measure import label, regionprops_table\n\n    image = np.asarray(image)\n\n    # segment\n    binary = image > 0.5 * image.max()\n    labels = label(binary)\n\n    # measure\n    dataframe = pd.DataFrame(regionprops_table(labels, intensity_image=image, \n                                              properties=['area', 'perimeter', 'mean_intensity', \n                                                          'minor_axis_length', 'major_axis_length']))\n\n    # append UMAP\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    return dataframe", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_watershed_segmentation_correction_measurement.ipynb", "completion": "\n    import skimage\n    blurred = skimage.filters.gaussian(image * 255, sigma=1)\n    minima = skimage.morphology.local_minima(blurred)\n    spots = skimage.measure.label(minima)\n    labels = skimage.segmentation.watershed(blurred, spots)\n    labels_without_border = skimage.segmentation.clear_border(labels)   \n    binary = labels_without_border > 0\n    return binary.sum()", "full_response": "\n    import skimage\n    blurred = skimage.filters.gaussian(image * 255, sigma=1)\n    minima = skimage.morphology.local_minima(blurred)\n    spots = skimage.measure.label(minima)\n    labels = skimage.segmentation.watershed(blurred, spots)\n    labels_without_border = skimage.segmentation.clear_border(labels)   \n    binary = labels_without_border > 0\n    return binary.sum()", "result": "passed", "passed": true}
{"task_id": "../test_cases/apply_otsu_threshold_and_count_positive_pixels.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n\n    result = np.sum(binary_image)\n\n    return result", "full_response": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n\n    result = np.sum(binary_image)\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/binary_closing.ipynb", "completion": "\n    import numpy as np\n    import skimage\n    size = radius * 2 + 1\n    return skimage.morphology.binary_closing(binary_image, footprint=np.ones((size, size)))", "full_response": "\n    import numpy as np\n    import skimage\n    size = radius * 2 + 1\n    return skimage.morphology.binary_closing(binary_image, footprint=np.ones((size, size)))", "result": "passed", "passed": true}
{"task_id": "../test_cases/binary_skeleton.ipynb", "completion": "\n    from skimage.morphology import skeletonize\n    return skeletonize(binary_image)", "full_response": "\n    from skimage.morphology import skeletonize\n    return skeletonize(binary_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/bland_altman.ipynb", "completion": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    dataframe['mean'] = (data1 + data2) / 2\n    dataframe['diff'] = data2 - data1\n    return dataframe", "full_response": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    dataframe['mean'] = (data1 + data2) / 2\n    dataframe['diff'] = data2 - data1\n    return dataframe", "result": "passed", "passed": true}
{"task_id": "../test_cases/combine_columns_of_tables.ipynb", "completion": "\n    import pandas as pd\n    return pd.merge(dataframe1, dataframe2, how='outer', on='label')", "full_response": "\n    import pandas as pd\n    return pd.merge(dataframe1, dataframe2, how='outer', on='label')", "result": "passed", "passed": true}
{"task_id": "../test_cases/convert_points_polygon.ipynb", "completion": "\n    from shapely import Polygon\n    polygon = Polygon(coordinates)\n    return polygon\n", "full_response": "\n    from shapely import Polygon\n    polygon = Polygon(coordinates)\n    return polygon\n", "result": "passed", "passed": true}
{"task_id": "../test_cases/convex_hull_measure_area.ipynb", "completion": "\n    import vedo\n    convex_hull = vedo.shapes.ConvexHull(point_cloud)\n    return convex_hull.area()", "full_response": "\n    import vedo\n    convex_hull = vedo.shapes.ConvexHull(point_cloud)\n    return convex_hull.area()", "result": "passed", "passed": true}
{"task_id": "../test_cases/convolve_images.ipynb", "completion": "\n    import scipy\n    return scipy.ndimage.convolve(image, kernel_image)\n    ", "full_response": "\n    import scipy\n    return scipy.ndimage.convolve(image, kernel_image)\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_number_of_touching_neighbors.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n\n    touch_matrix = cle.generate_touch_matrix(label_image)\n    cle.set_row(touch_matrix, 0, 0)\n    cle.set_column(touch_matrix, 0, 0)\n\n    return np.asarray(cle.sum_y_projection(touch_matrix))[0,1:].tolist()", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n\n    touch_matrix = cle.generate_touch_matrix(label_image)\n    cle.set_row(touch_matrix, 0, 0)\n    cle.set_column(touch_matrix, 0, 0)\n\n    return np.asarray(cle.sum_y_projection(touch_matrix))[0,1:].tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_objects_over_time.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import label\n    labels = [label(binary_image) for binary_image in binary_image_list]\n    return [len(np.unique(label)) - 1 for label in labels]", "full_response": "\n    import numpy as np\n    from skimage.measure import label\n    labels = [label(binary_image) for binary_image in binary_image_list]\n    return [len(np.unique(label)) - 1 for label in labels]", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_overlapping_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image_1, label_image_2, properties=('mean_intensity',))\n    return (pd.DataFrame(stats)['mean_intensity'] > 0).sum()", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image_1, label_image_2, properties=('mean_intensity',))\n    return (pd.DataFrame(stats)['mean_intensity'] > 0).sum()", "result": "passed", "passed": true}
{"task_id": "../test_cases/create_umap.ipynb", "completion": "\n    import umap\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    # no return value", "full_response": "\n    import umap\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    # no return value", "result": "passed", "passed": true}
{"task_id": "../test_cases/crop_quarter_image.ipynb", "completion": "\n    width = image.shape[1]\n    height = image.shape[0]\n\n    return image[:int(width/2),:int(height/2)]", "full_response": "\n    width = image.shape[1]\n    height = image.shape[0]\n\n    return image[:int(width/2),:int(height/2)]", "result": "passed", "passed": true}
{"task_id": "../test_cases/dataframe_column_rename.ipynb", "completion": "\n    for old_value, new_value in replacements.items():\n        df[column] = df[column].replace(old_value, new_value, regex=True)\n    return df", "full_response": "\n    for old_value, new_value in replacements.items():\n        df[column] = df[column].replace(old_value, new_value, regex=True)\n    return df", "result": "passed", "passed": true}
{"task_id": "../test_cases/deconvolve_image.ipynb", "completion": "\n    from scipy import fftpack\n\n    # adapted from: https://stackoverflow.com/questions/17473917/is-there-a-equivalent-of-scipy-signal-deconvolve-for-2d-arrays\n    star_fft = fftpack.fftshift(fftpack.fftn(image))\n    psf_fft = fftpack.fftshift(fftpack.fftn(kernel_image))\n    return fftpack.fftshift(fftpack.ifftn(fftpack.ifftshift(star_fft/psf_fft)))\n    ", "full_response": "\n    from scipy import fftpack\n\n    # adapted from: https://stackoverflow.com/questions/17473917/is-there-a-equivalent-of-scipy-signal-deconvolve-for-2d-arrays\n    star_fft = fftpack.fftshift(fftpack.fftn(image))\n    psf_fft = fftpack.fftshift(fftpack.fftn(kernel_image))\n    return fftpack.fftshift(fftpack.ifftn(fftpack.ifftshift(star_fft/psf_fft)))\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/detect_edges.ipynb", "completion": "\n    from scipy.ndimage import sobel\n    filtered_image = sobel(image)\n    return filtered_image", "full_response": "\n    from scipy.ndimage import sobel\n    filtered_image = sobel(image)\n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/detect_ellipse.ipynb", "completion": "\n    from skimage.transform import hough_ellipse\n    result = hough_ellipse(image,  accuracy=5, threshold=10)\n    result.sort(order='accumulator')\n    \n    # Estimated parameters for the ellipse\n    best = list(result[-1])\n    yc, xc, a, b = (int(round(x)) for x in best[1:5])\n    \n    return yc, xc", "full_response": "\n    from skimage.transform import hough_ellipse\n    result = hough_ellipse(image,  accuracy=5, threshold=10)\n    result.sort(order='accumulator')\n    \n    # Estimated parameters for the ellipse\n    best = list(result[-1])\n    yc, xc, a, b = (int(round(x)) for x in best[1:5])\n    \n    return yc, xc", "result": "passed", "passed": true}
{"task_id": "../test_cases/distance_between_maxima.ipynb", "completion": "\n    import numpy as np\n\n    im1 = np.asarray(image1)\n    im2 = np.asarray(image2)\n\n    x1,y1 = np.unravel_index(im1.argmax(), im1.shape)\n    x2,y2 = np.unravel_index(im2.argmax(), im2.shape)\n\n    distance = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n\n    return distance", "full_response": "\n    import numpy as np\n\n    im1 = np.asarray(image1)\n    im2 = np.asarray(image2)\n\n    x1,y1 = np.unravel_index(im1.argmax(), im1.shape)\n    x2,y2 = np.unravel_index(im2.argmax(), im2.shape)\n\n    distance = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n\n    return distance", "result": "passed", "passed": true}
{"task_id": "../test_cases/expand_labels_without_overlap.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.expand_labels(label_image, distance=radius)", "full_response": "\n    import skimage\n    return skimage.segmentation.expand_labels(label_image, distance=radius)", "result": "passed", "passed": true}
{"task_id": "../test_cases/extract_surface_measure_area.ipynb", "completion": "\n    import vedo\n    volume = vedo.Volume(binary_volume_image)\n    iso_surface = volume.isosurface()\n    return iso_surface.area()", "full_response": "\n    import vedo\n    volume = vedo.Volume(binary_volume_image)\n    iso_surface = volume.isosurface()\n    return iso_surface.area()", "result": "passed", "passed": true}
{"task_id": "../test_cases/fft_spectrum.ipynb", "completion": "\n        import numpy as np\n    \n        # computing padding tuple:\n        pad_width = ((padding, padding),)*nd_image.ndim\n    \n        # Padding:\n        image_padded = np.pad(nd_image, pad_width=pad_width, mode='symmetric')\n        \n        # prepare the apodization window in 1D:\n        from scipy import signal\n        window_tuple = (signal.windows.hamming(length+2*padding) for length in nd_image.shape)\n        \n        # prepare the apodization window in nD:\n        import functools\n        window = functools.reduce(np.multiply.outer, window_tuple)\n        \n        # Apodize:\n        image_padded_apodized = window*image_padded\n    \n        # Compute the Fourier transform of the image:\n        image_fft = np.fft.fftn(image_padded_apodized)\n        \n        # Shift the zero-frequency component to the center of the spectrum:\n        image_fft_shifted = np.fft.fftshift(image_fft)\n        \n        # Compute the magnitude spectrum:\n        magnitude_spectrum = np.log1p(np.abs(image_fft_shifted))\n            \n        return(magnitude_spectrum)\n    \n    import numpy as np   \n\n    # Test image:\n    image = np.ones((5, 6, 7), dtype=np.int16)\n\n    # Padding:\n    padding_width = 10\n\n    # running the candidate function:\n    magnitude_spectrum_candidate = candidate(image, padding_width)\n    \n    # Reference implementation:\n    magnitude_spectrum_reference = fft_spectrum_reference(image, padding_width)\n    \n    assert np.allclose(magnitude_spectrum_candidate, magnitude_spectrum_reference)", "full_response": "\n        import numpy as np\n    \n        # computing padding tuple:\n        pad_width = ((padding, padding),)*nd_image.ndim\n    \n        # Padding:\n        image_padded = np.pad(nd_image, pad_width=pad_width, mode='symmetric')\n        \n        # prepare the apodization window in 1D:\n        from scipy import signal\n        window_tuple = (signal.windows.hamming(length+2*padding) for length in nd_image.shape)\n        \n        # prepare the apodization window in nD:\n        import functools\n        window = functools.reduce(np.multiply.outer, window_tuple)\n        \n        # Apodize:\n        image_padded_apodized = window*image_padded\n    \n        # Compute the Fourier transform of the image:\n        image_fft = np.fft.fftn(image_padded_apodized)\n        \n        # Shift the zero-frequency component to the center of the spectrum:\n        image_fft_shifted = np.fft.fftshift(image_fft)\n        \n        # Compute the magnitude spectrum:\n        magnitude_spectrum = np.log1p(np.abs(image_fft_shifted))\n            \n        return(magnitude_spectrum)\n    \n    import numpy as np   \n\n    # Test image:\n    image = np.ones((5, 6, 7), dtype=np.int16)\n\n    # Padding:\n    padding_width = 10\n\n    # running the candidate function:\n    magnitude_spectrum_candidate = candidate(image, padding_width)\n    \n    # Reference implementation:\n    magnitude_spectrum_reference = fft_spectrum_reference(image, padding_width)\n    \n    assert np.allclose(magnitude_spectrum_candidate, magnitude_spectrum_reference)", "result": "timed out", "passed": false}
{"task_id": "../test_cases/find_closest_neighbors.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import centroid\n    \n    # Identify all centroid locations\n    label_count = np.max(label_image)\n    centroids = {}\n    for i in range(1, label_count + 1):\n        binary_image = (label_image == i)\n        centroids[i] = centroid(binary_image)\n    \n    # Find the closest top n\n    distances = [(other, np.linalg.norm(centroids[target_label] - centroids[other])) for other in centroids.keys() if other != target_label]\n    sorted_distances = sorted(distances, key = lambda pair: pair[1])\n    topn = [label for label, _ in sorted_distances[:n]]\n\n    return topn", "full_response": "\n    import numpy as np\n    from skimage.measure import centroid\n    \n    # Identify all centroid locations\n    label_count = np.max(label_image)\n    centroids = {}\n    for i in range(1, label_count + 1):\n        binary_image = (label_image == i)\n        centroids[i] = centroid(binary_image)\n    \n    # Find the closest top n\n    distances = [(other, np.linalg.norm(centroids[target_label] - centroids[other])) for other in centroids.keys() if other != target_label]\n    sorted_distances = sorted(distances, key = lambda pair: pair[1])\n    topn = [label for label, _ in sorted_distances[:n]]\n\n    return topn", "result": "passed", "passed": true}
{"task_id": "../test_cases/fit_circle.ipynb", "completion": "\n    import circle_fit as cf\n    xc, yc, r, _ = cf.least_squares_circle(list_of_2d_points)\n    return xc,yc,r", "full_response": "\n    import circle_fit as cf\n    xc, yc, r, _ = cf.least_squares_circle(list_of_2d_points)\n    return xc,yc,r", "result": "passed", "passed": true}
{"task_id": "../test_cases/fit_gaussian_to_spot.ipynb", "completion": "\n    import numpy as np\n    import scipy \n\n    image = np.asarray(image)\n    num_px = image.shape[0]\n    [xx, yy] = np.meshgrid(np.arange(0,num_px), np.arange(0,num_px))\n\n\n    def twoDGauss(x,y,ux,uy,sigma):\n        '''\n        Creates theoretical normalized 2D gaussian spot, centered around (ux,uy) \n        with standard deviation sigma, on grid specified by x and y\n        '''\n        p = 1/(2*np.pi*sigma**2) * np.exp(- ( (x-ux)**2+(y-uy)**2 ) / (2*sigma**2))\n        return p\n\n    def expected(x,y,params):   \n        '''\n        Creates simulated realistic Gaussian spot on x-y grid, with following\n        parameters = [x0,y0,sigma,bg,N], speficically:\n            - x0 = x-position of gaussian (px coord., first pixel is (0,0))\n            - y0 = y-positoin of gaussian (px coord.)\n            - sigma = stdev of gaussian (px coord)\n            - bg = number of photons in background\n            - N = number of photons in spot\n        '''\n        E = params[4] * twoDGauss(x,y,params[0],params[1],params[2]) + params[3]\n        return E\n\n    def SSE(params):\n        '''\n        Calculates sum-of-squared errors difference between 'image' and expected Gaussian defined by 'params'\n        This is essentially the cost-function that is minimized in the fit\n        '''\n        Expec = expected(xx,yy,params)\n        sse = np.sum((image -  Expec)**2)\n        return sse\n\n\n    #guess fit parameters:\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    sigma_guess = 2                 #assume sigma is 2 pixels\n    bg_guess = (np.sum(image) - np.sum(image[1:-1,1:-1]))/(4*num_px-4)           \n                                    #average of border pixels\n    N_guess = np.sum(image) - bg_guess * num_px**2\n                                    #sum of intensities, minus background\n    params_guess = [x_guess,x_guess,sigma_guess, bg_guess, N_guess]\n\n    #perform the fit\n    param = scipy.optimize.fmin(func=SSE,x0=params_guess, maxiter=10000,maxfun=10000,ftol=1e-5,disp=0)\n\n    xc_fit      = param[0]  #fitted x-position\n    yc_fit      = param[1]  #fitted y-position\n    sigma_fit   = param[2]  #fitted sigma\n\n    return (xc_fit, yc_fit, sigma_fit)", "full_response": "\n    import numpy as np\n    import scipy \n\n    image = np.asarray(image)\n    num_px = image.shape[0]\n    [xx, yy] = np.meshgrid(np.arange(0,num_px), np.arange(0,num_px))\n\n\n    def twoDGauss(x,y,ux,uy,sigma):\n        '''\n        Creates theoretical normalized 2D gaussian spot, centered around (ux,uy) \n        with standard deviation sigma, on grid specified by x and y\n        '''\n        p = 1/(2*np.pi*sigma**2) * np.exp(- ( (x-ux)**2+(y-uy)**2 ) / (2*sigma**2))\n        return p\n\n    def expected(x,y,params):   \n        '''\n        Creates simulated realistic Gaussian spot on x-y grid, with following\n        parameters = [x0,y0,sigma,bg,N], speficically:\n            - x0 = x-position of gaussian (px coord., first pixel is (0,0))\n            - y0 = y-positoin of gaussian (px coord.)\n            - sigma = stdev of gaussian (px coord)\n            - bg = number of photons in background\n            - N = number of photons in spot\n        '''\n        E = params[4] * twoDGauss(x,y,params[0],params[1],params[2]) + params[3]\n        return E\n\n    def SSE(params):\n        '''\n        Calculates sum-of-squared errors difference between 'image' and expected Gaussian defined by 'params'\n        This is essentially the cost-function that is minimized in the fit\n        '''\n        Expec = expected(xx,yy,params)\n        sse = np.sum((image -  Expec)**2)\n        return sse\n\n\n    #guess fit parameters:\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    sigma_guess = 2                 #assume sigma is 2 pixels\n    bg_guess = (np.sum(image) - np.sum(image[1:-1,1:-1]))/(4*num_px-4)           \n                                    #average of border pixels\n    N_guess = np.sum(image) - bg_guess * num_px**2\n                                    #sum of intensities, minus background\n    params_guess = [x_guess,x_guess,sigma_guess, bg_guess, N_guess]\n\n    #perform the fit\n    param = scipy.optimize.fmin(func=SSE,x0=params_guess, maxiter=10000,maxfun=10000,ftol=1e-5,disp=0)\n\n    xc_fit      = param[0]  #fitted x-position\n    yc_fit      = param[1]  #fitted y-position\n    sigma_fit   = param[2]  #fitted sigma\n\n    return (xc_fit, yc_fit, sigma_fit)", "result": "passed", "passed": true}
{"task_id": "../test_cases/flow_field_deformation.ipynb", "completion": "\n    import SimpleITK as sitk\n\n    target = sitk.GetImageFromArray(target)\n\n    displacement = sitk.DisplacementFieldTransform(2)\n    field_size = list(flow_field.shape[:2])\n    field_origin = [0, 0]\n    field_spacing = [1.0, 1.0]\n    field_direction = [1, 0, 0, 1]  # direction cosine matrix (row major order)\n\n    # Concatenate all the information into a single list\n    displacement.SetFixedParameters(\n        field_size + field_origin + field_spacing + field_direction\n    )\n    # Set the interpolator to nearest neighbor\n    displacement.SetInterpolator(sitk.sitkNearestNeighbor)\n\n    originalDisplacements = flow_field.reshape((-1, 2)).flatten()\n    displacement.SetParameters(originalDisplacements)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetTransform(displacement)\n    resampler.SetReferenceImage(target)\n    resampled = resampler.Execute(target)\n\n    return sitk.GetArrayFromImage(resampled)", "full_response": "\n    import SimpleITK as sitk\n\n    target = sitk.GetImageFromArray(target)\n\n    displacement = sitk.DisplacementFieldTransform(2)\n    field_size = list(flow_field.shape[:2])\n    field_origin = [0, 0]\n    field_spacing = [1.0, 1.0]\n    field_direction = [1, 0, 0, 1]  # direction cosine matrix (row major order)\n\n    # Concatenate all the information into a single list\n    displacement.SetFixedParameters(\n        field_size + field_origin + field_spacing + field_direction\n    )\n    # Set the interpolator to nearest neighbor\n    displacement.SetInterpolator(sitk.sitkNearestNeighbor)\n\n    originalDisplacements = flow_field.reshape((-1, 2)).flatten()\n    displacement.SetParameters(originalDisplacements)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetTransform(displacement)\n    resampler.SetReferenceImage(target)\n    resampled = resampler.Execute(target)\n\n    return sitk.GetArrayFromImage(resampled)", "result": "passed", "passed": true}
{"task_id": "../test_cases/generate_image_histogram.ipynb", "completion": "\n    import numpy as np\n    return np.histogram(image,bins=num_bins)[0]", "full_response": "\n    import numpy as np\n    return np.histogram(image,bins=num_bins)[0]", "result": "passed", "passed": true}
{"task_id": "../test_cases/identify_centroids.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import centroid\n    n = np.max(label_image)\n    out = {}\n    for i in range(1, n + 1):\n        binary_image = (label_image == i)\n        out[i] = centroid(binary_image)\n    return out", "full_response": "\n    import numpy as np\n    from skimage.measure import centroid\n    n = np.max(label_image)\n    out = {}\n    for i in range(1, n + 1):\n        binary_image = (label_image == i)\n        out[i] = centroid(binary_image)\n    return out", "result": "passed", "passed": true}
{"task_id": "../test_cases/interpolate_stack.ipynb", "completion": "\n    import numpy as np\n\n    return np.linspace(start_slice, end_slice, num)", "full_response": "\n    import numpy as np\n\n    return np.linspace(start_slice, end_slice, num)", "result": "passed", "passed": true}
{"task_id": "../test_cases/label_binary_image_and_count_labels.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    label_image = skimage.measure.label(binary_image)\n\n    return len(np.unique(label_image)) - 1", "full_response": "\n    import skimage\n    import numpy as np\n    label_image = skimage.measure.label(binary_image)\n\n    return len(np.unique(label_image)) - 1", "result": "passed", "passed": true}
{"task_id": "../test_cases/label_sequentially.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.relabel_sequential(label_image)[0]", "full_response": "\n    import skimage\n    return skimage.segmentation.relabel_sequential(label_image)[0]", "result": "passed", "passed": true}
{"task_id": "../test_cases/linear_intensity_profile.ipynb", "completion": "\n    from skimage.measure import profile_line\n    return profile_line(image, starting_point, ending_point)", "full_response": "\n    from skimage.measure import profile_line\n    return profile_line(image, starting_point, ending_point)", "result": "passed", "passed": true}
{"task_id": "../test_cases/list_image_files_in_folder.ipynb", "completion": "\n    import os\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    return [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]", "full_response": "\n    import os\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    return [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]", "result": "passed", "passed": true}
{"task_id": "../test_cases/load_tif_and_output_rgb.ipynb", "completion": "\n    from cv2 import imread, cvtColor, COLOR_BGR2RGB\n    image = imread(path_to_tif)\n    return cvtColor(image, COLOR_BGR2RGB)", "full_response": "\n    from cv2 import imread, cvtColor, COLOR_BGR2RGB\n    image = imread(path_to_tif)\n    return cvtColor(image, COLOR_BGR2RGB)", "result": "failed: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n", "passed": false}
{"task_id": "../test_cases/local_maxima_from_distance_transform.ipynb", "completion": "\n    import scipy.ndimage as ndi\n    import skimage.feature as skf\n    \n    distance_transform = ndi.distance_transform_edt(binary_image)\n    \n    image_max = ndi.maximum_filter(distance_transform, size=nms_window, mode='constant')\n    \n    # suppress non-maxima values by setting them to -1\n    mask = distance_transform == image_max\n    image_max[~mask] = -1\n    \n    local_maxima = skf.peak_local_max(image_max)\n\n    return local_maxima.tolist()", "full_response": "\n    import scipy.ndimage as ndi\n    import skimage.feature as skf\n    \n    distance_transform = ndi.distance_transform_edt(binary_image)\n    \n    image_max = ndi.maximum_filter(distance_transform, size=nms_window, mode='constant')\n    \n    # suppress non-maxima values by setting them to -1\n    mask = distance_transform == image_max\n    image_max[~mask] = -1\n    \n    local_maxima = skf.peak_local_max(image_max)\n\n    return local_maxima.tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/map_pixel_count_of_labels.ipynb", "completion": "\n    import pyclesperanto_prototype as cle\n    return cle.pixel_count_map(label_image)", "full_response": "\n    import pyclesperanto_prototype as cle\n    return cle.pixel_count_map(label_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/mask_image.ipynb", "completion": "\n    import numpy as np\n    return image * mask", "full_response": "\n    import numpy as np\n    return image * mask", "result": "passed", "passed": true}
{"task_id": "../test_cases/maximum_intensity_projection.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).max(axis=0)", "full_response": "\n    import numpy as np\n    return np.asarray(image).max(axis=0)", "result": "passed", "passed": true}
{"task_id": "../test_cases/mean_squared_error.ipynb", "completion": "\n    return ((image1 - image2)**2).mean()\n    # adapted from : https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy", "full_response": "\n    return ((image1 - image2)**2).mean()\n    # adapted from : https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy", "result": "passed", "passed": true}
{"task_id": "../test_cases/mean_std_column.ipynb", "completion": "\n    import numpy as np\n    data = dataframe[column]\n    return np.mean(data), np.std(data)", "full_response": "\n    import numpy as np\n    data = dataframe[column]\n    return np.mean(data), np.std(data)", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_aspect_ratio_of_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = pd.DataFrame(skimage.measure.regionprops_table(label_image, properties=('minor_axis_length', 'major_axis_length')))\n    stats['aspect_ratio'] = stats['major_axis_length'] / stats['minor_axis_length']\n    return stats", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = pd.DataFrame(skimage.measure.regionprops_table(label_image, properties=('minor_axis_length', 'major_axis_length')))\n    stats['aspect_ratio'] = stats['major_axis_length'] / stats['minor_axis_length']\n    return stats", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_intensity_of_labels.ipynb", "completion": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image, intensity_image)\n    return [s.mean_intensity for s in stats]", "full_response": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image, intensity_image)\n    return [s.mean_intensity for s in stats]", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_intensity_over_time.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image_list).mean(axis=(1,2)).tolist()", "full_response": "\n    import numpy as np\n    return np.asarray(image_list).mean(axis=(1,2)).tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_mean_image_intensity.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).mean()", "full_response": "\n    import numpy as np\n    return np.asarray(image).mean()", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_pixel_count_of_labels.ipynb", "completion": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image)\n    return [s.area for s in stats]", "full_response": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image)\n    return [s.area for s in stats]", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_properties_of_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\n    return pd.DataFrame(stats)", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\n    return pd.DataFrame(stats)", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_image_read_voxel_size.ipynb", "completion": "\n    from aicsimageio import AICSImage\n    aics_image = AICSImage(image_filename)\n\n    return aics_image.physical_pixel_sizes.Z, \\\n            aics_image.physical_pixel_sizes.Y, \\\n            aics_image.physical_pixel_sizes.X", "full_response": "\n    from aicsimageio import AICSImage\n    aics_image = AICSImage(image_filename)\n\n    return aics_image.physical_pixel_sizes.Z, \\\n            aics_image.physical_pixel_sizes.Y, \\\n            aics_image.physical_pixel_sizes.X", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_image_return_dimensions.ipynb", "completion": "\n    from skimage.io import imread\n    image = imread(image_file_location)\n    return image.shape", "full_response": "\n    from skimage.io import imread\n    image = imread(image_file_location)\n    return image.shape", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_nifti_image.ipynb", "completion": "\n    \n    import nibabel as nib\n    import numpy as nb\n\n    img = nib.load(image_file_location)\n    data = img.get_fdata()\n    return(data)", "full_response": "\n    \n    import nibabel as nib\n    import numpy as nb\n\n    img = nib.load(image_file_location)\n    data = img.get_fdata()\n    return(data)", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_zarr.ipynb", "completion": "\n    import zarr\n    array = zarr.load(zarr_file_location)\n    return array", "full_response": "\n    import zarr\n    array = zarr.load(zarr_file_location)\n    return array", "result": "passed", "passed": true}
{"task_id": "../test_cases/pair_wise_correlation_matrix.ipynb", "completion": "\n    return dataframe.corr()", "full_response": "\n    return dataframe.corr()", "result": "passed", "passed": true}
{"task_id": "../test_cases/radial_intensity_profile.ipynb", "completion": "\n    import numpy as np\n    y, x = np.indices((image.shape))\n    r = np.sqrt((x - xc)**2 + (y - yc)**2)\n    r = r.astype(int)\n    summed_values = np.bincount(r.ravel(), image.ravel())\n    number_of_pixels_at_r = np.bincount(r.ravel())\n    radial_profile = summed_values / number_of_pixels_at_r\n    return radial_profile ", "full_response": "\n    import numpy as np\n    y, x = np.indices((image.shape))\n    r = np.sqrt((x - xc)**2 + (y - yc)**2)\n    r = r.astype(int)\n    summed_values = np.bincount(r.ravel(), image.ravel())\n    number_of_pixels_at_r = np.bincount(r.ravel())\n    radial_profile = summed_values / number_of_pixels_at_r\n    return radial_profile ", "result": "passed", "passed": true}
{"task_id": "../test_cases/read_imagej_tif_metadata.ipynb", "completion": "\n    from tifffile import TiffFile\n    \n    with (TiffFile(image_filename) as tif):\n        imagej_metadata = tif.imagej_metadata\n    return imagej_metadata", "full_response": "\n    from tifffile import TiffFile\n    \n    with (TiffFile(image_filename) as tif):\n        imagej_metadata = tif.imagej_metadata\n    return imagej_metadata", "result": "passed", "passed": true}
{"task_id": "../test_cases/read_ome_metadata_from_ome_xml.ipynb", "completion": "\n    from ome_types import from_xml\n    ome = from_xml(img_path)\n    return ome.images[0]", "full_response": "\n    from ome_types import from_xml\n    ome = from_xml(img_path)\n    return ome.images[0]", "result": "failed: Could not parse XML from '../example_data/ome_xml_example.xml'", "passed": false}
{"task_id": "../test_cases/region_growing_segmentation.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.flood(image, point)", "full_response": "\n    import skimage\n    return skimage.segmentation.flood(image, point)", "result": "passed", "passed": true}
{"task_id": "../test_cases/register_timelapse.ipynb", "completion": "\n    from skimage import registration\n    import scipy.ndimage as ndi\n\n    new_video = video.copy()\n    ref_frame = new_video[-1]\n    for t in range(len(video) - 1, 0, -1):\n        mov_frame = video[t - 1]\n        shift, _, _ = registration.phase_cross_correlation(\n            ref_frame,\n            mov_frame,\n            upsample_factor=4,\n            normalization=None,\n        )\n        # replaces old ref_frame with shifted mov_frame\n        ref_frame = ndi.shift(mov_frame, shift, order=1)\n        new_video[t - 1] = ref_frame\n\n    return new_video", "full_response": "\n    from skimage import registration\n    import scipy.ndimage as ndi\n\n    new_video = video.copy()\n    ref_frame = new_video[-1]\n    for t in range(len(video) - 1, 0, -1):\n        mov_frame = video[t - 1]\n        shift, _, _ = registration.phase_cross_correlation(\n            ref_frame,\n            mov_frame,\n            upsample_factor=4,\n            normalization=None,\n        )\n        # replaces old ref_frame with shifted mov_frame\n        ref_frame = ndi.shift(mov_frame, shift, order=1)\n        new_video[t - 1] = ref_frame\n\n    return new_video", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_labels_on_edges.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.clear_border(label_image)", "full_response": "\n    import skimage\n    return skimage.segmentation.clear_border(label_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_noise_edge_preserving.ipynb", "completion": "\n    from scipy.ndimage import median_filter\n    filtered_image = median_filter(image, size=radius * 2 + 1)\n    return filtered_image", "full_response": "\n    from scipy.ndimage import median_filter\n    filtered_image = median_filter(image, size=radius * 2 + 1)\n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_small_labels.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.exclude_small_labels(label_image, maximum_size=size_threshold))", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.exclude_small_labels(label_image, maximum_size=size_threshold))", "result": "passed", "passed": true}
{"task_id": "../test_cases/reshape_array.ipynb", "completion": "\n    import numpy as np\n    \n    array = np.asarray(image)\n    array = np.transpose(array, axes=[2, 0, 1])\n    return array", "full_response": "\n    import numpy as np\n    \n    array = np.asarray(image)\n    array = np.transpose(array, axes=[2, 0, 1])\n    return array", "result": "passed", "passed": true}
{"task_id": "../test_cases/return_hello_world.ipynb", "completion": "\n    return \"hello world\"", "full_response": "\n    return \"hello world\"", "result": "passed", "passed": true}
{"task_id": "../test_cases/rgb_to_grey_image_transform.ipynb", "completion": "\n    rgb_sum = r + g + b\n    r = r / rgb_sum\n    g = g / rgb_sum\n    b = b / rgb_sum\n    \n    import numpy as np\n    channel_r = rgb_image[...,0]\n    channel_g = rgb_image[...,1]\n    channel_b = rgb_image[...,2]\n    grey_image = channel_r * r + \\\n                 channel_g * g + \\\n                 channel_b * b\n    \n    return grey_image", "full_response": "\n    rgb_sum = r + g + b\n    r = r / rgb_sum\n    g = g / rgb_sum\n    b = b / rgb_sum\n    \n    import numpy as np\n    channel_r = rgb_image[...,0]\n    channel_g = rgb_image[...,1]\n    channel_b = rgb_image[...,2]\n    grey_image = channel_r * r + \\\n                 channel_g * g + \\\n                 channel_b * b\n    \n    return grey_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/roi_imagej_to_ezomero.ipynb", "completion": "\n    list_of_tuples = list(dataframe.itertuples(index=False, name=None))\n    return list_of_tuples", "full_response": "\n    list_of_tuples = list(dataframe.itertuples(index=False, name=None))\n    return list_of_tuples", "result": "passed", "passed": true}
{"task_id": "../test_cases/rotate_image_by_90_degrees.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.rotate(image, angle_around_z_in_degrees=90))", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.rotate(image, angle_around_z_in_degrees=90))", "result": "passed", "passed": true}
{"task_id": "../test_cases/save_image_with_voxel_size.ipynb", "completion": "\n    from aicsimageio import AICSImage \n    from aicsimageio.types import PhysicalPixelSizes\n    from tempfile import tempdir\n    import os \n\n    image = AICSImage(image)\n    AICSImage.physical_pixel_sizes = PhysicalPixelSizes(Z=vz,Y=vy,X=vx)\n    img_path = os.path.join(tempdir, 'voxel_save_test.ome.tiff')\n    image.save(img_path)\n    return img_path", "full_response": "\n    from aicsimageio import AICSImage \n    from aicsimageio.types import PhysicalPixelSizes\n    from tempfile import tempdir\n    import os \n\n    image = AICSImage(image)\n    AICSImage.physical_pixel_sizes = PhysicalPixelSizes(Z=vz,Y=vy,X=vx)\n    img_path = os.path.join(tempdir, 'voxel_save_test.ome.tiff')\n    image.save(img_path)\n    return img_path", "result": "passed", "passed": true}
{"task_id": "../test_cases/scale_image_affine_transform.ipynb", "completion": "\n    from pyclesperanto_prototype import AffineTransform3D\n    import pyclesperanto_prototype as cle \n    import numpy as np\n    \n    output_img_shape =  (image.shape[0]*sy, image.shape[1]*sx)\n\n    transform = AffineTransform3D()\n    transform.center(image.shape)\n    transform.scale(scale_x = sx, scale_y = sy)\n    transform.center(output_img_shape,undo=True)\n    scaled_image = np.array(cle.affine_transform(image,transform=transform,auto_size=True))\n    return scaled_image, transform._matrix", "full_response": "\n    from pyclesperanto_prototype import AffineTransform3D\n    import pyclesperanto_prototype as cle \n    import numpy as np\n    \n    output_img_shape =  (image.shape[0]*sy, image.shape[1]*sx)\n\n    transform = AffineTransform3D()\n    transform.center(image.shape)\n    transform.scale(scale_x = sx, scale_y = sy)\n    transform.center(output_img_shape,undo=True)\n    scaled_image = np.array(cle.affine_transform(image,transform=transform,auto_size=True))\n    return scaled_image, transform._matrix", "result": "passed", "passed": true}
{"task_id": "../test_cases/select_coexpressing_cells.ipynb", "completion": "\n    import numpy as np\n    import pandas as pd\n    from skimage.measure import regionprops_table\n\n    df = pd.DataFrame(\n        regionprops_table(label_image, image, properties=(\"label\", \"area\", \"intensity_mean\"))\n    )\n    mean_cols = [c for c in df.columns if c.startswith(\"intensity_mean\")]\n    sum_cols = [f\"intensity_sum-{i}\" for i in range(len(mean_cols))]\n    \n    df[sum_cols] = df[mean_cols] * df[\"area\"].to_numpy()\n    \n    selected_ids = df.loc[(df[sum_cols] > threshold).all(axis=1), \"label\"].to_numpy()\n    \n    below_threshold_mask = np.isin(label_image, selected_ids, invert=False)\n    filtered_labels = label_image * below_threshold_mask\n\n    return filtered_labels", "full_response": "\n    import numpy as np\n    import pandas as pd\n    from skimage.measure import regionprops_table\n\n    df = pd.DataFrame(\n        regionprops_table(label_image, image, properties=(\"label\", \"area\", \"intensity_mean\"))\n    )\n    mean_cols = [c for c in df.columns if c.startswith(\"intensity_mean\")]\n    sum_cols = [f\"intensity_sum-{i}\" for i in range(len(mean_cols))]\n    \n    df[sum_cols] = df[mean_cols] * df[\"area\"].to_numpy()\n    \n    selected_ids = df.loc[(df[sum_cols] > threshold).all(axis=1), \"label\"].to_numpy()\n    \n    below_threshold_mask = np.isin(label_image, selected_ids, invert=False)\n    filtered_labels = label_image * below_threshold_mask\n\n    return filtered_labels", "result": "passed", "passed": true}
{"task_id": "../test_cases/stack_and_merge.ipynb", "completion": "\n    import numpy as np\n    stacked_image = np.stack((image1, image2), axis=0)\n    stitched_image = np.concatenate((stacked_image, image3), axis=2)\n    return stitched_image.shape", "full_response": "\n    import numpy as np\n    stacked_image = np.stack((image1, image2), axis=0)\n    stitched_image = np.concatenate((stacked_image, image3), axis=2)\n    return stitched_image.shape", "result": "passed", "passed": true}
{"task_id": "../test_cases/subsample_image.ipynb", "completion": "\n    return image[::n,::n]", "full_response": "\n    return image[::n,::n]", "result": "passed", "passed": true}
{"task_id": "../test_cases/subtract_background_tophat.ipynb", "completion": "\n    from skimage.morphology import white_tophat\n    from skimage.morphology import disk\n    filtered_image = white_tophat(image, footprint=disk(radius))\n    \n    return filtered_image", "full_response": "\n    from skimage.morphology import white_tophat\n    from skimage.morphology import disk\n    filtered_image = white_tophat(image, footprint=disk(radius))\n    \n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/sum_images.ipynb", "completion": "\n    return image1 + image2", "full_response": "\n    return image1 + image2", "result": "passed", "passed": true}
{"task_id": "../test_cases/sum_intensity_projection.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).sum(axis=0)", "full_response": "\n    import numpy as np\n    return np.asarray(image).sum(axis=0)", "result": "passed", "passed": true}
{"task_id": "../test_cases/tiled_image_processing.ipynb", "completion": "\n    import dask\n    import dask.array as da\n\n    tiles = da.from_array(image, chunks=(tile_size, tile_size))\n    \n    def procedure(image):\n        from scipy.ndimage import maximum_filter\n        return maximum_filter(image, size=radius*2+1)\n\n    # setup a lazy result (not computed yet)\n    tile_map = da.map_blocks(procedure, tiles)\n\n    # actually apply filter\n    result = tile_map.compute()\n\n    return result", "full_response": "\n    import dask\n    import dask.array as da\n\n    tiles = da.from_array(image, chunks=(tile_size, tile_size))\n    \n    def procedure(image):\n        from scipy.ndimage import maximum_filter\n        return maximum_filter(image, size=radius*2+1)\n\n    # setup a lazy result (not computed yet)\n    tile_map = da.map_blocks(procedure, tiles)\n\n    # actually apply filter\n    result = tile_map.compute()\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/translate_3d_image_along_vector.ipynb", "completion": "\n    from pyclesperanto_prototype import translate\n\n    # translate 3d image along t_x, t_y and t_z\n    return translate(image, translate_x = t_x, translate_y = t_y, translate_z = t_z)", "full_response": "\n    from pyclesperanto_prototype import translate\n\n    # translate 3d image along t_x, t_y and t_z\n    return translate(image, translate_x = t_x, translate_y = t_y, translate_z = t_z)", "result": "passed", "passed": true}
{"task_id": "../test_cases/transpose_image_axes.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).T", "full_response": "\n    import numpy as np\n    return np.asarray(image).T", "result": "passed", "passed": true}
{"task_id": "../test_cases/t_test.ipynb", "completion": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    return scipy.stats.ttest_rel(data1, data2)[1]\n    ", "full_response": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    return scipy.stats.ttest_rel(data1, data2)[1]\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_batch_process_folder_count_labels.ipynb", "completion": "\n    import os\n    from skimage.io import imread\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]\n    result = {}\n\n    for filename in file_list:\n        image = imread(folder_location + filename)\n\n        labels = np.unique(image).tolist()\n        labels.pop(0)\n\n        count = len(labels)\n\n        result[filename] = count\n\n    return result", "full_response": "\n    import os\n    from skimage.io import imread\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]\n    result = {}\n\n    for filename in file_list:\n        image = imread(folder_location + filename)\n\n        labels = np.unique(image).tolist()\n        labels.pop(0)\n\n        count = len(labels)\n\n        result[filename] = count\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_batch_process_folder_measure_intensity.ipynb", "completion": "\n    import os\n    import pandas as pd\n    from skimage.io import imread\n    from skimage.measure import regionprops\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(image_folder_location) if str(fn[-4:]) in supported_fileendings]\n\n    result = []\n\n    for filename in file_list:\n        image = imread(image_folder_location + filename)[...,0]\n        labels = imread(labels_folder_location + filename)\n\n        stats = regionprops(labels, intensity_image=image)\n\n        for s in stats:\n            result.append({\n                \"filename\":filename,\n                \"label\":s.label,\n                \"min_intensity\":s.min_intensity,\n                \"mean_intensity\":s.mean_intensity,\n                \"max_intensity\":s.max_intensity,\n            })\n\n    return pd.DataFrame(result)", "full_response": "\n    import os\n    import pandas as pd\n    from skimage.io import imread\n    from skimage.measure import regionprops\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(image_folder_location) if str(fn[-4:]) in supported_fileendings]\n\n    result = []\n\n    for filename in file_list:\n        image = imread(image_folder_location + filename)[...,0]\n        labels = imread(labels_folder_location + filename)\n\n        stats = regionprops(labels, intensity_image=image)\n\n        for s in stats:\n            result.append({\n                \"filename\":filename,\n                \"label\":s.label,\n                \"min_intensity\":s.min_intensity,\n                \"mean_intensity\":s.mean_intensity,\n                \"max_intensity\":s.max_intensity,\n            })\n\n    return pd.DataFrame(result)", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segmentation_counting.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    average_intensity = np.asarray(image).mean()\n    binary = image > average_intensity\n    labels = skimage.measure.label(binary)\n    return labels.max()", "full_response": "\n    import skimage\n    import numpy as np\n    average_intensity = np.asarray(image).mean()\n    binary = image > average_intensity\n    labels = skimage.measure.label(binary)\n    return labels.max()", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segmentation_measurement_summary.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n    label_image = skimage.measure.label(binary_image)\n    stats = skimage.measure.regionprops(label_image)\n    areas = [s.area for s in stats]\n    return np.mean(areas)", "full_response": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n    label_image = skimage.measure.label(binary_image)\n    stats = skimage.measure.regionprops(label_image)\n    areas = [s.area for s in stats]\n    return np.mean(areas)", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segment_measure_umap.ipynb", "completion": "\n    import numpy as np\n    import pandas as pd\n    import umap\n    from skimage.measure import label, regionprops_table\n\n    image = np.asarray(image)\n\n    # segment\n    binary = image > 0.5 * image.max()\n    labels = label(binary)\n\n    # measure\n    dataframe = pd.DataFrame(regionprops_table(labels, intensity_image=image, \n                                              properties=['area', 'perimeter', 'mean_intensity', \n                                                          'minor_axis_length', 'major_axis_length']))\n\n    # append UMAP\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    return dataframe", "full_response": "\n    import numpy as np\n    import pandas as pd\n    import umap\n    from skimage.measure import label, regionprops_table\n\n    image = np.asarray(image)\n\n    # segment\n    binary = image > 0.5 * image.max()\n    labels = label(binary)\n\n    # measure\n    dataframe = pd.DataFrame(regionprops_table(labels, intensity_image=image, \n                                              properties=['area', 'perimeter', 'mean_intensity', \n                                                          'minor_axis_length', 'major_axis_length']))\n\n    # append UMAP\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    return dataframe", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_watershed_segmentation_correction_measurement.ipynb", "completion": "\n    import skimage\n    blurred = skimage.filters.gaussian(image * 255, sigma=1)\n    minima = skimage.morphology.local_minima(blurred)\n    spots = skimage.measure.label(minima)\n    labels = skimage.segmentation.watershed(blurred, spots)\n    labels_without_border = skimage.segmentation.clear_border(labels)   \n    binary = labels_without_border > 0\n    return binary.sum()", "full_response": "\n    import skimage\n    blurred = skimage.filters.gaussian(image * 255, sigma=1)\n    minima = skimage.morphology.local_minima(blurred)\n    spots = skimage.measure.label(minima)\n    labels = skimage.segmentation.watershed(blurred, spots)\n    labels_without_border = skimage.segmentation.clear_border(labels)   \n    binary = labels_without_border > 0\n    return binary.sum()", "result": "passed", "passed": true}
{"task_id": "../test_cases/apply_otsu_threshold_and_count_positive_pixels.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n\n    result = np.sum(binary_image)\n\n    return result", "full_response": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n\n    result = np.sum(binary_image)\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/binary_closing.ipynb", "completion": "\n    import numpy as np\n    import skimage\n    size = radius * 2 + 1\n    return skimage.morphology.binary_closing(binary_image, footprint=np.ones((size, size)))", "full_response": "\n    import numpy as np\n    import skimage\n    size = radius * 2 + 1\n    return skimage.morphology.binary_closing(binary_image, footprint=np.ones((size, size)))", "result": "passed", "passed": true}
{"task_id": "../test_cases/binary_skeleton.ipynb", "completion": "\n    from skimage.morphology import skeletonize\n    return skeletonize(binary_image)", "full_response": "\n    from skimage.morphology import skeletonize\n    return skeletonize(binary_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/bland_altman.ipynb", "completion": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    dataframe['mean'] = (data1 + data2) / 2\n    dataframe['diff'] = data2 - data1\n    return dataframe", "full_response": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    dataframe['mean'] = (data1 + data2) / 2\n    dataframe['diff'] = data2 - data1\n    return dataframe", "result": "passed", "passed": true}
{"task_id": "../test_cases/combine_columns_of_tables.ipynb", "completion": "\n    import pandas as pd\n    return pd.merge(dataframe1, dataframe2, how='outer', on='label')", "full_response": "\n    import pandas as pd\n    return pd.merge(dataframe1, dataframe2, how='outer', on='label')", "result": "passed", "passed": true}
{"task_id": "../test_cases/convert_points_polygon.ipynb", "completion": "\n    from shapely import Polygon\n    polygon = Polygon(coordinates)\n    return polygon\n", "full_response": "\n    from shapely import Polygon\n    polygon = Polygon(coordinates)\n    return polygon\n", "result": "passed", "passed": true}
{"task_id": "../test_cases/convex_hull_measure_area.ipynb", "completion": "\n    import vedo\n    convex_hull = vedo.shapes.ConvexHull(point_cloud)\n    return convex_hull.area()", "full_response": "\n    import vedo\n    convex_hull = vedo.shapes.ConvexHull(point_cloud)\n    return convex_hull.area()", "result": "passed", "passed": true}
{"task_id": "../test_cases/convolve_images.ipynb", "completion": "\n    import scipy\n    return scipy.ndimage.convolve(image, kernel_image)\n    ", "full_response": "\n    import scipy\n    return scipy.ndimage.convolve(image, kernel_image)\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_number_of_touching_neighbors.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n\n    touch_matrix = cle.generate_touch_matrix(label_image)\n    cle.set_row(touch_matrix, 0, 0)\n    cle.set_column(touch_matrix, 0, 0)\n\n    return np.asarray(cle.sum_y_projection(touch_matrix))[0,1:].tolist()", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n\n    touch_matrix = cle.generate_touch_matrix(label_image)\n    cle.set_row(touch_matrix, 0, 0)\n    cle.set_column(touch_matrix, 0, 0)\n\n    return np.asarray(cle.sum_y_projection(touch_matrix))[0,1:].tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_objects_over_time.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import label\n    labels = [label(binary_image) for binary_image in binary_image_list]\n    return [len(np.unique(label)) - 1 for label in labels]", "full_response": "\n    import numpy as np\n    from skimage.measure import label\n    labels = [label(binary_image) for binary_image in binary_image_list]\n    return [len(np.unique(label)) - 1 for label in labels]", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_overlapping_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image_1, label_image_2, properties=('mean_intensity',))\n    return (pd.DataFrame(stats)['mean_intensity'] > 0).sum()", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image_1, label_image_2, properties=('mean_intensity',))\n    return (pd.DataFrame(stats)['mean_intensity'] > 0).sum()", "result": "passed", "passed": true}
{"task_id": "../test_cases/create_umap.ipynb", "completion": "\n    import umap\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    # no return value", "full_response": "\n    import umap\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    # no return value", "result": "passed", "passed": true}
{"task_id": "../test_cases/crop_quarter_image.ipynb", "completion": "\n    width = image.shape[1]\n    height = image.shape[0]\n\n    return image[:int(width/2),:int(height/2)]", "full_response": "\n    width = image.shape[1]\n    height = image.shape[0]\n\n    return image[:int(width/2),:int(height/2)]", "result": "passed", "passed": true}
{"task_id": "../test_cases/dataframe_column_rename.ipynb", "completion": "\n    for old_value, new_value in replacements.items():\n        df[column] = df[column].replace(old_value, new_value, regex=True)\n    return df", "full_response": "\n    for old_value, new_value in replacements.items():\n        df[column] = df[column].replace(old_value, new_value, regex=True)\n    return df", "result": "passed", "passed": true}
{"task_id": "../test_cases/deconvolve_image.ipynb", "completion": "\n    from scipy import fftpack\n\n    # adapted from: https://stackoverflow.com/questions/17473917/is-there-a-equivalent-of-scipy-signal-deconvolve-for-2d-arrays\n    star_fft = fftpack.fftshift(fftpack.fftn(image))\n    psf_fft = fftpack.fftshift(fftpack.fftn(kernel_image))\n    return fftpack.fftshift(fftpack.ifftn(fftpack.ifftshift(star_fft/psf_fft)))\n    ", "full_response": "\n    from scipy import fftpack\n\n    # adapted from: https://stackoverflow.com/questions/17473917/is-there-a-equivalent-of-scipy-signal-deconvolve-for-2d-arrays\n    star_fft = fftpack.fftshift(fftpack.fftn(image))\n    psf_fft = fftpack.fftshift(fftpack.fftn(kernel_image))\n    return fftpack.fftshift(fftpack.ifftn(fftpack.ifftshift(star_fft/psf_fft)))\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/detect_edges.ipynb", "completion": "\n    from scipy.ndimage import sobel\n    filtered_image = sobel(image)\n    return filtered_image", "full_response": "\n    from scipy.ndimage import sobel\n    filtered_image = sobel(image)\n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/detect_ellipse.ipynb", "completion": "\n    from skimage.transform import hough_ellipse\n    result = hough_ellipse(image,  accuracy=5, threshold=10)\n    result.sort(order='accumulator')\n    \n    # Estimated parameters for the ellipse\n    best = list(result[-1])\n    yc, xc, a, b = (int(round(x)) for x in best[1:5])\n    \n    return yc, xc", "full_response": "\n    from skimage.transform import hough_ellipse\n    result = hough_ellipse(image,  accuracy=5, threshold=10)\n    result.sort(order='accumulator')\n    \n    # Estimated parameters for the ellipse\n    best = list(result[-1])\n    yc, xc, a, b = (int(round(x)) for x in best[1:5])\n    \n    return yc, xc", "result": "passed", "passed": true}
{"task_id": "../test_cases/distance_between_maxima.ipynb", "completion": "\n    import numpy as np\n\n    im1 = np.asarray(image1)\n    im2 = np.asarray(image2)\n\n    x1,y1 = np.unravel_index(im1.argmax(), im1.shape)\n    x2,y2 = np.unravel_index(im2.argmax(), im2.shape)\n\n    distance = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n\n    return distance", "full_response": "\n    import numpy as np\n\n    im1 = np.asarray(image1)\n    im2 = np.asarray(image2)\n\n    x1,y1 = np.unravel_index(im1.argmax(), im1.shape)\n    x2,y2 = np.unravel_index(im2.argmax(), im2.shape)\n\n    distance = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n\n    return distance", "result": "passed", "passed": true}
{"task_id": "../test_cases/expand_labels_without_overlap.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.expand_labels(label_image, distance=radius)", "full_response": "\n    import skimage\n    return skimage.segmentation.expand_labels(label_image, distance=radius)", "result": "passed", "passed": true}
{"task_id": "../test_cases/extract_surface_measure_area.ipynb", "completion": "\n    import vedo\n    volume = vedo.Volume(binary_volume_image)\n    iso_surface = volume.isosurface()\n    return iso_surface.area()", "full_response": "\n    import vedo\n    volume = vedo.Volume(binary_volume_image)\n    iso_surface = volume.isosurface()\n    return iso_surface.area()", "result": "passed", "passed": true}
{"task_id": "../test_cases/fft_spectrum.ipynb", "completion": "\n        import numpy as np\n    \n        # computing padding tuple:\n        pad_width = ((padding, padding),)*nd_image.ndim\n    \n        # Padding:\n        image_padded = np.pad(nd_image, pad_width=pad_width, mode='symmetric')\n        \n        # prepare the apodization window in 1D:\n        from scipy import signal\n        window_tuple = (signal.windows.hamming(length+2*padding) for length in nd_image.shape)\n        \n        # prepare the apodization window in nD:\n        import functools\n        window = functools.reduce(np.multiply.outer, window_tuple)\n        \n        # Apodize:\n        image_padded_apodized = window*image_padded\n    \n        # Compute the Fourier transform of the image:\n        image_fft = np.fft.fftn(image_padded_apodized)\n        \n        # Shift the zero-frequency component to the center of the spectrum:\n        image_fft_shifted = np.fft.fftshift(image_fft)\n        \n        # Compute the magnitude spectrum:\n        magnitude_spectrum = np.log1p(np.abs(image_fft_shifted))\n            \n        return(magnitude_spectrum)\n    \n    import numpy as np   \n\n    # Test image:\n    image = np.ones((5, 6, 7), dtype=np.int16)\n\n    # Padding:\n    padding_width = 10\n\n    # running the candidate function:\n    magnitude_spectrum_candidate = candidate(image, padding_width)\n    \n    # Reference implementation:\n    magnitude_spectrum_reference = fft_spectrum_reference(image, padding_width)\n    \n    assert np.allclose(magnitude_spectrum_candidate, magnitude_spectrum_reference)", "full_response": "\n        import numpy as np\n    \n        # computing padding tuple:\n        pad_width = ((padding, padding),)*nd_image.ndim\n    \n        # Padding:\n        image_padded = np.pad(nd_image, pad_width=pad_width, mode='symmetric')\n        \n        # prepare the apodization window in 1D:\n        from scipy import signal\n        window_tuple = (signal.windows.hamming(length+2*padding) for length in nd_image.shape)\n        \n        # prepare the apodization window in nD:\n        import functools\n        window = functools.reduce(np.multiply.outer, window_tuple)\n        \n        # Apodize:\n        image_padded_apodized = window*image_padded\n    \n        # Compute the Fourier transform of the image:\n        image_fft = np.fft.fftn(image_padded_apodized)\n        \n        # Shift the zero-frequency component to the center of the spectrum:\n        image_fft_shifted = np.fft.fftshift(image_fft)\n        \n        # Compute the magnitude spectrum:\n        magnitude_spectrum = np.log1p(np.abs(image_fft_shifted))\n            \n        return(magnitude_spectrum)\n    \n    import numpy as np   \n\n    # Test image:\n    image = np.ones((5, 6, 7), dtype=np.int16)\n\n    # Padding:\n    padding_width = 10\n\n    # running the candidate function:\n    magnitude_spectrum_candidate = candidate(image, padding_width)\n    \n    # Reference implementation:\n    magnitude_spectrum_reference = fft_spectrum_reference(image, padding_width)\n    \n    assert np.allclose(magnitude_spectrum_candidate, magnitude_spectrum_reference)", "result": "timed out", "passed": false}
{"task_id": "../test_cases/find_closest_neighbors.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import centroid\n    \n    # Identify all centroid locations\n    label_count = np.max(label_image)\n    centroids = {}\n    for i in range(1, label_count + 1):\n        binary_image = (label_image == i)\n        centroids[i] = centroid(binary_image)\n    \n    # Find the closest top n\n    distances = [(other, np.linalg.norm(centroids[target_label] - centroids[other])) for other in centroids.keys() if other != target_label]\n    sorted_distances = sorted(distances, key = lambda pair: pair[1])\n    topn = [label for label, _ in sorted_distances[:n]]\n\n    return topn", "full_response": "\n    import numpy as np\n    from skimage.measure import centroid\n    \n    # Identify all centroid locations\n    label_count = np.max(label_image)\n    centroids = {}\n    for i in range(1, label_count + 1):\n        binary_image = (label_image == i)\n        centroids[i] = centroid(binary_image)\n    \n    # Find the closest top n\n    distances = [(other, np.linalg.norm(centroids[target_label] - centroids[other])) for other in centroids.keys() if other != target_label]\n    sorted_distances = sorted(distances, key = lambda pair: pair[1])\n    topn = [label for label, _ in sorted_distances[:n]]\n\n    return topn", "result": "passed", "passed": true}
{"task_id": "../test_cases/fit_circle.ipynb", "completion": "\n    import circle_fit as cf\n    xc, yc, r, _ = cf.least_squares_circle(list_of_2d_points)\n    return xc,yc,r", "full_response": "\n    import circle_fit as cf\n    xc, yc, r, _ = cf.least_squares_circle(list_of_2d_points)\n    return xc,yc,r", "result": "passed", "passed": true}
{"task_id": "../test_cases/fit_gaussian_to_spot.ipynb", "completion": "\n    import numpy as np\n    import scipy \n\n    image = np.asarray(image)\n    num_px = image.shape[0]\n    [xx, yy] = np.meshgrid(np.arange(0,num_px), np.arange(0,num_px))\n\n\n    def twoDGauss(x,y,ux,uy,sigma):\n        '''\n        Creates theoretical normalized 2D gaussian spot, centered around (ux,uy) \n        with standard deviation sigma, on grid specified by x and y\n        '''\n        p = 1/(2*np.pi*sigma**2) * np.exp(- ( (x-ux)**2+(y-uy)**2 ) / (2*sigma**2))\n        return p\n\n    def expected(x,y,params):   \n        '''\n        Creates simulated realistic Gaussian spot on x-y grid, with following\n        parameters = [x0,y0,sigma,bg,N], speficically:\n            - x0 = x-position of gaussian (px coord., first pixel is (0,0))\n            - y0 = y-positoin of gaussian (px coord.)\n            - sigma = stdev of gaussian (px coord)\n            - bg = number of photons in background\n            - N = number of photons in spot\n        '''\n        E = params[4] * twoDGauss(x,y,params[0],params[1],params[2]) + params[3]\n        return E\n\n    def SSE(params):\n        '''\n        Calculates sum-of-squared errors difference between 'image' and expected Gaussian defined by 'params'\n        This is essentially the cost-function that is minimized in the fit\n        '''\n        Expec = expected(xx,yy,params)\n        sse = np.sum((image -  Expec)**2)\n        return sse\n\n\n    #guess fit parameters:\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    sigma_guess = 2                 #assume sigma is 2 pixels\n    bg_guess = (np.sum(image) - np.sum(image[1:-1,1:-1]))/(4*num_px-4)           \n                                    #average of border pixels\n    N_guess = np.sum(image) - bg_guess * num_px**2\n                                    #sum of intensities, minus background\n    params_guess = [x_guess,x_guess,sigma_guess, bg_guess, N_guess]\n\n    #perform the fit\n    param = scipy.optimize.fmin(func=SSE,x0=params_guess, maxiter=10000,maxfun=10000,ftol=1e-5,disp=0)\n\n    xc_fit      = param[0]  #fitted x-position\n    yc_fit      = param[1]  #fitted y-position\n    sigma_fit   = param[2]  #fitted sigma\n\n    return (xc_fit, yc_fit, sigma_fit)", "full_response": "\n    import numpy as np\n    import scipy \n\n    image = np.asarray(image)\n    num_px = image.shape[0]\n    [xx, yy] = np.meshgrid(np.arange(0,num_px), np.arange(0,num_px))\n\n\n    def twoDGauss(x,y,ux,uy,sigma):\n        '''\n        Creates theoretical normalized 2D gaussian spot, centered around (ux,uy) \n        with standard deviation sigma, on grid specified by x and y\n        '''\n        p = 1/(2*np.pi*sigma**2) * np.exp(- ( (x-ux)**2+(y-uy)**2 ) / (2*sigma**2))\n        return p\n\n    def expected(x,y,params):   \n        '''\n        Creates simulated realistic Gaussian spot on x-y grid, with following\n        parameters = [x0,y0,sigma,bg,N], speficically:\n            - x0 = x-position of gaussian (px coord., first pixel is (0,0))\n            - y0 = y-positoin of gaussian (px coord.)\n            - sigma = stdev of gaussian (px coord)\n            - bg = number of photons in background\n            - N = number of photons in spot\n        '''\n        E = params[4] * twoDGauss(x,y,params[0],params[1],params[2]) + params[3]\n        return E\n\n    def SSE(params):\n        '''\n        Calculates sum-of-squared errors difference between 'image' and expected Gaussian defined by 'params'\n        This is essentially the cost-function that is minimized in the fit\n        '''\n        Expec = expected(xx,yy,params)\n        sse = np.sum((image -  Expec)**2)\n        return sse\n\n\n    #guess fit parameters:\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    sigma_guess = 2                 #assume sigma is 2 pixels\n    bg_guess = (np.sum(image) - np.sum(image[1:-1,1:-1]))/(4*num_px-4)           \n                                    #average of border pixels\n    N_guess = np.sum(image) - bg_guess * num_px**2\n                                    #sum of intensities, minus background\n    params_guess = [x_guess,x_guess,sigma_guess, bg_guess, N_guess]\n\n    #perform the fit\n    param = scipy.optimize.fmin(func=SSE,x0=params_guess, maxiter=10000,maxfun=10000,ftol=1e-5,disp=0)\n\n    xc_fit      = param[0]  #fitted x-position\n    yc_fit      = param[1]  #fitted y-position\n    sigma_fit   = param[2]  #fitted sigma\n\n    return (xc_fit, yc_fit, sigma_fit)", "result": "passed", "passed": true}
{"task_id": "../test_cases/flow_field_deformation.ipynb", "completion": "\n    import SimpleITK as sitk\n\n    target = sitk.GetImageFromArray(target)\n\n    displacement = sitk.DisplacementFieldTransform(2)\n    field_size = list(flow_field.shape[:2])\n    field_origin = [0, 0]\n    field_spacing = [1.0, 1.0]\n    field_direction = [1, 0, 0, 1]  # direction cosine matrix (row major order)\n\n    # Concatenate all the information into a single list\n    displacement.SetFixedParameters(\n        field_size + field_origin + field_spacing + field_direction\n    )\n    # Set the interpolator to nearest neighbor\n    displacement.SetInterpolator(sitk.sitkNearestNeighbor)\n\n    originalDisplacements = flow_field.reshape((-1, 2)).flatten()\n    displacement.SetParameters(originalDisplacements)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetTransform(displacement)\n    resampler.SetReferenceImage(target)\n    resampled = resampler.Execute(target)\n\n    return sitk.GetArrayFromImage(resampled)", "full_response": "\n    import SimpleITK as sitk\n\n    target = sitk.GetImageFromArray(target)\n\n    displacement = sitk.DisplacementFieldTransform(2)\n    field_size = list(flow_field.shape[:2])\n    field_origin = [0, 0]\n    field_spacing = [1.0, 1.0]\n    field_direction = [1, 0, 0, 1]  # direction cosine matrix (row major order)\n\n    # Concatenate all the information into a single list\n    displacement.SetFixedParameters(\n        field_size + field_origin + field_spacing + field_direction\n    )\n    # Set the interpolator to nearest neighbor\n    displacement.SetInterpolator(sitk.sitkNearestNeighbor)\n\n    originalDisplacements = flow_field.reshape((-1, 2)).flatten()\n    displacement.SetParameters(originalDisplacements)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetTransform(displacement)\n    resampler.SetReferenceImage(target)\n    resampled = resampler.Execute(target)\n\n    return sitk.GetArrayFromImage(resampled)", "result": "passed", "passed": true}
{"task_id": "../test_cases/generate_image_histogram.ipynb", "completion": "\n    import numpy as np\n    return np.histogram(image,bins=num_bins)[0]", "full_response": "\n    import numpy as np\n    return np.histogram(image,bins=num_bins)[0]", "result": "passed", "passed": true}
{"task_id": "../test_cases/identify_centroids.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import centroid\n    n = np.max(label_image)\n    out = {}\n    for i in range(1, n + 1):\n        binary_image = (label_image == i)\n        out[i] = centroid(binary_image)\n    return out", "full_response": "\n    import numpy as np\n    from skimage.measure import centroid\n    n = np.max(label_image)\n    out = {}\n    for i in range(1, n + 1):\n        binary_image = (label_image == i)\n        out[i] = centroid(binary_image)\n    return out", "result": "passed", "passed": true}
{"task_id": "../test_cases/interpolate_stack.ipynb", "completion": "\n    import numpy as np\n\n    return np.linspace(start_slice, end_slice, num)", "full_response": "\n    import numpy as np\n\n    return np.linspace(start_slice, end_slice, num)", "result": "passed", "passed": true}
{"task_id": "../test_cases/label_binary_image_and_count_labels.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    label_image = skimage.measure.label(binary_image)\n\n    return len(np.unique(label_image)) - 1", "full_response": "\n    import skimage\n    import numpy as np\n    label_image = skimage.measure.label(binary_image)\n\n    return len(np.unique(label_image)) - 1", "result": "passed", "passed": true}
{"task_id": "../test_cases/label_sequentially.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.relabel_sequential(label_image)[0]", "full_response": "\n    import skimage\n    return skimage.segmentation.relabel_sequential(label_image)[0]", "result": "passed", "passed": true}
{"task_id": "../test_cases/linear_intensity_profile.ipynb", "completion": "\n    from skimage.measure import profile_line\n    return profile_line(image, starting_point, ending_point)", "full_response": "\n    from skimage.measure import profile_line\n    return profile_line(image, starting_point, ending_point)", "result": "passed", "passed": true}
{"task_id": "../test_cases/list_image_files_in_folder.ipynb", "completion": "\n    import os\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    return [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]", "full_response": "\n    import os\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    return [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]", "result": "passed", "passed": true}
{"task_id": "../test_cases/load_tif_and_output_rgb.ipynb", "completion": "\n    from cv2 import imread, cvtColor, COLOR_BGR2RGB\n    image = imread(path_to_tif)\n    return cvtColor(image, COLOR_BGR2RGB)", "full_response": "\n    from cv2 import imread, cvtColor, COLOR_BGR2RGB\n    image = imread(path_to_tif)\n    return cvtColor(image, COLOR_BGR2RGB)", "result": "failed: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n", "passed": false}
{"task_id": "../test_cases/local_maxima_from_distance_transform.ipynb", "completion": "\n    import scipy.ndimage as ndi\n    import skimage.feature as skf\n    \n    distance_transform = ndi.distance_transform_edt(binary_image)\n    \n    image_max = ndi.maximum_filter(distance_transform, size=nms_window, mode='constant')\n    \n    # suppress non-maxima values by setting them to -1\n    mask = distance_transform == image_max\n    image_max[~mask] = -1\n    \n    local_maxima = skf.peak_local_max(image_max)\n\n    return local_maxima.tolist()", "full_response": "\n    import scipy.ndimage as ndi\n    import skimage.feature as skf\n    \n    distance_transform = ndi.distance_transform_edt(binary_image)\n    \n    image_max = ndi.maximum_filter(distance_transform, size=nms_window, mode='constant')\n    \n    # suppress non-maxima values by setting them to -1\n    mask = distance_transform == image_max\n    image_max[~mask] = -1\n    \n    local_maxima = skf.peak_local_max(image_max)\n\n    return local_maxima.tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/map_pixel_count_of_labels.ipynb", "completion": "\n    import pyclesperanto_prototype as cle\n    return cle.pixel_count_map(label_image)", "full_response": "\n    import pyclesperanto_prototype as cle\n    return cle.pixel_count_map(label_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/mask_image.ipynb", "completion": "\n    import numpy as np\n    return image * mask", "full_response": "\n    import numpy as np\n    return image * mask", "result": "passed", "passed": true}
{"task_id": "../test_cases/maximum_intensity_projection.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).max(axis=0)", "full_response": "\n    import numpy as np\n    return np.asarray(image).max(axis=0)", "result": "passed", "passed": true}
{"task_id": "../test_cases/mean_squared_error.ipynb", "completion": "\n    return ((image1 - image2)**2).mean()\n    # adapted from : https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy", "full_response": "\n    return ((image1 - image2)**2).mean()\n    # adapted from : https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy", "result": "passed", "passed": true}
{"task_id": "../test_cases/mean_std_column.ipynb", "completion": "\n    import numpy as np\n    data = dataframe[column]\n    return np.mean(data), np.std(data)", "full_response": "\n    import numpy as np\n    data = dataframe[column]\n    return np.mean(data), np.std(data)", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_aspect_ratio_of_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = pd.DataFrame(skimage.measure.regionprops_table(label_image, properties=('minor_axis_length', 'major_axis_length')))\n    stats['aspect_ratio'] = stats['major_axis_length'] / stats['minor_axis_length']\n    return stats", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = pd.DataFrame(skimage.measure.regionprops_table(label_image, properties=('minor_axis_length', 'major_axis_length')))\n    stats['aspect_ratio'] = stats['major_axis_length'] / stats['minor_axis_length']\n    return stats", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_intensity_of_labels.ipynb", "completion": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image, intensity_image)\n    return [s.mean_intensity for s in stats]", "full_response": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image, intensity_image)\n    return [s.mean_intensity for s in stats]", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_intensity_over_time.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image_list).mean(axis=(1,2)).tolist()", "full_response": "\n    import numpy as np\n    return np.asarray(image_list).mean(axis=(1,2)).tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_mean_image_intensity.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).mean()", "full_response": "\n    import numpy as np\n    return np.asarray(image).mean()", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_pixel_count_of_labels.ipynb", "completion": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image)\n    return [s.area for s in stats]", "full_response": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image)\n    return [s.area for s in stats]", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_properties_of_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\n    return pd.DataFrame(stats)", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\n    return pd.DataFrame(stats)", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_image_read_voxel_size.ipynb", "completion": "\n    from aicsimageio import AICSImage\n    aics_image = AICSImage(image_filename)\n\n    return aics_image.physical_pixel_sizes.Z, \\\n            aics_image.physical_pixel_sizes.Y, \\\n            aics_image.physical_pixel_sizes.X", "full_response": "\n    from aicsimageio import AICSImage\n    aics_image = AICSImage(image_filename)\n\n    return aics_image.physical_pixel_sizes.Z, \\\n            aics_image.physical_pixel_sizes.Y, \\\n            aics_image.physical_pixel_sizes.X", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_image_return_dimensions.ipynb", "completion": "\n    from skimage.io import imread\n    image = imread(image_file_location)\n    return image.shape", "full_response": "\n    from skimage.io import imread\n    image = imread(image_file_location)\n    return image.shape", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_nifti_image.ipynb", "completion": "\n    \n    import nibabel as nib\n    import numpy as nb\n\n    img = nib.load(image_file_location)\n    data = img.get_fdata()\n    return(data)", "full_response": "\n    \n    import nibabel as nib\n    import numpy as nb\n\n    img = nib.load(image_file_location)\n    data = img.get_fdata()\n    return(data)", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_zarr.ipynb", "completion": "\n    import zarr\n    array = zarr.load(zarr_file_location)\n    return array", "full_response": "\n    import zarr\n    array = zarr.load(zarr_file_location)\n    return array", "result": "passed", "passed": true}
{"task_id": "../test_cases/pair_wise_correlation_matrix.ipynb", "completion": "\n    return dataframe.corr()", "full_response": "\n    return dataframe.corr()", "result": "passed", "passed": true}
{"task_id": "../test_cases/radial_intensity_profile.ipynb", "completion": "\n    import numpy as np\n    y, x = np.indices((image.shape))\n    r = np.sqrt((x - xc)**2 + (y - yc)**2)\n    r = r.astype(int)\n    summed_values = np.bincount(r.ravel(), image.ravel())\n    number_of_pixels_at_r = np.bincount(r.ravel())\n    radial_profile = summed_values / number_of_pixels_at_r\n    return radial_profile ", "full_response": "\n    import numpy as np\n    y, x = np.indices((image.shape))\n    r = np.sqrt((x - xc)**2 + (y - yc)**2)\n    r = r.astype(int)\n    summed_values = np.bincount(r.ravel(), image.ravel())\n    number_of_pixels_at_r = np.bincount(r.ravel())\n    radial_profile = summed_values / number_of_pixels_at_r\n    return radial_profile ", "result": "passed", "passed": true}
{"task_id": "../test_cases/read_imagej_tif_metadata.ipynb", "completion": "\n    from tifffile import TiffFile\n    \n    with (TiffFile(image_filename) as tif):\n        imagej_metadata = tif.imagej_metadata\n    return imagej_metadata", "full_response": "\n    from tifffile import TiffFile\n    \n    with (TiffFile(image_filename) as tif):\n        imagej_metadata = tif.imagej_metadata\n    return imagej_metadata", "result": "passed", "passed": true}
{"task_id": "../test_cases/read_ome_metadata_from_ome_xml.ipynb", "completion": "\n    from ome_types import from_xml\n    ome = from_xml(img_path)\n    return ome.images[0]", "full_response": "\n    from ome_types import from_xml\n    ome = from_xml(img_path)\n    return ome.images[0]", "result": "failed: Could not parse XML from '../example_data/ome_xml_example.xml'", "passed": false}
{"task_id": "../test_cases/region_growing_segmentation.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.flood(image, point)", "full_response": "\n    import skimage\n    return skimage.segmentation.flood(image, point)", "result": "passed", "passed": true}
{"task_id": "../test_cases/register_timelapse.ipynb", "completion": "\n    from skimage import registration\n    import scipy.ndimage as ndi\n\n    new_video = video.copy()\n    ref_frame = new_video[-1]\n    for t in range(len(video) - 1, 0, -1):\n        mov_frame = video[t - 1]\n        shift, _, _ = registration.phase_cross_correlation(\n            ref_frame,\n            mov_frame,\n            upsample_factor=4,\n            normalization=None,\n        )\n        # replaces old ref_frame with shifted mov_frame\n        ref_frame = ndi.shift(mov_frame, shift, order=1)\n        new_video[t - 1] = ref_frame\n\n    return new_video", "full_response": "\n    from skimage import registration\n    import scipy.ndimage as ndi\n\n    new_video = video.copy()\n    ref_frame = new_video[-1]\n    for t in range(len(video) - 1, 0, -1):\n        mov_frame = video[t - 1]\n        shift, _, _ = registration.phase_cross_correlation(\n            ref_frame,\n            mov_frame,\n            upsample_factor=4,\n            normalization=None,\n        )\n        # replaces old ref_frame with shifted mov_frame\n        ref_frame = ndi.shift(mov_frame, shift, order=1)\n        new_video[t - 1] = ref_frame\n\n    return new_video", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_labels_on_edges.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.clear_border(label_image)", "full_response": "\n    import skimage\n    return skimage.segmentation.clear_border(label_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_noise_edge_preserving.ipynb", "completion": "\n    from scipy.ndimage import median_filter\n    filtered_image = median_filter(image, size=radius * 2 + 1)\n    return filtered_image", "full_response": "\n    from scipy.ndimage import median_filter\n    filtered_image = median_filter(image, size=radius * 2 + 1)\n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_small_labels.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.exclude_small_labels(label_image, maximum_size=size_threshold))", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.exclude_small_labels(label_image, maximum_size=size_threshold))", "result": "passed", "passed": true}
{"task_id": "../test_cases/reshape_array.ipynb", "completion": "\n    import numpy as np\n    \n    array = np.asarray(image)\n    array = np.transpose(array, axes=[2, 0, 1])\n    return array", "full_response": "\n    import numpy as np\n    \n    array = np.asarray(image)\n    array = np.transpose(array, axes=[2, 0, 1])\n    return array", "result": "passed", "passed": true}
{"task_id": "../test_cases/return_hello_world.ipynb", "completion": "\n    return \"hello world\"", "full_response": "\n    return \"hello world\"", "result": "passed", "passed": true}
{"task_id": "../test_cases/rgb_to_grey_image_transform.ipynb", "completion": "\n    rgb_sum = r + g + b\n    r = r / rgb_sum\n    g = g / rgb_sum\n    b = b / rgb_sum\n    \n    import numpy as np\n    channel_r = rgb_image[...,0]\n    channel_g = rgb_image[...,1]\n    channel_b = rgb_image[...,2]\n    grey_image = channel_r * r + \\\n                 channel_g * g + \\\n                 channel_b * b\n    \n    return grey_image", "full_response": "\n    rgb_sum = r + g + b\n    r = r / rgb_sum\n    g = g / rgb_sum\n    b = b / rgb_sum\n    \n    import numpy as np\n    channel_r = rgb_image[...,0]\n    channel_g = rgb_image[...,1]\n    channel_b = rgb_image[...,2]\n    grey_image = channel_r * r + \\\n                 channel_g * g + \\\n                 channel_b * b\n    \n    return grey_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/roi_imagej_to_ezomero.ipynb", "completion": "\n    list_of_tuples = list(dataframe.itertuples(index=False, name=None))\n    return list_of_tuples", "full_response": "\n    list_of_tuples = list(dataframe.itertuples(index=False, name=None))\n    return list_of_tuples", "result": "passed", "passed": true}
{"task_id": "../test_cases/rotate_image_by_90_degrees.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.rotate(image, angle_around_z_in_degrees=90))", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.rotate(image, angle_around_z_in_degrees=90))", "result": "passed", "passed": true}
{"task_id": "../test_cases/save_image_with_voxel_size.ipynb", "completion": "\n    from aicsimageio import AICSImage \n    from aicsimageio.types import PhysicalPixelSizes\n    from tempfile import tempdir\n    import os \n\n    image = AICSImage(image)\n    AICSImage.physical_pixel_sizes = PhysicalPixelSizes(Z=vz,Y=vy,X=vx)\n    img_path = os.path.join(tempdir, 'voxel_save_test.ome.tiff')\n    image.save(img_path)\n    return img_path", "full_response": "\n    from aicsimageio import AICSImage \n    from aicsimageio.types import PhysicalPixelSizes\n    from tempfile import tempdir\n    import os \n\n    image = AICSImage(image)\n    AICSImage.physical_pixel_sizes = PhysicalPixelSizes(Z=vz,Y=vy,X=vx)\n    img_path = os.path.join(tempdir, 'voxel_save_test.ome.tiff')\n    image.save(img_path)\n    return img_path", "result": "passed", "passed": true}
{"task_id": "../test_cases/scale_image_affine_transform.ipynb", "completion": "\n    from pyclesperanto_prototype import AffineTransform3D\n    import pyclesperanto_prototype as cle \n    import numpy as np\n    \n    output_img_shape =  (image.shape[0]*sy, image.shape[1]*sx)\n\n    transform = AffineTransform3D()\n    transform.center(image.shape)\n    transform.scale(scale_x = sx, scale_y = sy)\n    transform.center(output_img_shape,undo=True)\n    scaled_image = np.array(cle.affine_transform(image,transform=transform,auto_size=True))\n    return scaled_image, transform._matrix", "full_response": "\n    from pyclesperanto_prototype import AffineTransform3D\n    import pyclesperanto_prototype as cle \n    import numpy as np\n    \n    output_img_shape =  (image.shape[0]*sy, image.shape[1]*sx)\n\n    transform = AffineTransform3D()\n    transform.center(image.shape)\n    transform.scale(scale_x = sx, scale_y = sy)\n    transform.center(output_img_shape,undo=True)\n    scaled_image = np.array(cle.affine_transform(image,transform=transform,auto_size=True))\n    return scaled_image, transform._matrix", "result": "passed", "passed": true}
{"task_id": "../test_cases/select_coexpressing_cells.ipynb", "completion": "\n    import numpy as np\n    import pandas as pd\n    from skimage.measure import regionprops_table\n\n    df = pd.DataFrame(\n        regionprops_table(label_image, image, properties=(\"label\", \"area\", \"intensity_mean\"))\n    )\n    mean_cols = [c for c in df.columns if c.startswith(\"intensity_mean\")]\n    sum_cols = [f\"intensity_sum-{i}\" for i in range(len(mean_cols))]\n    \n    df[sum_cols] = df[mean_cols] * df[\"area\"].to_numpy()\n    \n    selected_ids = df.loc[(df[sum_cols] > threshold).all(axis=1), \"label\"].to_numpy()\n    \n    below_threshold_mask = np.isin(label_image, selected_ids, invert=False)\n    filtered_labels = label_image * below_threshold_mask\n\n    return filtered_labels", "full_response": "\n    import numpy as np\n    import pandas as pd\n    from skimage.measure import regionprops_table\n\n    df = pd.DataFrame(\n        regionprops_table(label_image, image, properties=(\"label\", \"area\", \"intensity_mean\"))\n    )\n    mean_cols = [c for c in df.columns if c.startswith(\"intensity_mean\")]\n    sum_cols = [f\"intensity_sum-{i}\" for i in range(len(mean_cols))]\n    \n    df[sum_cols] = df[mean_cols] * df[\"area\"].to_numpy()\n    \n    selected_ids = df.loc[(df[sum_cols] > threshold).all(axis=1), \"label\"].to_numpy()\n    \n    below_threshold_mask = np.isin(label_image, selected_ids, invert=False)\n    filtered_labels = label_image * below_threshold_mask\n\n    return filtered_labels", "result": "passed", "passed": true}
{"task_id": "../test_cases/stack_and_merge.ipynb", "completion": "\n    import numpy as np\n    stacked_image = np.stack((image1, image2), axis=0)\n    stitched_image = np.concatenate((stacked_image, image3), axis=2)\n    return stitched_image.shape", "full_response": "\n    import numpy as np\n    stacked_image = np.stack((image1, image2), axis=0)\n    stitched_image = np.concatenate((stacked_image, image3), axis=2)\n    return stitched_image.shape", "result": "passed", "passed": true}
{"task_id": "../test_cases/subsample_image.ipynb", "completion": "\n    return image[::n,::n]", "full_response": "\n    return image[::n,::n]", "result": "passed", "passed": true}
{"task_id": "../test_cases/subtract_background_tophat.ipynb", "completion": "\n    from skimage.morphology import white_tophat\n    from skimage.morphology import disk\n    filtered_image = white_tophat(image, footprint=disk(radius))\n    \n    return filtered_image", "full_response": "\n    from skimage.morphology import white_tophat\n    from skimage.morphology import disk\n    filtered_image = white_tophat(image, footprint=disk(radius))\n    \n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/sum_images.ipynb", "completion": "\n    return image1 + image2", "full_response": "\n    return image1 + image2", "result": "passed", "passed": true}
{"task_id": "../test_cases/sum_intensity_projection.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).sum(axis=0)", "full_response": "\n    import numpy as np\n    return np.asarray(image).sum(axis=0)", "result": "passed", "passed": true}
{"task_id": "../test_cases/tiled_image_processing.ipynb", "completion": "\n    import dask\n    import dask.array as da\n\n    tiles = da.from_array(image, chunks=(tile_size, tile_size))\n    \n    def procedure(image):\n        from scipy.ndimage import maximum_filter\n        return maximum_filter(image, size=radius*2+1)\n\n    # setup a lazy result (not computed yet)\n    tile_map = da.map_blocks(procedure, tiles)\n\n    # actually apply filter\n    result = tile_map.compute()\n\n    return result", "full_response": "\n    import dask\n    import dask.array as da\n\n    tiles = da.from_array(image, chunks=(tile_size, tile_size))\n    \n    def procedure(image):\n        from scipy.ndimage import maximum_filter\n        return maximum_filter(image, size=radius*2+1)\n\n    # setup a lazy result (not computed yet)\n    tile_map = da.map_blocks(procedure, tiles)\n\n    # actually apply filter\n    result = tile_map.compute()\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/translate_3d_image_along_vector.ipynb", "completion": "\n    from pyclesperanto_prototype import translate\n\n    # translate 3d image along t_x, t_y and t_z\n    return translate(image, translate_x = t_x, translate_y = t_y, translate_z = t_z)", "full_response": "\n    from pyclesperanto_prototype import translate\n\n    # translate 3d image along t_x, t_y and t_z\n    return translate(image, translate_x = t_x, translate_y = t_y, translate_z = t_z)", "result": "passed", "passed": true}
{"task_id": "../test_cases/transpose_image_axes.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).T", "full_response": "\n    import numpy as np\n    return np.asarray(image).T", "result": "passed", "passed": true}
{"task_id": "../test_cases/t_test.ipynb", "completion": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    return scipy.stats.ttest_rel(data1, data2)[1]\n    ", "full_response": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    return scipy.stats.ttest_rel(data1, data2)[1]\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_batch_process_folder_count_labels.ipynb", "completion": "\n    import os\n    from skimage.io import imread\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]\n    result = {}\n\n    for filename in file_list:\n        image = imread(folder_location + filename)\n\n        labels = np.unique(image).tolist()\n        labels.pop(0)\n\n        count = len(labels)\n\n        result[filename] = count\n\n    return result", "full_response": "\n    import os\n    from skimage.io import imread\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]\n    result = {}\n\n    for filename in file_list:\n        image = imread(folder_location + filename)\n\n        labels = np.unique(image).tolist()\n        labels.pop(0)\n\n        count = len(labels)\n\n        result[filename] = count\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_batch_process_folder_measure_intensity.ipynb", "completion": "\n    import os\n    import pandas as pd\n    from skimage.io import imread\n    from skimage.measure import regionprops\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(image_folder_location) if str(fn[-4:]) in supported_fileendings]\n\n    result = []\n\n    for filename in file_list:\n        image = imread(image_folder_location + filename)[...,0]\n        labels = imread(labels_folder_location + filename)\n\n        stats = regionprops(labels, intensity_image=image)\n\n        for s in stats:\n            result.append({\n                \"filename\":filename,\n                \"label\":s.label,\n                \"min_intensity\":s.min_intensity,\n                \"mean_intensity\":s.mean_intensity,\n                \"max_intensity\":s.max_intensity,\n            })\n\n    return pd.DataFrame(result)", "full_response": "\n    import os\n    import pandas as pd\n    from skimage.io import imread\n    from skimage.measure import regionprops\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(image_folder_location) if str(fn[-4:]) in supported_fileendings]\n\n    result = []\n\n    for filename in file_list:\n        image = imread(image_folder_location + filename)[...,0]\n        labels = imread(labels_folder_location + filename)\n\n        stats = regionprops(labels, intensity_image=image)\n\n        for s in stats:\n            result.append({\n                \"filename\":filename,\n                \"label\":s.label,\n                \"min_intensity\":s.min_intensity,\n                \"mean_intensity\":s.mean_intensity,\n                \"max_intensity\":s.max_intensity,\n            })\n\n    return pd.DataFrame(result)", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segmentation_counting.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    average_intensity = np.asarray(image).mean()\n    binary = image > average_intensity\n    labels = skimage.measure.label(binary)\n    return labels.max()", "full_response": "\n    import skimage\n    import numpy as np\n    average_intensity = np.asarray(image).mean()\n    binary = image > average_intensity\n    labels = skimage.measure.label(binary)\n    return labels.max()", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segmentation_measurement_summary.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n    label_image = skimage.measure.label(binary_image)\n    stats = skimage.measure.regionprops(label_image)\n    areas = [s.area for s in stats]\n    return np.mean(areas)", "full_response": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n    label_image = skimage.measure.label(binary_image)\n    stats = skimage.measure.regionprops(label_image)\n    areas = [s.area for s in stats]\n    return np.mean(areas)", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segment_measure_umap.ipynb", "completion": "\n    import numpy as np\n    import pandas as pd\n    import umap\n    from skimage.measure import label, regionprops_table\n\n    image = np.asarray(image)\n\n    # segment\n    binary = image > 0.5 * image.max()\n    labels = label(binary)\n\n    # measure\n    dataframe = pd.DataFrame(regionprops_table(labels, intensity_image=image, \n                                              properties=['area', 'perimeter', 'mean_intensity', \n                                                          'minor_axis_length', 'major_axis_length']))\n\n    # append UMAP\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    return dataframe", "full_response": "\n    import numpy as np\n    import pandas as pd\n    import umap\n    from skimage.measure import label, regionprops_table\n\n    image = np.asarray(image)\n\n    # segment\n    binary = image > 0.5 * image.max()\n    labels = label(binary)\n\n    # measure\n    dataframe = pd.DataFrame(regionprops_table(labels, intensity_image=image, \n                                              properties=['area', 'perimeter', 'mean_intensity', \n                                                          'minor_axis_length', 'major_axis_length']))\n\n    # append UMAP\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    return dataframe", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_watershed_segmentation_correction_measurement.ipynb", "completion": "\n    import skimage\n    blurred = skimage.filters.gaussian(image * 255, sigma=1)\n    minima = skimage.morphology.local_minima(blurred)\n    spots = skimage.measure.label(minima)\n    labels = skimage.segmentation.watershed(blurred, spots)\n    labels_without_border = skimage.segmentation.clear_border(labels)   \n    binary = labels_without_border > 0\n    return binary.sum()", "full_response": "\n    import skimage\n    blurred = skimage.filters.gaussian(image * 255, sigma=1)\n    minima = skimage.morphology.local_minima(blurred)\n    spots = skimage.measure.label(minima)\n    labels = skimage.segmentation.watershed(blurred, spots)\n    labels_without_border = skimage.segmentation.clear_border(labels)   \n    binary = labels_without_border > 0\n    return binary.sum()", "result": "passed", "passed": true}
{"task_id": "../test_cases/apply_otsu_threshold_and_count_positive_pixels.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n\n    result = np.sum(binary_image)\n\n    return result", "full_response": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n\n    result = np.sum(binary_image)\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/binary_closing.ipynb", "completion": "\n    import numpy as np\n    import skimage\n    size = radius * 2 + 1\n    return skimage.morphology.binary_closing(binary_image, footprint=np.ones((size, size)))", "full_response": "\n    import numpy as np\n    import skimage\n    size = radius * 2 + 1\n    return skimage.morphology.binary_closing(binary_image, footprint=np.ones((size, size)))", "result": "passed", "passed": true}
{"task_id": "../test_cases/binary_skeleton.ipynb", "completion": "\n    from skimage.morphology import skeletonize\n    return skeletonize(binary_image)", "full_response": "\n    from skimage.morphology import skeletonize\n    return skeletonize(binary_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/bland_altman.ipynb", "completion": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    dataframe['mean'] = (data1 + data2) / 2\n    dataframe['diff'] = data2 - data1\n    return dataframe", "full_response": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    dataframe['mean'] = (data1 + data2) / 2\n    dataframe['diff'] = data2 - data1\n    return dataframe", "result": "passed", "passed": true}
{"task_id": "../test_cases/combine_columns_of_tables.ipynb", "completion": "\n    import pandas as pd\n    return pd.merge(dataframe1, dataframe2, how='outer', on='label')", "full_response": "\n    import pandas as pd\n    return pd.merge(dataframe1, dataframe2, how='outer', on='label')", "result": "passed", "passed": true}
{"task_id": "../test_cases/convert_points_polygon.ipynb", "completion": "\n    from shapely import Polygon\n    polygon = Polygon(coordinates)\n    return polygon\n", "full_response": "\n    from shapely import Polygon\n    polygon = Polygon(coordinates)\n    return polygon\n", "result": "passed", "passed": true}
{"task_id": "../test_cases/convex_hull_measure_area.ipynb", "completion": "\n    import vedo\n    convex_hull = vedo.shapes.ConvexHull(point_cloud)\n    return convex_hull.area()", "full_response": "\n    import vedo\n    convex_hull = vedo.shapes.ConvexHull(point_cloud)\n    return convex_hull.area()", "result": "passed", "passed": true}
{"task_id": "../test_cases/convolve_images.ipynb", "completion": "\n    import scipy\n    return scipy.ndimage.convolve(image, kernel_image)\n    ", "full_response": "\n    import scipy\n    return scipy.ndimage.convolve(image, kernel_image)\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_number_of_touching_neighbors.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n\n    touch_matrix = cle.generate_touch_matrix(label_image)\n    cle.set_row(touch_matrix, 0, 0)\n    cle.set_column(touch_matrix, 0, 0)\n\n    return np.asarray(cle.sum_y_projection(touch_matrix))[0,1:].tolist()", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n\n    touch_matrix = cle.generate_touch_matrix(label_image)\n    cle.set_row(touch_matrix, 0, 0)\n    cle.set_column(touch_matrix, 0, 0)\n\n    return np.asarray(cle.sum_y_projection(touch_matrix))[0,1:].tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_objects_over_time.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import label\n    labels = [label(binary_image) for binary_image in binary_image_list]\n    return [len(np.unique(label)) - 1 for label in labels]", "full_response": "\n    import numpy as np\n    from skimage.measure import label\n    labels = [label(binary_image) for binary_image in binary_image_list]\n    return [len(np.unique(label)) - 1 for label in labels]", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_overlapping_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image_1, label_image_2, properties=('mean_intensity',))\n    return (pd.DataFrame(stats)['mean_intensity'] > 0).sum()", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image_1, label_image_2, properties=('mean_intensity',))\n    return (pd.DataFrame(stats)['mean_intensity'] > 0).sum()", "result": "passed", "passed": true}
{"task_id": "../test_cases/create_umap.ipynb", "completion": "\n    import umap\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    # no return value", "full_response": "\n    import umap\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    # no return value", "result": "passed", "passed": true}
{"task_id": "../test_cases/crop_quarter_image.ipynb", "completion": "\n    width = image.shape[1]\n    height = image.shape[0]\n\n    return image[:int(width/2),:int(height/2)]", "full_response": "\n    width = image.shape[1]\n    height = image.shape[0]\n\n    return image[:int(width/2),:int(height/2)]", "result": "passed", "passed": true}
{"task_id": "../test_cases/dataframe_column_rename.ipynb", "completion": "\n    for old_value, new_value in replacements.items():\n        df[column] = df[column].replace(old_value, new_value, regex=True)\n    return df", "full_response": "\n    for old_value, new_value in replacements.items():\n        df[column] = df[column].replace(old_value, new_value, regex=True)\n    return df", "result": "passed", "passed": true}
{"task_id": "../test_cases/deconvolve_image.ipynb", "completion": "\n    from scipy import fftpack\n\n    # adapted from: https://stackoverflow.com/questions/17473917/is-there-a-equivalent-of-scipy-signal-deconvolve-for-2d-arrays\n    star_fft = fftpack.fftshift(fftpack.fftn(image))\n    psf_fft = fftpack.fftshift(fftpack.fftn(kernel_image))\n    return fftpack.fftshift(fftpack.ifftn(fftpack.ifftshift(star_fft/psf_fft)))\n    ", "full_response": "\n    from scipy import fftpack\n\n    # adapted from: https://stackoverflow.com/questions/17473917/is-there-a-equivalent-of-scipy-signal-deconvolve-for-2d-arrays\n    star_fft = fftpack.fftshift(fftpack.fftn(image))\n    psf_fft = fftpack.fftshift(fftpack.fftn(kernel_image))\n    return fftpack.fftshift(fftpack.ifftn(fftpack.ifftshift(star_fft/psf_fft)))\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/detect_edges.ipynb", "completion": "\n    from scipy.ndimage import sobel\n    filtered_image = sobel(image)\n    return filtered_image", "full_response": "\n    from scipy.ndimage import sobel\n    filtered_image = sobel(image)\n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/detect_ellipse.ipynb", "completion": "\n    from skimage.transform import hough_ellipse\n    result = hough_ellipse(image,  accuracy=5, threshold=10)\n    result.sort(order='accumulator')\n    \n    # Estimated parameters for the ellipse\n    best = list(result[-1])\n    yc, xc, a, b = (int(round(x)) for x in best[1:5])\n    \n    return yc, xc", "full_response": "\n    from skimage.transform import hough_ellipse\n    result = hough_ellipse(image,  accuracy=5, threshold=10)\n    result.sort(order='accumulator')\n    \n    # Estimated parameters for the ellipse\n    best = list(result[-1])\n    yc, xc, a, b = (int(round(x)) for x in best[1:5])\n    \n    return yc, xc", "result": "passed", "passed": true}
{"task_id": "../test_cases/distance_between_maxima.ipynb", "completion": "\n    import numpy as np\n\n    im1 = np.asarray(image1)\n    im2 = np.asarray(image2)\n\n    x1,y1 = np.unravel_index(im1.argmax(), im1.shape)\n    x2,y2 = np.unravel_index(im2.argmax(), im2.shape)\n\n    distance = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n\n    return distance", "full_response": "\n    import numpy as np\n\n    im1 = np.asarray(image1)\n    im2 = np.asarray(image2)\n\n    x1,y1 = np.unravel_index(im1.argmax(), im1.shape)\n    x2,y2 = np.unravel_index(im2.argmax(), im2.shape)\n\n    distance = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n\n    return distance", "result": "passed", "passed": true}
{"task_id": "../test_cases/expand_labels_without_overlap.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.expand_labels(label_image, distance=radius)", "full_response": "\n    import skimage\n    return skimage.segmentation.expand_labels(label_image, distance=radius)", "result": "passed", "passed": true}
{"task_id": "../test_cases/extract_surface_measure_area.ipynb", "completion": "\n    import vedo\n    volume = vedo.Volume(binary_volume_image)\n    iso_surface = volume.isosurface()\n    return iso_surface.area()", "full_response": "\n    import vedo\n    volume = vedo.Volume(binary_volume_image)\n    iso_surface = volume.isosurface()\n    return iso_surface.area()", "result": "passed", "passed": true}
{"task_id": "../test_cases/fft_spectrum.ipynb", "completion": "\n        import numpy as np\n    \n        # computing padding tuple:\n        pad_width = ((padding, padding),)*nd_image.ndim\n    \n        # Padding:\n        image_padded = np.pad(nd_image, pad_width=pad_width, mode='symmetric')\n        \n        # prepare the apodization window in 1D:\n        from scipy import signal\n        window_tuple = (signal.windows.hamming(length+2*padding) for length in nd_image.shape)\n        \n        # prepare the apodization window in nD:\n        import functools\n        window = functools.reduce(np.multiply.outer, window_tuple)\n        \n        # Apodize:\n        image_padded_apodized = window*image_padded\n    \n        # Compute the Fourier transform of the image:\n        image_fft = np.fft.fftn(image_padded_apodized)\n        \n        # Shift the zero-frequency component to the center of the spectrum:\n        image_fft_shifted = np.fft.fftshift(image_fft)\n        \n        # Compute the magnitude spectrum:\n        magnitude_spectrum = np.log1p(np.abs(image_fft_shifted))\n            \n        return(magnitude_spectrum)\n    \n    import numpy as np   \n\n    # Test image:\n    image = np.ones((5, 6, 7), dtype=np.int16)\n\n    # Padding:\n    padding_width = 10\n\n    # running the candidate function:\n    magnitude_spectrum_candidate = candidate(image, padding_width)\n    \n    # Reference implementation:\n    magnitude_spectrum_reference = fft_spectrum_reference(image, padding_width)\n    \n    assert np.allclose(magnitude_spectrum_candidate, magnitude_spectrum_reference)", "full_response": "\n        import numpy as np\n    \n        # computing padding tuple:\n        pad_width = ((padding, padding),)*nd_image.ndim\n    \n        # Padding:\n        image_padded = np.pad(nd_image, pad_width=pad_width, mode='symmetric')\n        \n        # prepare the apodization window in 1D:\n        from scipy import signal\n        window_tuple = (signal.windows.hamming(length+2*padding) for length in nd_image.shape)\n        \n        # prepare the apodization window in nD:\n        import functools\n        window = functools.reduce(np.multiply.outer, window_tuple)\n        \n        # Apodize:\n        image_padded_apodized = window*image_padded\n    \n        # Compute the Fourier transform of the image:\n        image_fft = np.fft.fftn(image_padded_apodized)\n        \n        # Shift the zero-frequency component to the center of the spectrum:\n        image_fft_shifted = np.fft.fftshift(image_fft)\n        \n        # Compute the magnitude spectrum:\n        magnitude_spectrum = np.log1p(np.abs(image_fft_shifted))\n            \n        return(magnitude_spectrum)\n    \n    import numpy as np   \n\n    # Test image:\n    image = np.ones((5, 6, 7), dtype=np.int16)\n\n    # Padding:\n    padding_width = 10\n\n    # running the candidate function:\n    magnitude_spectrum_candidate = candidate(image, padding_width)\n    \n    # Reference implementation:\n    magnitude_spectrum_reference = fft_spectrum_reference(image, padding_width)\n    \n    assert np.allclose(magnitude_spectrum_candidate, magnitude_spectrum_reference)", "result": "timed out", "passed": false}
{"task_id": "../test_cases/find_closest_neighbors.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import centroid\n    \n    # Identify all centroid locations\n    label_count = np.max(label_image)\n    centroids = {}\n    for i in range(1, label_count + 1):\n        binary_image = (label_image == i)\n        centroids[i] = centroid(binary_image)\n    \n    # Find the closest top n\n    distances = [(other, np.linalg.norm(centroids[target_label] - centroids[other])) for other in centroids.keys() if other != target_label]\n    sorted_distances = sorted(distances, key = lambda pair: pair[1])\n    topn = [label for label, _ in sorted_distances[:n]]\n\n    return topn", "full_response": "\n    import numpy as np\n    from skimage.measure import centroid\n    \n    # Identify all centroid locations\n    label_count = np.max(label_image)\n    centroids = {}\n    for i in range(1, label_count + 1):\n        binary_image = (label_image == i)\n        centroids[i] = centroid(binary_image)\n    \n    # Find the closest top n\n    distances = [(other, np.linalg.norm(centroids[target_label] - centroids[other])) for other in centroids.keys() if other != target_label]\n    sorted_distances = sorted(distances, key = lambda pair: pair[1])\n    topn = [label for label, _ in sorted_distances[:n]]\n\n    return topn", "result": "passed", "passed": true}
{"task_id": "../test_cases/fit_circle.ipynb", "completion": "\n    import circle_fit as cf\n    xc, yc, r, _ = cf.least_squares_circle(list_of_2d_points)\n    return xc,yc,r", "full_response": "\n    import circle_fit as cf\n    xc, yc, r, _ = cf.least_squares_circle(list_of_2d_points)\n    return xc,yc,r", "result": "passed", "passed": true}
{"task_id": "../test_cases/fit_gaussian_to_spot.ipynb", "completion": "\n    import numpy as np\n    import scipy \n\n    image = np.asarray(image)\n    num_px = image.shape[0]\n    [xx, yy] = np.meshgrid(np.arange(0,num_px), np.arange(0,num_px))\n\n\n    def twoDGauss(x,y,ux,uy,sigma):\n        '''\n        Creates theoretical normalized 2D gaussian spot, centered around (ux,uy) \n        with standard deviation sigma, on grid specified by x and y\n        '''\n        p = 1/(2*np.pi*sigma**2) * np.exp(- ( (x-ux)**2+(y-uy)**2 ) / (2*sigma**2))\n        return p\n\n    def expected(x,y,params):   \n        '''\n        Creates simulated realistic Gaussian spot on x-y grid, with following\n        parameters = [x0,y0,sigma,bg,N], speficically:\n            - x0 = x-position of gaussian (px coord., first pixel is (0,0))\n            - y0 = y-positoin of gaussian (px coord.)\n            - sigma = stdev of gaussian (px coord)\n            - bg = number of photons in background\n            - N = number of photons in spot\n        '''\n        E = params[4] * twoDGauss(x,y,params[0],params[1],params[2]) + params[3]\n        return E\n\n    def SSE(params):\n        '''\n        Calculates sum-of-squared errors difference between 'image' and expected Gaussian defined by 'params'\n        This is essentially the cost-function that is minimized in the fit\n        '''\n        Expec = expected(xx,yy,params)\n        sse = np.sum((image -  Expec)**2)\n        return sse\n\n\n    #guess fit parameters:\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    sigma_guess = 2                 #assume sigma is 2 pixels\n    bg_guess = (np.sum(image) - np.sum(image[1:-1,1:-1]))/(4*num_px-4)           \n                                    #average of border pixels\n    N_guess = np.sum(image) - bg_guess * num_px**2\n                                    #sum of intensities, minus background\n    params_guess = [x_guess,x_guess,sigma_guess, bg_guess, N_guess]\n\n    #perform the fit\n    param = scipy.optimize.fmin(func=SSE,x0=params_guess, maxiter=10000,maxfun=10000,ftol=1e-5,disp=0)\n\n    xc_fit      = param[0]  #fitted x-position\n    yc_fit      = param[1]  #fitted y-position\n    sigma_fit   = param[2]  #fitted sigma\n\n    return (xc_fit, yc_fit, sigma_fit)", "full_response": "\n    import numpy as np\n    import scipy \n\n    image = np.asarray(image)\n    num_px = image.shape[0]\n    [xx, yy] = np.meshgrid(np.arange(0,num_px), np.arange(0,num_px))\n\n\n    def twoDGauss(x,y,ux,uy,sigma):\n        '''\n        Creates theoretical normalized 2D gaussian spot, centered around (ux,uy) \n        with standard deviation sigma, on grid specified by x and y\n        '''\n        p = 1/(2*np.pi*sigma**2) * np.exp(- ( (x-ux)**2+(y-uy)**2 ) / (2*sigma**2))\n        return p\n\n    def expected(x,y,params):   \n        '''\n        Creates simulated realistic Gaussian spot on x-y grid, with following\n        parameters = [x0,y0,sigma,bg,N], speficically:\n            - x0 = x-position of gaussian (px coord., first pixel is (0,0))\n            - y0 = y-positoin of gaussian (px coord.)\n            - sigma = stdev of gaussian (px coord)\n            - bg = number of photons in background\n            - N = number of photons in spot\n        '''\n        E = params[4] * twoDGauss(x,y,params[0],params[1],params[2]) + params[3]\n        return E\n\n    def SSE(params):\n        '''\n        Calculates sum-of-squared errors difference between 'image' and expected Gaussian defined by 'params'\n        This is essentially the cost-function that is minimized in the fit\n        '''\n        Expec = expected(xx,yy,params)\n        sse = np.sum((image -  Expec)**2)\n        return sse\n\n\n    #guess fit parameters:\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    sigma_guess = 2                 #assume sigma is 2 pixels\n    bg_guess = (np.sum(image) - np.sum(image[1:-1,1:-1]))/(4*num_px-4)           \n                                    #average of border pixels\n    N_guess = np.sum(image) - bg_guess * num_px**2\n                                    #sum of intensities, minus background\n    params_guess = [x_guess,x_guess,sigma_guess, bg_guess, N_guess]\n\n    #perform the fit\n    param = scipy.optimize.fmin(func=SSE,x0=params_guess, maxiter=10000,maxfun=10000,ftol=1e-5,disp=0)\n\n    xc_fit      = param[0]  #fitted x-position\n    yc_fit      = param[1]  #fitted y-position\n    sigma_fit   = param[2]  #fitted sigma\n\n    return (xc_fit, yc_fit, sigma_fit)", "result": "passed", "passed": true}
{"task_id": "../test_cases/flow_field_deformation.ipynb", "completion": "\n    import SimpleITK as sitk\n\n    target = sitk.GetImageFromArray(target)\n\n    displacement = sitk.DisplacementFieldTransform(2)\n    field_size = list(flow_field.shape[:2])\n    field_origin = [0, 0]\n    field_spacing = [1.0, 1.0]\n    field_direction = [1, 0, 0, 1]  # direction cosine matrix (row major order)\n\n    # Concatenate all the information into a single list\n    displacement.SetFixedParameters(\n        field_size + field_origin + field_spacing + field_direction\n    )\n    # Set the interpolator to nearest neighbor\n    displacement.SetInterpolator(sitk.sitkNearestNeighbor)\n\n    originalDisplacements = flow_field.reshape((-1, 2)).flatten()\n    displacement.SetParameters(originalDisplacements)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetTransform(displacement)\n    resampler.SetReferenceImage(target)\n    resampled = resampler.Execute(target)\n\n    return sitk.GetArrayFromImage(resampled)", "full_response": "\n    import SimpleITK as sitk\n\n    target = sitk.GetImageFromArray(target)\n\n    displacement = sitk.DisplacementFieldTransform(2)\n    field_size = list(flow_field.shape[:2])\n    field_origin = [0, 0]\n    field_spacing = [1.0, 1.0]\n    field_direction = [1, 0, 0, 1]  # direction cosine matrix (row major order)\n\n    # Concatenate all the information into a single list\n    displacement.SetFixedParameters(\n        field_size + field_origin + field_spacing + field_direction\n    )\n    # Set the interpolator to nearest neighbor\n    displacement.SetInterpolator(sitk.sitkNearestNeighbor)\n\n    originalDisplacements = flow_field.reshape((-1, 2)).flatten()\n    displacement.SetParameters(originalDisplacements)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetTransform(displacement)\n    resampler.SetReferenceImage(target)\n    resampled = resampler.Execute(target)\n\n    return sitk.GetArrayFromImage(resampled)", "result": "passed", "passed": true}
{"task_id": "../test_cases/generate_image_histogram.ipynb", "completion": "\n    import numpy as np\n    return np.histogram(image,bins=num_bins)[0]", "full_response": "\n    import numpy as np\n    return np.histogram(image,bins=num_bins)[0]", "result": "passed", "passed": true}
{"task_id": "../test_cases/identify_centroids.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import centroid\n    n = np.max(label_image)\n    out = {}\n    for i in range(1, n + 1):\n        binary_image = (label_image == i)\n        out[i] = centroid(binary_image)\n    return out", "full_response": "\n    import numpy as np\n    from skimage.measure import centroid\n    n = np.max(label_image)\n    out = {}\n    for i in range(1, n + 1):\n        binary_image = (label_image == i)\n        out[i] = centroid(binary_image)\n    return out", "result": "passed", "passed": true}
{"task_id": "../test_cases/interpolate_stack.ipynb", "completion": "\n    import numpy as np\n\n    return np.linspace(start_slice, end_slice, num)", "full_response": "\n    import numpy as np\n\n    return np.linspace(start_slice, end_slice, num)", "result": "passed", "passed": true}
{"task_id": "../test_cases/label_binary_image_and_count_labels.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    label_image = skimage.measure.label(binary_image)\n\n    return len(np.unique(label_image)) - 1", "full_response": "\n    import skimage\n    import numpy as np\n    label_image = skimage.measure.label(binary_image)\n\n    return len(np.unique(label_image)) - 1", "result": "passed", "passed": true}
{"task_id": "../test_cases/label_sequentially.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.relabel_sequential(label_image)[0]", "full_response": "\n    import skimage\n    return skimage.segmentation.relabel_sequential(label_image)[0]", "result": "passed", "passed": true}
{"task_id": "../test_cases/linear_intensity_profile.ipynb", "completion": "\n    from skimage.measure import profile_line\n    return profile_line(image, starting_point, ending_point)", "full_response": "\n    from skimage.measure import profile_line\n    return profile_line(image, starting_point, ending_point)", "result": "passed", "passed": true}
{"task_id": "../test_cases/list_image_files_in_folder.ipynb", "completion": "\n    import os\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    return [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]", "full_response": "\n    import os\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    return [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]", "result": "passed", "passed": true}
{"task_id": "../test_cases/load_tif_and_output_rgb.ipynb", "completion": "\n    from cv2 import imread, cvtColor, COLOR_BGR2RGB\n    image = imread(path_to_tif)\n    return cvtColor(image, COLOR_BGR2RGB)", "full_response": "\n    from cv2 import imread, cvtColor, COLOR_BGR2RGB\n    image = imread(path_to_tif)\n    return cvtColor(image, COLOR_BGR2RGB)", "result": "failed: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n", "passed": false}
{"task_id": "../test_cases/local_maxima_from_distance_transform.ipynb", "completion": "\n    import scipy.ndimage as ndi\n    import skimage.feature as skf\n    \n    distance_transform = ndi.distance_transform_edt(binary_image)\n    \n    image_max = ndi.maximum_filter(distance_transform, size=nms_window, mode='constant')\n    \n    # suppress non-maxima values by setting them to -1\n    mask = distance_transform == image_max\n    image_max[~mask] = -1\n    \n    local_maxima = skf.peak_local_max(image_max)\n\n    return local_maxima.tolist()", "full_response": "\n    import scipy.ndimage as ndi\n    import skimage.feature as skf\n    \n    distance_transform = ndi.distance_transform_edt(binary_image)\n    \n    image_max = ndi.maximum_filter(distance_transform, size=nms_window, mode='constant')\n    \n    # suppress non-maxima values by setting them to -1\n    mask = distance_transform == image_max\n    image_max[~mask] = -1\n    \n    local_maxima = skf.peak_local_max(image_max)\n\n    return local_maxima.tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/map_pixel_count_of_labels.ipynb", "completion": "\n    import pyclesperanto_prototype as cle\n    return cle.pixel_count_map(label_image)", "full_response": "\n    import pyclesperanto_prototype as cle\n    return cle.pixel_count_map(label_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/mask_image.ipynb", "completion": "\n    import numpy as np\n    return image * mask", "full_response": "\n    import numpy as np\n    return image * mask", "result": "passed", "passed": true}
{"task_id": "../test_cases/maximum_intensity_projection.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).max(axis=0)", "full_response": "\n    import numpy as np\n    return np.asarray(image).max(axis=0)", "result": "passed", "passed": true}
{"task_id": "../test_cases/mean_squared_error.ipynb", "completion": "\n    return ((image1 - image2)**2).mean()\n    # adapted from : https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy", "full_response": "\n    return ((image1 - image2)**2).mean()\n    # adapted from : https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy", "result": "passed", "passed": true}
{"task_id": "../test_cases/mean_std_column.ipynb", "completion": "\n    import numpy as np\n    data = dataframe[column]\n    return np.mean(data), np.std(data)", "full_response": "\n    import numpy as np\n    data = dataframe[column]\n    return np.mean(data), np.std(data)", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_aspect_ratio_of_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = pd.DataFrame(skimage.measure.regionprops_table(label_image, properties=('minor_axis_length', 'major_axis_length')))\n    stats['aspect_ratio'] = stats['major_axis_length'] / stats['minor_axis_length']\n    return stats", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = pd.DataFrame(skimage.measure.regionprops_table(label_image, properties=('minor_axis_length', 'major_axis_length')))\n    stats['aspect_ratio'] = stats['major_axis_length'] / stats['minor_axis_length']\n    return stats", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_intensity_of_labels.ipynb", "completion": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image, intensity_image)\n    return [s.mean_intensity for s in stats]", "full_response": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image, intensity_image)\n    return [s.mean_intensity for s in stats]", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_intensity_over_time.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image_list).mean(axis=(1,2)).tolist()", "full_response": "\n    import numpy as np\n    return np.asarray(image_list).mean(axis=(1,2)).tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_mean_image_intensity.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).mean()", "full_response": "\n    import numpy as np\n    return np.asarray(image).mean()", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_pixel_count_of_labels.ipynb", "completion": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image)\n    return [s.area for s in stats]", "full_response": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image)\n    return [s.area for s in stats]", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_properties_of_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\n    return pd.DataFrame(stats)", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\n    return pd.DataFrame(stats)", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_image_read_voxel_size.ipynb", "completion": "\n    from aicsimageio import AICSImage\n    aics_image = AICSImage(image_filename)\n\n    return aics_image.physical_pixel_sizes.Z, \\\n            aics_image.physical_pixel_sizes.Y, \\\n            aics_image.physical_pixel_sizes.X", "full_response": "\n    from aicsimageio import AICSImage\n    aics_image = AICSImage(image_filename)\n\n    return aics_image.physical_pixel_sizes.Z, \\\n            aics_image.physical_pixel_sizes.Y, \\\n            aics_image.physical_pixel_sizes.X", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_image_return_dimensions.ipynb", "completion": "\n    from skimage.io import imread\n    image = imread(image_file_location)\n    return image.shape", "full_response": "\n    from skimage.io import imread\n    image = imread(image_file_location)\n    return image.shape", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_nifti_image.ipynb", "completion": "\n    \n    import nibabel as nib\n    import numpy as nb\n\n    img = nib.load(image_file_location)\n    data = img.get_fdata()\n    return(data)", "full_response": "\n    \n    import nibabel as nib\n    import numpy as nb\n\n    img = nib.load(image_file_location)\n    data = img.get_fdata()\n    return(data)", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_zarr.ipynb", "completion": "\n    import zarr\n    array = zarr.load(zarr_file_location)\n    return array", "full_response": "\n    import zarr\n    array = zarr.load(zarr_file_location)\n    return array", "result": "passed", "passed": true}
{"task_id": "../test_cases/pair_wise_correlation_matrix.ipynb", "completion": "\n    return dataframe.corr()", "full_response": "\n    return dataframe.corr()", "result": "passed", "passed": true}
{"task_id": "../test_cases/radial_intensity_profile.ipynb", "completion": "\n    import numpy as np\n    y, x = np.indices((image.shape))\n    r = np.sqrt((x - xc)**2 + (y - yc)**2)\n    r = r.astype(int)\n    summed_values = np.bincount(r.ravel(), image.ravel())\n    number_of_pixels_at_r = np.bincount(r.ravel())\n    radial_profile = summed_values / number_of_pixels_at_r\n    return radial_profile ", "full_response": "\n    import numpy as np\n    y, x = np.indices((image.shape))\n    r = np.sqrt((x - xc)**2 + (y - yc)**2)\n    r = r.astype(int)\n    summed_values = np.bincount(r.ravel(), image.ravel())\n    number_of_pixels_at_r = np.bincount(r.ravel())\n    radial_profile = summed_values / number_of_pixels_at_r\n    return radial_profile ", "result": "passed", "passed": true}
{"task_id": "../test_cases/read_imagej_tif_metadata.ipynb", "completion": "\n    from tifffile import TiffFile\n    \n    with (TiffFile(image_filename) as tif):\n        imagej_metadata = tif.imagej_metadata\n    return imagej_metadata", "full_response": "\n    from tifffile import TiffFile\n    \n    with (TiffFile(image_filename) as tif):\n        imagej_metadata = tif.imagej_metadata\n    return imagej_metadata", "result": "passed", "passed": true}
{"task_id": "../test_cases/read_ome_metadata_from_ome_xml.ipynb", "completion": "\n    from ome_types import from_xml\n    ome = from_xml(img_path)\n    return ome.images[0]", "full_response": "\n    from ome_types import from_xml\n    ome = from_xml(img_path)\n    return ome.images[0]", "result": "failed: Could not parse XML from '../example_data/ome_xml_example.xml'", "passed": false}
{"task_id": "../test_cases/region_growing_segmentation.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.flood(image, point)", "full_response": "\n    import skimage\n    return skimage.segmentation.flood(image, point)", "result": "passed", "passed": true}
{"task_id": "../test_cases/register_timelapse.ipynb", "completion": "\n    from skimage import registration\n    import scipy.ndimage as ndi\n\n    new_video = video.copy()\n    ref_frame = new_video[-1]\n    for t in range(len(video) - 1, 0, -1):\n        mov_frame = video[t - 1]\n        shift, _, _ = registration.phase_cross_correlation(\n            ref_frame,\n            mov_frame,\n            upsample_factor=4,\n            normalization=None,\n        )\n        # replaces old ref_frame with shifted mov_frame\n        ref_frame = ndi.shift(mov_frame, shift, order=1)\n        new_video[t - 1] = ref_frame\n\n    return new_video", "full_response": "\n    from skimage import registration\n    import scipy.ndimage as ndi\n\n    new_video = video.copy()\n    ref_frame = new_video[-1]\n    for t in range(len(video) - 1, 0, -1):\n        mov_frame = video[t - 1]\n        shift, _, _ = registration.phase_cross_correlation(\n            ref_frame,\n            mov_frame,\n            upsample_factor=4,\n            normalization=None,\n        )\n        # replaces old ref_frame with shifted mov_frame\n        ref_frame = ndi.shift(mov_frame, shift, order=1)\n        new_video[t - 1] = ref_frame\n\n    return new_video", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_labels_on_edges.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.clear_border(label_image)", "full_response": "\n    import skimage\n    return skimage.segmentation.clear_border(label_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_noise_edge_preserving.ipynb", "completion": "\n    from scipy.ndimage import median_filter\n    filtered_image = median_filter(image, size=radius * 2 + 1)\n    return filtered_image", "full_response": "\n    from scipy.ndimage import median_filter\n    filtered_image = median_filter(image, size=radius * 2 + 1)\n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_small_labels.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.exclude_small_labels(label_image, maximum_size=size_threshold))", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.exclude_small_labels(label_image, maximum_size=size_threshold))", "result": "passed", "passed": true}
{"task_id": "../test_cases/reshape_array.ipynb", "completion": "\n    import numpy as np\n    \n    array = np.asarray(image)\n    array = np.transpose(array, axes=[2, 0, 1])\n    return array", "full_response": "\n    import numpy as np\n    \n    array = np.asarray(image)\n    array = np.transpose(array, axes=[2, 0, 1])\n    return array", "result": "passed", "passed": true}
{"task_id": "../test_cases/return_hello_world.ipynb", "completion": "\n    return \"hello world\"", "full_response": "\n    return \"hello world\"", "result": "passed", "passed": true}
{"task_id": "../test_cases/rgb_to_grey_image_transform.ipynb", "completion": "\n    rgb_sum = r + g + b\n    r = r / rgb_sum\n    g = g / rgb_sum\n    b = b / rgb_sum\n    \n    import numpy as np\n    channel_r = rgb_image[...,0]\n    channel_g = rgb_image[...,1]\n    channel_b = rgb_image[...,2]\n    grey_image = channel_r * r + \\\n                 channel_g * g + \\\n                 channel_b * b\n    \n    return grey_image", "full_response": "\n    rgb_sum = r + g + b\n    r = r / rgb_sum\n    g = g / rgb_sum\n    b = b / rgb_sum\n    \n    import numpy as np\n    channel_r = rgb_image[...,0]\n    channel_g = rgb_image[...,1]\n    channel_b = rgb_image[...,2]\n    grey_image = channel_r * r + \\\n                 channel_g * g + \\\n                 channel_b * b\n    \n    return grey_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/roi_imagej_to_ezomero.ipynb", "completion": "\n    list_of_tuples = list(dataframe.itertuples(index=False, name=None))\n    return list_of_tuples", "full_response": "\n    list_of_tuples = list(dataframe.itertuples(index=False, name=None))\n    return list_of_tuples", "result": "passed", "passed": true}
{"task_id": "../test_cases/rotate_image_by_90_degrees.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.rotate(image, angle_around_z_in_degrees=90))", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.rotate(image, angle_around_z_in_degrees=90))", "result": "passed", "passed": true}
{"task_id": "../test_cases/save_image_with_voxel_size.ipynb", "completion": "\n    from aicsimageio import AICSImage \n    from aicsimageio.types import PhysicalPixelSizes\n    from tempfile import tempdir\n    import os \n\n    image = AICSImage(image)\n    AICSImage.physical_pixel_sizes = PhysicalPixelSizes(Z=vz,Y=vy,X=vx)\n    img_path = os.path.join(tempdir, 'voxel_save_test.ome.tiff')\n    image.save(img_path)\n    return img_path", "full_response": "\n    from aicsimageio import AICSImage \n    from aicsimageio.types import PhysicalPixelSizes\n    from tempfile import tempdir\n    import os \n\n    image = AICSImage(image)\n    AICSImage.physical_pixel_sizes = PhysicalPixelSizes(Z=vz,Y=vy,X=vx)\n    img_path = os.path.join(tempdir, 'voxel_save_test.ome.tiff')\n    image.save(img_path)\n    return img_path", "result": "passed", "passed": true}
{"task_id": "../test_cases/scale_image_affine_transform.ipynb", "completion": "\n    from pyclesperanto_prototype import AffineTransform3D\n    import pyclesperanto_prototype as cle \n    import numpy as np\n    \n    output_img_shape =  (image.shape[0]*sy, image.shape[1]*sx)\n\n    transform = AffineTransform3D()\n    transform.center(image.shape)\n    transform.scale(scale_x = sx, scale_y = sy)\n    transform.center(output_img_shape,undo=True)\n    scaled_image = np.array(cle.affine_transform(image,transform=transform,auto_size=True))\n    return scaled_image, transform._matrix", "full_response": "\n    from pyclesperanto_prototype import AffineTransform3D\n    import pyclesperanto_prototype as cle \n    import numpy as np\n    \n    output_img_shape =  (image.shape[0]*sy, image.shape[1]*sx)\n\n    transform = AffineTransform3D()\n    transform.center(image.shape)\n    transform.scale(scale_x = sx, scale_y = sy)\n    transform.center(output_img_shape,undo=True)\n    scaled_image = np.array(cle.affine_transform(image,transform=transform,auto_size=True))\n    return scaled_image, transform._matrix", "result": "passed", "passed": true}
{"task_id": "../test_cases/select_coexpressing_cells.ipynb", "completion": "\n    import numpy as np\n    import pandas as pd\n    from skimage.measure import regionprops_table\n\n    df = pd.DataFrame(\n        regionprops_table(label_image, image, properties=(\"label\", \"area\", \"intensity_mean\"))\n    )\n    mean_cols = [c for c in df.columns if c.startswith(\"intensity_mean\")]\n    sum_cols = [f\"intensity_sum-{i}\" for i in range(len(mean_cols))]\n    \n    df[sum_cols] = df[mean_cols] * df[\"area\"].to_numpy()\n    \n    selected_ids = df.loc[(df[sum_cols] > threshold).all(axis=1), \"label\"].to_numpy()\n    \n    below_threshold_mask = np.isin(label_image, selected_ids, invert=False)\n    filtered_labels = label_image * below_threshold_mask\n\n    return filtered_labels", "full_response": "\n    import numpy as np\n    import pandas as pd\n    from skimage.measure import regionprops_table\n\n    df = pd.DataFrame(\n        regionprops_table(label_image, image, properties=(\"label\", \"area\", \"intensity_mean\"))\n    )\n    mean_cols = [c for c in df.columns if c.startswith(\"intensity_mean\")]\n    sum_cols = [f\"intensity_sum-{i}\" for i in range(len(mean_cols))]\n    \n    df[sum_cols] = df[mean_cols] * df[\"area\"].to_numpy()\n    \n    selected_ids = df.loc[(df[sum_cols] > threshold).all(axis=1), \"label\"].to_numpy()\n    \n    below_threshold_mask = np.isin(label_image, selected_ids, invert=False)\n    filtered_labels = label_image * below_threshold_mask\n\n    return filtered_labels", "result": "passed", "passed": true}
{"task_id": "../test_cases/stack_and_merge.ipynb", "completion": "\n    import numpy as np\n    stacked_image = np.stack((image1, image2), axis=0)\n    stitched_image = np.concatenate((stacked_image, image3), axis=2)\n    return stitched_image.shape", "full_response": "\n    import numpy as np\n    stacked_image = np.stack((image1, image2), axis=0)\n    stitched_image = np.concatenate((stacked_image, image3), axis=2)\n    return stitched_image.shape", "result": "passed", "passed": true}
{"task_id": "../test_cases/subsample_image.ipynb", "completion": "\n    return image[::n,::n]", "full_response": "\n    return image[::n,::n]", "result": "passed", "passed": true}
{"task_id": "../test_cases/subtract_background_tophat.ipynb", "completion": "\n    from skimage.morphology import white_tophat\n    from skimage.morphology import disk\n    filtered_image = white_tophat(image, footprint=disk(radius))\n    \n    return filtered_image", "full_response": "\n    from skimage.morphology import white_tophat\n    from skimage.morphology import disk\n    filtered_image = white_tophat(image, footprint=disk(radius))\n    \n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/sum_images.ipynb", "completion": "\n    return image1 + image2", "full_response": "\n    return image1 + image2", "result": "passed", "passed": true}
{"task_id": "../test_cases/sum_intensity_projection.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).sum(axis=0)", "full_response": "\n    import numpy as np\n    return np.asarray(image).sum(axis=0)", "result": "passed", "passed": true}
{"task_id": "../test_cases/tiled_image_processing.ipynb", "completion": "\n    import dask\n    import dask.array as da\n\n    tiles = da.from_array(image, chunks=(tile_size, tile_size))\n    \n    def procedure(image):\n        from scipy.ndimage import maximum_filter\n        return maximum_filter(image, size=radius*2+1)\n\n    # setup a lazy result (not computed yet)\n    tile_map = da.map_blocks(procedure, tiles)\n\n    # actually apply filter\n    result = tile_map.compute()\n\n    return result", "full_response": "\n    import dask\n    import dask.array as da\n\n    tiles = da.from_array(image, chunks=(tile_size, tile_size))\n    \n    def procedure(image):\n        from scipy.ndimage import maximum_filter\n        return maximum_filter(image, size=radius*2+1)\n\n    # setup a lazy result (not computed yet)\n    tile_map = da.map_blocks(procedure, tiles)\n\n    # actually apply filter\n    result = tile_map.compute()\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/translate_3d_image_along_vector.ipynb", "completion": "\n    from pyclesperanto_prototype import translate\n\n    # translate 3d image along t_x, t_y and t_z\n    return translate(image, translate_x = t_x, translate_y = t_y, translate_z = t_z)", "full_response": "\n    from pyclesperanto_prototype import translate\n\n    # translate 3d image along t_x, t_y and t_z\n    return translate(image, translate_x = t_x, translate_y = t_y, translate_z = t_z)", "result": "passed", "passed": true}
{"task_id": "../test_cases/transpose_image_axes.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).T", "full_response": "\n    import numpy as np\n    return np.asarray(image).T", "result": "passed", "passed": true}
{"task_id": "../test_cases/t_test.ipynb", "completion": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    return scipy.stats.ttest_rel(data1, data2)[1]\n    ", "full_response": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    return scipy.stats.ttest_rel(data1, data2)[1]\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_batch_process_folder_count_labels.ipynb", "completion": "\n    import os\n    from skimage.io import imread\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]\n    result = {}\n\n    for filename in file_list:\n        image = imread(folder_location + filename)\n\n        labels = np.unique(image).tolist()\n        labels.pop(0)\n\n        count = len(labels)\n\n        result[filename] = count\n\n    return result", "full_response": "\n    import os\n    from skimage.io import imread\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]\n    result = {}\n\n    for filename in file_list:\n        image = imread(folder_location + filename)\n\n        labels = np.unique(image).tolist()\n        labels.pop(0)\n\n        count = len(labels)\n\n        result[filename] = count\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_batch_process_folder_measure_intensity.ipynb", "completion": "\n    import os\n    import pandas as pd\n    from skimage.io import imread\n    from skimage.measure import regionprops\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(image_folder_location) if str(fn[-4:]) in supported_fileendings]\n\n    result = []\n\n    for filename in file_list:\n        image = imread(image_folder_location + filename)[...,0]\n        labels = imread(labels_folder_location + filename)\n\n        stats = regionprops(labels, intensity_image=image)\n\n        for s in stats:\n            result.append({\n                \"filename\":filename,\n                \"label\":s.label,\n                \"min_intensity\":s.min_intensity,\n                \"mean_intensity\":s.mean_intensity,\n                \"max_intensity\":s.max_intensity,\n            })\n\n    return pd.DataFrame(result)", "full_response": "\n    import os\n    import pandas as pd\n    from skimage.io import imread\n    from skimage.measure import regionprops\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(image_folder_location) if str(fn[-4:]) in supported_fileendings]\n\n    result = []\n\n    for filename in file_list:\n        image = imread(image_folder_location + filename)[...,0]\n        labels = imread(labels_folder_location + filename)\n\n        stats = regionprops(labels, intensity_image=image)\n\n        for s in stats:\n            result.append({\n                \"filename\":filename,\n                \"label\":s.label,\n                \"min_intensity\":s.min_intensity,\n                \"mean_intensity\":s.mean_intensity,\n                \"max_intensity\":s.max_intensity,\n            })\n\n    return pd.DataFrame(result)", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segmentation_counting.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    average_intensity = np.asarray(image).mean()\n    binary = image > average_intensity\n    labels = skimage.measure.label(binary)\n    return labels.max()", "full_response": "\n    import skimage\n    import numpy as np\n    average_intensity = np.asarray(image).mean()\n    binary = image > average_intensity\n    labels = skimage.measure.label(binary)\n    return labels.max()", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segmentation_measurement_summary.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n    label_image = skimage.measure.label(binary_image)\n    stats = skimage.measure.regionprops(label_image)\n    areas = [s.area for s in stats]\n    return np.mean(areas)", "full_response": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n    label_image = skimage.measure.label(binary_image)\n    stats = skimage.measure.regionprops(label_image)\n    areas = [s.area for s in stats]\n    return np.mean(areas)", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segment_measure_umap.ipynb", "completion": "\n    import numpy as np\n    import pandas as pd\n    import umap\n    from skimage.measure import label, regionprops_table\n\n    image = np.asarray(image)\n\n    # segment\n    binary = image > 0.5 * image.max()\n    labels = label(binary)\n\n    # measure\n    dataframe = pd.DataFrame(regionprops_table(labels, intensity_image=image, \n                                              properties=['area', 'perimeter', 'mean_intensity', \n                                                          'minor_axis_length', 'major_axis_length']))\n\n    # append UMAP\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    return dataframe", "full_response": "\n    import numpy as np\n    import pandas as pd\n    import umap\n    from skimage.measure import label, regionprops_table\n\n    image = np.asarray(image)\n\n    # segment\n    binary = image > 0.5 * image.max()\n    labels = label(binary)\n\n    # measure\n    dataframe = pd.DataFrame(regionprops_table(labels, intensity_image=image, \n                                              properties=['area', 'perimeter', 'mean_intensity', \n                                                          'minor_axis_length', 'major_axis_length']))\n\n    # append UMAP\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    return dataframe", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_watershed_segmentation_correction_measurement.ipynb", "completion": "\n    import skimage\n    blurred = skimage.filters.gaussian(image * 255, sigma=1)\n    minima = skimage.morphology.local_minima(blurred)\n    spots = skimage.measure.label(minima)\n    labels = skimage.segmentation.watershed(blurred, spots)\n    labels_without_border = skimage.segmentation.clear_border(labels)   \n    binary = labels_without_border > 0\n    return binary.sum()", "full_response": "\n    import skimage\n    blurred = skimage.filters.gaussian(image * 255, sigma=1)\n    minima = skimage.morphology.local_minima(blurred)\n    spots = skimage.measure.label(minima)\n    labels = skimage.segmentation.watershed(blurred, spots)\n    labels_without_border = skimage.segmentation.clear_border(labels)   \n    binary = labels_without_border > 0\n    return binary.sum()", "result": "passed", "passed": true}
{"task_id": "../test_cases/apply_otsu_threshold_and_count_positive_pixels.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n\n    result = np.sum(binary_image)\n\n    return result", "full_response": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n\n    result = np.sum(binary_image)\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/binary_closing.ipynb", "completion": "\n    import numpy as np\n    import skimage\n    size = radius * 2 + 1\n    return skimage.morphology.binary_closing(binary_image, footprint=np.ones((size, size)))", "full_response": "\n    import numpy as np\n    import skimage\n    size = radius * 2 + 1\n    return skimage.morphology.binary_closing(binary_image, footprint=np.ones((size, size)))", "result": "passed", "passed": true}
{"task_id": "../test_cases/binary_skeleton.ipynb", "completion": "\n    from skimage.morphology import skeletonize\n    return skeletonize(binary_image)", "full_response": "\n    from skimage.morphology import skeletonize\n    return skeletonize(binary_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/bland_altman.ipynb", "completion": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    dataframe['mean'] = (data1 + data2) / 2\n    dataframe['diff'] = data2 - data1\n    return dataframe", "full_response": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    dataframe['mean'] = (data1 + data2) / 2\n    dataframe['diff'] = data2 - data1\n    return dataframe", "result": "passed", "passed": true}
{"task_id": "../test_cases/combine_columns_of_tables.ipynb", "completion": "\n    import pandas as pd\n    return pd.merge(dataframe1, dataframe2, how='outer', on='label')", "full_response": "\n    import pandas as pd\n    return pd.merge(dataframe1, dataframe2, how='outer', on='label')", "result": "passed", "passed": true}
{"task_id": "../test_cases/convert_points_polygon.ipynb", "completion": "\n    from shapely import Polygon\n    polygon = Polygon(coordinates)\n    return polygon\n", "full_response": "\n    from shapely import Polygon\n    polygon = Polygon(coordinates)\n    return polygon\n", "result": "passed", "passed": true}
{"task_id": "../test_cases/convex_hull_measure_area.ipynb", "completion": "\n    import vedo\n    convex_hull = vedo.shapes.ConvexHull(point_cloud)\n    return convex_hull.area()", "full_response": "\n    import vedo\n    convex_hull = vedo.shapes.ConvexHull(point_cloud)\n    return convex_hull.area()", "result": "passed", "passed": true}
{"task_id": "../test_cases/convolve_images.ipynb", "completion": "\n    import scipy\n    return scipy.ndimage.convolve(image, kernel_image)\n    ", "full_response": "\n    import scipy\n    return scipy.ndimage.convolve(image, kernel_image)\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_number_of_touching_neighbors.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n\n    touch_matrix = cle.generate_touch_matrix(label_image)\n    cle.set_row(touch_matrix, 0, 0)\n    cle.set_column(touch_matrix, 0, 0)\n\n    return np.asarray(cle.sum_y_projection(touch_matrix))[0,1:].tolist()", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n\n    touch_matrix = cle.generate_touch_matrix(label_image)\n    cle.set_row(touch_matrix, 0, 0)\n    cle.set_column(touch_matrix, 0, 0)\n\n    return np.asarray(cle.sum_y_projection(touch_matrix))[0,1:].tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_objects_over_time.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import label\n    labels = [label(binary_image) for binary_image in binary_image_list]\n    return [len(np.unique(label)) - 1 for label in labels]", "full_response": "\n    import numpy as np\n    from skimage.measure import label\n    labels = [label(binary_image) for binary_image in binary_image_list]\n    return [len(np.unique(label)) - 1 for label in labels]", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_overlapping_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image_1, label_image_2, properties=('mean_intensity',))\n    return (pd.DataFrame(stats)['mean_intensity'] > 0).sum()", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image_1, label_image_2, properties=('mean_intensity',))\n    return (pd.DataFrame(stats)['mean_intensity'] > 0).sum()", "result": "passed", "passed": true}
{"task_id": "../test_cases/create_umap.ipynb", "completion": "\n    import umap\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    # no return value", "full_response": "\n    import umap\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    # no return value", "result": "passed", "passed": true}
{"task_id": "../test_cases/crop_quarter_image.ipynb", "completion": "\n    width = image.shape[1]\n    height = image.shape[0]\n\n    return image[:int(width/2),:int(height/2)]", "full_response": "\n    width = image.shape[1]\n    height = image.shape[0]\n\n    return image[:int(width/2),:int(height/2)]", "result": "passed", "passed": true}
{"task_id": "../test_cases/dataframe_column_rename.ipynb", "completion": "\n    for old_value, new_value in replacements.items():\n        df[column] = df[column].replace(old_value, new_value, regex=True)\n    return df", "full_response": "\n    for old_value, new_value in replacements.items():\n        df[column] = df[column].replace(old_value, new_value, regex=True)\n    return df", "result": "passed", "passed": true}
{"task_id": "../test_cases/deconvolve_image.ipynb", "completion": "\n    from scipy import fftpack\n\n    # adapted from: https://stackoverflow.com/questions/17473917/is-there-a-equivalent-of-scipy-signal-deconvolve-for-2d-arrays\n    star_fft = fftpack.fftshift(fftpack.fftn(image))\n    psf_fft = fftpack.fftshift(fftpack.fftn(kernel_image))\n    return fftpack.fftshift(fftpack.ifftn(fftpack.ifftshift(star_fft/psf_fft)))\n    ", "full_response": "\n    from scipy import fftpack\n\n    # adapted from: https://stackoverflow.com/questions/17473917/is-there-a-equivalent-of-scipy-signal-deconvolve-for-2d-arrays\n    star_fft = fftpack.fftshift(fftpack.fftn(image))\n    psf_fft = fftpack.fftshift(fftpack.fftn(kernel_image))\n    return fftpack.fftshift(fftpack.ifftn(fftpack.ifftshift(star_fft/psf_fft)))\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/detect_edges.ipynb", "completion": "\n    from scipy.ndimage import sobel\n    filtered_image = sobel(image)\n    return filtered_image", "full_response": "\n    from scipy.ndimage import sobel\n    filtered_image = sobel(image)\n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/detect_ellipse.ipynb", "completion": "\n    from skimage.transform import hough_ellipse\n    result = hough_ellipse(image,  accuracy=5, threshold=10)\n    result.sort(order='accumulator')\n    \n    # Estimated parameters for the ellipse\n    best = list(result[-1])\n    yc, xc, a, b = (int(round(x)) for x in best[1:5])\n    \n    return yc, xc", "full_response": "\n    from skimage.transform import hough_ellipse\n    result = hough_ellipse(image,  accuracy=5, threshold=10)\n    result.sort(order='accumulator')\n    \n    # Estimated parameters for the ellipse\n    best = list(result[-1])\n    yc, xc, a, b = (int(round(x)) for x in best[1:5])\n    \n    return yc, xc", "result": "passed", "passed": true}
{"task_id": "../test_cases/distance_between_maxima.ipynb", "completion": "\n    import numpy as np\n\n    im1 = np.asarray(image1)\n    im2 = np.asarray(image2)\n\n    x1,y1 = np.unravel_index(im1.argmax(), im1.shape)\n    x2,y2 = np.unravel_index(im2.argmax(), im2.shape)\n\n    distance = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n\n    return distance", "full_response": "\n    import numpy as np\n\n    im1 = np.asarray(image1)\n    im2 = np.asarray(image2)\n\n    x1,y1 = np.unravel_index(im1.argmax(), im1.shape)\n    x2,y2 = np.unravel_index(im2.argmax(), im2.shape)\n\n    distance = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n\n    return distance", "result": "passed", "passed": true}
{"task_id": "../test_cases/expand_labels_without_overlap.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.expand_labels(label_image, distance=radius)", "full_response": "\n    import skimage\n    return skimage.segmentation.expand_labels(label_image, distance=radius)", "result": "passed", "passed": true}
{"task_id": "../test_cases/extract_surface_measure_area.ipynb", "completion": "\n    import vedo\n    volume = vedo.Volume(binary_volume_image)\n    iso_surface = volume.isosurface()\n    return iso_surface.area()", "full_response": "\n    import vedo\n    volume = vedo.Volume(binary_volume_image)\n    iso_surface = volume.isosurface()\n    return iso_surface.area()", "result": "passed", "passed": true}
{"task_id": "../test_cases/fft_spectrum.ipynb", "completion": "\n        import numpy as np\n    \n        # computing padding tuple:\n        pad_width = ((padding, padding),)*nd_image.ndim\n    \n        # Padding:\n        image_padded = np.pad(nd_image, pad_width=pad_width, mode='symmetric')\n        \n        # prepare the apodization window in 1D:\n        from scipy import signal\n        window_tuple = (signal.windows.hamming(length+2*padding) for length in nd_image.shape)\n        \n        # prepare the apodization window in nD:\n        import functools\n        window = functools.reduce(np.multiply.outer, window_tuple)\n        \n        # Apodize:\n        image_padded_apodized = window*image_padded\n    \n        # Compute the Fourier transform of the image:\n        image_fft = np.fft.fftn(image_padded_apodized)\n        \n        # Shift the zero-frequency component to the center of the spectrum:\n        image_fft_shifted = np.fft.fftshift(image_fft)\n        \n        # Compute the magnitude spectrum:\n        magnitude_spectrum = np.log1p(np.abs(image_fft_shifted))\n            \n        return(magnitude_spectrum)\n    \n    import numpy as np   \n\n    # Test image:\n    image = np.ones((5, 6, 7), dtype=np.int16)\n\n    # Padding:\n    padding_width = 10\n\n    # running the candidate function:\n    magnitude_spectrum_candidate = candidate(image, padding_width)\n    \n    # Reference implementation:\n    magnitude_spectrum_reference = fft_spectrum_reference(image, padding_width)\n    \n    assert np.allclose(magnitude_spectrum_candidate, magnitude_spectrum_reference)", "full_response": "\n        import numpy as np\n    \n        # computing padding tuple:\n        pad_width = ((padding, padding),)*nd_image.ndim\n    \n        # Padding:\n        image_padded = np.pad(nd_image, pad_width=pad_width, mode='symmetric')\n        \n        # prepare the apodization window in 1D:\n        from scipy import signal\n        window_tuple = (signal.windows.hamming(length+2*padding) for length in nd_image.shape)\n        \n        # prepare the apodization window in nD:\n        import functools\n        window = functools.reduce(np.multiply.outer, window_tuple)\n        \n        # Apodize:\n        image_padded_apodized = window*image_padded\n    \n        # Compute the Fourier transform of the image:\n        image_fft = np.fft.fftn(image_padded_apodized)\n        \n        # Shift the zero-frequency component to the center of the spectrum:\n        image_fft_shifted = np.fft.fftshift(image_fft)\n        \n        # Compute the magnitude spectrum:\n        magnitude_spectrum = np.log1p(np.abs(image_fft_shifted))\n            \n        return(magnitude_spectrum)\n    \n    import numpy as np   \n\n    # Test image:\n    image = np.ones((5, 6, 7), dtype=np.int16)\n\n    # Padding:\n    padding_width = 10\n\n    # running the candidate function:\n    magnitude_spectrum_candidate = candidate(image, padding_width)\n    \n    # Reference implementation:\n    magnitude_spectrum_reference = fft_spectrum_reference(image, padding_width)\n    \n    assert np.allclose(magnitude_spectrum_candidate, magnitude_spectrum_reference)", "result": "timed out", "passed": false}
{"task_id": "../test_cases/find_closest_neighbors.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import centroid\n    \n    # Identify all centroid locations\n    label_count = np.max(label_image)\n    centroids = {}\n    for i in range(1, label_count + 1):\n        binary_image = (label_image == i)\n        centroids[i] = centroid(binary_image)\n    \n    # Find the closest top n\n    distances = [(other, np.linalg.norm(centroids[target_label] - centroids[other])) for other in centroids.keys() if other != target_label]\n    sorted_distances = sorted(distances, key = lambda pair: pair[1])\n    topn = [label for label, _ in sorted_distances[:n]]\n\n    return topn", "full_response": "\n    import numpy as np\n    from skimage.measure import centroid\n    \n    # Identify all centroid locations\n    label_count = np.max(label_image)\n    centroids = {}\n    for i in range(1, label_count + 1):\n        binary_image = (label_image == i)\n        centroids[i] = centroid(binary_image)\n    \n    # Find the closest top n\n    distances = [(other, np.linalg.norm(centroids[target_label] - centroids[other])) for other in centroids.keys() if other != target_label]\n    sorted_distances = sorted(distances, key = lambda pair: pair[1])\n    topn = [label for label, _ in sorted_distances[:n]]\n\n    return topn", "result": "passed", "passed": true}
{"task_id": "../test_cases/fit_circle.ipynb", "completion": "\n    import circle_fit as cf\n    xc, yc, r, _ = cf.least_squares_circle(list_of_2d_points)\n    return xc,yc,r", "full_response": "\n    import circle_fit as cf\n    xc, yc, r, _ = cf.least_squares_circle(list_of_2d_points)\n    return xc,yc,r", "result": "passed", "passed": true}
{"task_id": "../test_cases/fit_gaussian_to_spot.ipynb", "completion": "\n    import numpy as np\n    import scipy \n\n    image = np.asarray(image)\n    num_px = image.shape[0]\n    [xx, yy] = np.meshgrid(np.arange(0,num_px), np.arange(0,num_px))\n\n\n    def twoDGauss(x,y,ux,uy,sigma):\n        '''\n        Creates theoretical normalized 2D gaussian spot, centered around (ux,uy) \n        with standard deviation sigma, on grid specified by x and y\n        '''\n        p = 1/(2*np.pi*sigma**2) * np.exp(- ( (x-ux)**2+(y-uy)**2 ) / (2*sigma**2))\n        return p\n\n    def expected(x,y,params):   \n        '''\n        Creates simulated realistic Gaussian spot on x-y grid, with following\n        parameters = [x0,y0,sigma,bg,N], speficically:\n            - x0 = x-position of gaussian (px coord., first pixel is (0,0))\n            - y0 = y-positoin of gaussian (px coord.)\n            - sigma = stdev of gaussian (px coord)\n            - bg = number of photons in background\n            - N = number of photons in spot\n        '''\n        E = params[4] * twoDGauss(x,y,params[0],params[1],params[2]) + params[3]\n        return E\n\n    def SSE(params):\n        '''\n        Calculates sum-of-squared errors difference between 'image' and expected Gaussian defined by 'params'\n        This is essentially the cost-function that is minimized in the fit\n        '''\n        Expec = expected(xx,yy,params)\n        sse = np.sum((image -  Expec)**2)\n        return sse\n\n\n    #guess fit parameters:\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    sigma_guess = 2                 #assume sigma is 2 pixels\n    bg_guess = (np.sum(image) - np.sum(image[1:-1,1:-1]))/(4*num_px-4)           \n                                    #average of border pixels\n    N_guess = np.sum(image) - bg_guess * num_px**2\n                                    #sum of intensities, minus background\n    params_guess = [x_guess,x_guess,sigma_guess, bg_guess, N_guess]\n\n    #perform the fit\n    param = scipy.optimize.fmin(func=SSE,x0=params_guess, maxiter=10000,maxfun=10000,ftol=1e-5,disp=0)\n\n    xc_fit      = param[0]  #fitted x-position\n    yc_fit      = param[1]  #fitted y-position\n    sigma_fit   = param[2]  #fitted sigma\n\n    return (xc_fit, yc_fit, sigma_fit)", "full_response": "\n    import numpy as np\n    import scipy \n\n    image = np.asarray(image)\n    num_px = image.shape[0]\n    [xx, yy] = np.meshgrid(np.arange(0,num_px), np.arange(0,num_px))\n\n\n    def twoDGauss(x,y,ux,uy,sigma):\n        '''\n        Creates theoretical normalized 2D gaussian spot, centered around (ux,uy) \n        with standard deviation sigma, on grid specified by x and y\n        '''\n        p = 1/(2*np.pi*sigma**2) * np.exp(- ( (x-ux)**2+(y-uy)**2 ) / (2*sigma**2))\n        return p\n\n    def expected(x,y,params):   \n        '''\n        Creates simulated realistic Gaussian spot on x-y grid, with following\n        parameters = [x0,y0,sigma,bg,N], speficically:\n            - x0 = x-position of gaussian (px coord., first pixel is (0,0))\n            - y0 = y-positoin of gaussian (px coord.)\n            - sigma = stdev of gaussian (px coord)\n            - bg = number of photons in background\n            - N = number of photons in spot\n        '''\n        E = params[4] * twoDGauss(x,y,params[0],params[1],params[2]) + params[3]\n        return E\n\n    def SSE(params):\n        '''\n        Calculates sum-of-squared errors difference between 'image' and expected Gaussian defined by 'params'\n        This is essentially the cost-function that is minimized in the fit\n        '''\n        Expec = expected(xx,yy,params)\n        sse = np.sum((image -  Expec)**2)\n        return sse\n\n\n    #guess fit parameters:\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    sigma_guess = 2                 #assume sigma is 2 pixels\n    bg_guess = (np.sum(image) - np.sum(image[1:-1,1:-1]))/(4*num_px-4)           \n                                    #average of border pixels\n    N_guess = np.sum(image) - bg_guess * num_px**2\n                                    #sum of intensities, minus background\n    params_guess = [x_guess,x_guess,sigma_guess, bg_guess, N_guess]\n\n    #perform the fit\n    param = scipy.optimize.fmin(func=SSE,x0=params_guess, maxiter=10000,maxfun=10000,ftol=1e-5,disp=0)\n\n    xc_fit      = param[0]  #fitted x-position\n    yc_fit      = param[1]  #fitted y-position\n    sigma_fit   = param[2]  #fitted sigma\n\n    return (xc_fit, yc_fit, sigma_fit)", "result": "passed", "passed": true}
{"task_id": "../test_cases/flow_field_deformation.ipynb", "completion": "\n    import SimpleITK as sitk\n\n    target = sitk.GetImageFromArray(target)\n\n    displacement = sitk.DisplacementFieldTransform(2)\n    field_size = list(flow_field.shape[:2])\n    field_origin = [0, 0]\n    field_spacing = [1.0, 1.0]\n    field_direction = [1, 0, 0, 1]  # direction cosine matrix (row major order)\n\n    # Concatenate all the information into a single list\n    displacement.SetFixedParameters(\n        field_size + field_origin + field_spacing + field_direction\n    )\n    # Set the interpolator to nearest neighbor\n    displacement.SetInterpolator(sitk.sitkNearestNeighbor)\n\n    originalDisplacements = flow_field.reshape((-1, 2)).flatten()\n    displacement.SetParameters(originalDisplacements)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetTransform(displacement)\n    resampler.SetReferenceImage(target)\n    resampled = resampler.Execute(target)\n\n    return sitk.GetArrayFromImage(resampled)", "full_response": "\n    import SimpleITK as sitk\n\n    target = sitk.GetImageFromArray(target)\n\n    displacement = sitk.DisplacementFieldTransform(2)\n    field_size = list(flow_field.shape[:2])\n    field_origin = [0, 0]\n    field_spacing = [1.0, 1.0]\n    field_direction = [1, 0, 0, 1]  # direction cosine matrix (row major order)\n\n    # Concatenate all the information into a single list\n    displacement.SetFixedParameters(\n        field_size + field_origin + field_spacing + field_direction\n    )\n    # Set the interpolator to nearest neighbor\n    displacement.SetInterpolator(sitk.sitkNearestNeighbor)\n\n    originalDisplacements = flow_field.reshape((-1, 2)).flatten()\n    displacement.SetParameters(originalDisplacements)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetTransform(displacement)\n    resampler.SetReferenceImage(target)\n    resampled = resampler.Execute(target)\n\n    return sitk.GetArrayFromImage(resampled)", "result": "passed", "passed": true}
{"task_id": "../test_cases/generate_image_histogram.ipynb", "completion": "\n    import numpy as np\n    return np.histogram(image,bins=num_bins)[0]", "full_response": "\n    import numpy as np\n    return np.histogram(image,bins=num_bins)[0]", "result": "passed", "passed": true}
{"task_id": "../test_cases/identify_centroids.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import centroid\n    n = np.max(label_image)\n    out = {}\n    for i in range(1, n + 1):\n        binary_image = (label_image == i)\n        out[i] = centroid(binary_image)\n    return out", "full_response": "\n    import numpy as np\n    from skimage.measure import centroid\n    n = np.max(label_image)\n    out = {}\n    for i in range(1, n + 1):\n        binary_image = (label_image == i)\n        out[i] = centroid(binary_image)\n    return out", "result": "passed", "passed": true}
{"task_id": "../test_cases/interpolate_stack.ipynb", "completion": "\n    import numpy as np\n\n    return np.linspace(start_slice, end_slice, num)", "full_response": "\n    import numpy as np\n\n    return np.linspace(start_slice, end_slice, num)", "result": "passed", "passed": true}
{"task_id": "../test_cases/label_binary_image_and_count_labels.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    label_image = skimage.measure.label(binary_image)\n\n    return len(np.unique(label_image)) - 1", "full_response": "\n    import skimage\n    import numpy as np\n    label_image = skimage.measure.label(binary_image)\n\n    return len(np.unique(label_image)) - 1", "result": "passed", "passed": true}
{"task_id": "../test_cases/label_sequentially.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.relabel_sequential(label_image)[0]", "full_response": "\n    import skimage\n    return skimage.segmentation.relabel_sequential(label_image)[0]", "result": "passed", "passed": true}
{"task_id": "../test_cases/linear_intensity_profile.ipynb", "completion": "\n    from skimage.measure import profile_line\n    return profile_line(image, starting_point, ending_point)", "full_response": "\n    from skimage.measure import profile_line\n    return profile_line(image, starting_point, ending_point)", "result": "passed", "passed": true}
{"task_id": "../test_cases/list_image_files_in_folder.ipynb", "completion": "\n    import os\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    return [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]", "full_response": "\n    import os\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    return [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]", "result": "passed", "passed": true}
{"task_id": "../test_cases/load_tif_and_output_rgb.ipynb", "completion": "\n    from cv2 import imread, cvtColor, COLOR_BGR2RGB\n    image = imread(path_to_tif)\n    return cvtColor(image, COLOR_BGR2RGB)", "full_response": "\n    from cv2 import imread, cvtColor, COLOR_BGR2RGB\n    image = imread(path_to_tif)\n    return cvtColor(image, COLOR_BGR2RGB)", "result": "failed: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n", "passed": false}
{"task_id": "../test_cases/local_maxima_from_distance_transform.ipynb", "completion": "\n    import scipy.ndimage as ndi\n    import skimage.feature as skf\n    \n    distance_transform = ndi.distance_transform_edt(binary_image)\n    \n    image_max = ndi.maximum_filter(distance_transform, size=nms_window, mode='constant')\n    \n    # suppress non-maxima values by setting them to -1\n    mask = distance_transform == image_max\n    image_max[~mask] = -1\n    \n    local_maxima = skf.peak_local_max(image_max)\n\n    return local_maxima.tolist()", "full_response": "\n    import scipy.ndimage as ndi\n    import skimage.feature as skf\n    \n    distance_transform = ndi.distance_transform_edt(binary_image)\n    \n    image_max = ndi.maximum_filter(distance_transform, size=nms_window, mode='constant')\n    \n    # suppress non-maxima values by setting them to -1\n    mask = distance_transform == image_max\n    image_max[~mask] = -1\n    \n    local_maxima = skf.peak_local_max(image_max)\n\n    return local_maxima.tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/map_pixel_count_of_labels.ipynb", "completion": "\n    import pyclesperanto_prototype as cle\n    return cle.pixel_count_map(label_image)", "full_response": "\n    import pyclesperanto_prototype as cle\n    return cle.pixel_count_map(label_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/mask_image.ipynb", "completion": "\n    import numpy as np\n    return image * mask", "full_response": "\n    import numpy as np\n    return image * mask", "result": "passed", "passed": true}
{"task_id": "../test_cases/maximum_intensity_projection.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).max(axis=0)", "full_response": "\n    import numpy as np\n    return np.asarray(image).max(axis=0)", "result": "passed", "passed": true}
{"task_id": "../test_cases/mean_squared_error.ipynb", "completion": "\n    return ((image1 - image2)**2).mean()\n    # adapted from : https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy", "full_response": "\n    return ((image1 - image2)**2).mean()\n    # adapted from : https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy", "result": "passed", "passed": true}
{"task_id": "../test_cases/mean_std_column.ipynb", "completion": "\n    import numpy as np\n    data = dataframe[column]\n    return np.mean(data), np.std(data)", "full_response": "\n    import numpy as np\n    data = dataframe[column]\n    return np.mean(data), np.std(data)", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_aspect_ratio_of_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = pd.DataFrame(skimage.measure.regionprops_table(label_image, properties=('minor_axis_length', 'major_axis_length')))\n    stats['aspect_ratio'] = stats['major_axis_length'] / stats['minor_axis_length']\n    return stats", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = pd.DataFrame(skimage.measure.regionprops_table(label_image, properties=('minor_axis_length', 'major_axis_length')))\n    stats['aspect_ratio'] = stats['major_axis_length'] / stats['minor_axis_length']\n    return stats", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_intensity_of_labels.ipynb", "completion": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image, intensity_image)\n    return [s.mean_intensity for s in stats]", "full_response": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image, intensity_image)\n    return [s.mean_intensity for s in stats]", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_intensity_over_time.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image_list).mean(axis=(1,2)).tolist()", "full_response": "\n    import numpy as np\n    return np.asarray(image_list).mean(axis=(1,2)).tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_mean_image_intensity.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).mean()", "full_response": "\n    import numpy as np\n    return np.asarray(image).mean()", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_pixel_count_of_labels.ipynb", "completion": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image)\n    return [s.area for s in stats]", "full_response": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image)\n    return [s.area for s in stats]", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_properties_of_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\n    return pd.DataFrame(stats)", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\n    return pd.DataFrame(stats)", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_image_read_voxel_size.ipynb", "completion": "\n    from aicsimageio import AICSImage\n    aics_image = AICSImage(image_filename)\n\n    return aics_image.physical_pixel_sizes.Z, \\\n            aics_image.physical_pixel_sizes.Y, \\\n            aics_image.physical_pixel_sizes.X", "full_response": "\n    from aicsimageio import AICSImage\n    aics_image = AICSImage(image_filename)\n\n    return aics_image.physical_pixel_sizes.Z, \\\n            aics_image.physical_pixel_sizes.Y, \\\n            aics_image.physical_pixel_sizes.X", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_image_return_dimensions.ipynb", "completion": "\n    from skimage.io import imread\n    image = imread(image_file_location)\n    return image.shape", "full_response": "\n    from skimage.io import imread\n    image = imread(image_file_location)\n    return image.shape", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_nifti_image.ipynb", "completion": "\n    \n    import nibabel as nib\n    import numpy as nb\n\n    img = nib.load(image_file_location)\n    data = img.get_fdata()\n    return(data)", "full_response": "\n    \n    import nibabel as nib\n    import numpy as nb\n\n    img = nib.load(image_file_location)\n    data = img.get_fdata()\n    return(data)", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_zarr.ipynb", "completion": "\n    import zarr\n    array = zarr.load(zarr_file_location)\n    return array", "full_response": "\n    import zarr\n    array = zarr.load(zarr_file_location)\n    return array", "result": "passed", "passed": true}
{"task_id": "../test_cases/pair_wise_correlation_matrix.ipynb", "completion": "\n    return dataframe.corr()", "full_response": "\n    return dataframe.corr()", "result": "passed", "passed": true}
{"task_id": "../test_cases/radial_intensity_profile.ipynb", "completion": "\n    import numpy as np\n    y, x = np.indices((image.shape))\n    r = np.sqrt((x - xc)**2 + (y - yc)**2)\n    r = r.astype(int)\n    summed_values = np.bincount(r.ravel(), image.ravel())\n    number_of_pixels_at_r = np.bincount(r.ravel())\n    radial_profile = summed_values / number_of_pixels_at_r\n    return radial_profile ", "full_response": "\n    import numpy as np\n    y, x = np.indices((image.shape))\n    r = np.sqrt((x - xc)**2 + (y - yc)**2)\n    r = r.astype(int)\n    summed_values = np.bincount(r.ravel(), image.ravel())\n    number_of_pixels_at_r = np.bincount(r.ravel())\n    radial_profile = summed_values / number_of_pixels_at_r\n    return radial_profile ", "result": "passed", "passed": true}
{"task_id": "../test_cases/read_imagej_tif_metadata.ipynb", "completion": "\n    from tifffile import TiffFile\n    \n    with (TiffFile(image_filename) as tif):\n        imagej_metadata = tif.imagej_metadata\n    return imagej_metadata", "full_response": "\n    from tifffile import TiffFile\n    \n    with (TiffFile(image_filename) as tif):\n        imagej_metadata = tif.imagej_metadata\n    return imagej_metadata", "result": "passed", "passed": true}
{"task_id": "../test_cases/read_ome_metadata_from_ome_xml.ipynb", "completion": "\n    from ome_types import from_xml\n    ome = from_xml(img_path)\n    return ome.images[0]", "full_response": "\n    from ome_types import from_xml\n    ome = from_xml(img_path)\n    return ome.images[0]", "result": "failed: Could not parse XML from '../example_data/ome_xml_example.xml'", "passed": false}
{"task_id": "../test_cases/region_growing_segmentation.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.flood(image, point)", "full_response": "\n    import skimage\n    return skimage.segmentation.flood(image, point)", "result": "passed", "passed": true}
{"task_id": "../test_cases/register_timelapse.ipynb", "completion": "\n    from skimage import registration\n    import scipy.ndimage as ndi\n\n    new_video = video.copy()\n    ref_frame = new_video[-1]\n    for t in range(len(video) - 1, 0, -1):\n        mov_frame = video[t - 1]\n        shift, _, _ = registration.phase_cross_correlation(\n            ref_frame,\n            mov_frame,\n            upsample_factor=4,\n            normalization=None,\n        )\n        # replaces old ref_frame with shifted mov_frame\n        ref_frame = ndi.shift(mov_frame, shift, order=1)\n        new_video[t - 1] = ref_frame\n\n    return new_video", "full_response": "\n    from skimage import registration\n    import scipy.ndimage as ndi\n\n    new_video = video.copy()\n    ref_frame = new_video[-1]\n    for t in range(len(video) - 1, 0, -1):\n        mov_frame = video[t - 1]\n        shift, _, _ = registration.phase_cross_correlation(\n            ref_frame,\n            mov_frame,\n            upsample_factor=4,\n            normalization=None,\n        )\n        # replaces old ref_frame with shifted mov_frame\n        ref_frame = ndi.shift(mov_frame, shift, order=1)\n        new_video[t - 1] = ref_frame\n\n    return new_video", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_labels_on_edges.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.clear_border(label_image)", "full_response": "\n    import skimage\n    return skimage.segmentation.clear_border(label_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_noise_edge_preserving.ipynb", "completion": "\n    from scipy.ndimage import median_filter\n    filtered_image = median_filter(image, size=radius * 2 + 1)\n    return filtered_image", "full_response": "\n    from scipy.ndimage import median_filter\n    filtered_image = median_filter(image, size=radius * 2 + 1)\n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_small_labels.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.exclude_small_labels(label_image, maximum_size=size_threshold))", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.exclude_small_labels(label_image, maximum_size=size_threshold))", "result": "passed", "passed": true}
{"task_id": "../test_cases/reshape_array.ipynb", "completion": "\n    import numpy as np\n    \n    array = np.asarray(image)\n    array = np.transpose(array, axes=[2, 0, 1])\n    return array", "full_response": "\n    import numpy as np\n    \n    array = np.asarray(image)\n    array = np.transpose(array, axes=[2, 0, 1])\n    return array", "result": "passed", "passed": true}
{"task_id": "../test_cases/return_hello_world.ipynb", "completion": "\n    return \"hello world\"", "full_response": "\n    return \"hello world\"", "result": "passed", "passed": true}
{"task_id": "../test_cases/rgb_to_grey_image_transform.ipynb", "completion": "\n    rgb_sum = r + g + b\n    r = r / rgb_sum\n    g = g / rgb_sum\n    b = b / rgb_sum\n    \n    import numpy as np\n    channel_r = rgb_image[...,0]\n    channel_g = rgb_image[...,1]\n    channel_b = rgb_image[...,2]\n    grey_image = channel_r * r + \\\n                 channel_g * g + \\\n                 channel_b * b\n    \n    return grey_image", "full_response": "\n    rgb_sum = r + g + b\n    r = r / rgb_sum\n    g = g / rgb_sum\n    b = b / rgb_sum\n    \n    import numpy as np\n    channel_r = rgb_image[...,0]\n    channel_g = rgb_image[...,1]\n    channel_b = rgb_image[...,2]\n    grey_image = channel_r * r + \\\n                 channel_g * g + \\\n                 channel_b * b\n    \n    return grey_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/roi_imagej_to_ezomero.ipynb", "completion": "\n    list_of_tuples = list(dataframe.itertuples(index=False, name=None))\n    return list_of_tuples", "full_response": "\n    list_of_tuples = list(dataframe.itertuples(index=False, name=None))\n    return list_of_tuples", "result": "passed", "passed": true}
{"task_id": "../test_cases/rotate_image_by_90_degrees.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.rotate(image, angle_around_z_in_degrees=90))", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.rotate(image, angle_around_z_in_degrees=90))", "result": "passed", "passed": true}
{"task_id": "../test_cases/save_image_with_voxel_size.ipynb", "completion": "\n    from aicsimageio import AICSImage \n    from aicsimageio.types import PhysicalPixelSizes\n    from tempfile import tempdir\n    import os \n\n    image = AICSImage(image)\n    AICSImage.physical_pixel_sizes = PhysicalPixelSizes(Z=vz,Y=vy,X=vx)\n    img_path = os.path.join(tempdir, 'voxel_save_test.ome.tiff')\n    image.save(img_path)\n    return img_path", "full_response": "\n    from aicsimageio import AICSImage \n    from aicsimageio.types import PhysicalPixelSizes\n    from tempfile import tempdir\n    import os \n\n    image = AICSImage(image)\n    AICSImage.physical_pixel_sizes = PhysicalPixelSizes(Z=vz,Y=vy,X=vx)\n    img_path = os.path.join(tempdir, 'voxel_save_test.ome.tiff')\n    image.save(img_path)\n    return img_path", "result": "passed", "passed": true}
{"task_id": "../test_cases/scale_image_affine_transform.ipynb", "completion": "\n    from pyclesperanto_prototype import AffineTransform3D\n    import pyclesperanto_prototype as cle \n    import numpy as np\n    \n    output_img_shape =  (image.shape[0]*sy, image.shape[1]*sx)\n\n    transform = AffineTransform3D()\n    transform.center(image.shape)\n    transform.scale(scale_x = sx, scale_y = sy)\n    transform.center(output_img_shape,undo=True)\n    scaled_image = np.array(cle.affine_transform(image,transform=transform,auto_size=True))\n    return scaled_image, transform._matrix", "full_response": "\n    from pyclesperanto_prototype import AffineTransform3D\n    import pyclesperanto_prototype as cle \n    import numpy as np\n    \n    output_img_shape =  (image.shape[0]*sy, image.shape[1]*sx)\n\n    transform = AffineTransform3D()\n    transform.center(image.shape)\n    transform.scale(scale_x = sx, scale_y = sy)\n    transform.center(output_img_shape,undo=True)\n    scaled_image = np.array(cle.affine_transform(image,transform=transform,auto_size=True))\n    return scaled_image, transform._matrix", "result": "passed", "passed": true}
{"task_id": "../test_cases/select_coexpressing_cells.ipynb", "completion": "\n    import numpy as np\n    import pandas as pd\n    from skimage.measure import regionprops_table\n\n    df = pd.DataFrame(\n        regionprops_table(label_image, image, properties=(\"label\", \"area\", \"intensity_mean\"))\n    )\n    mean_cols = [c for c in df.columns if c.startswith(\"intensity_mean\")]\n    sum_cols = [f\"intensity_sum-{i}\" for i in range(len(mean_cols))]\n    \n    df[sum_cols] = df[mean_cols] * df[\"area\"].to_numpy()\n    \n    selected_ids = df.loc[(df[sum_cols] > threshold).all(axis=1), \"label\"].to_numpy()\n    \n    below_threshold_mask = np.isin(label_image, selected_ids, invert=False)\n    filtered_labels = label_image * below_threshold_mask\n\n    return filtered_labels", "full_response": "\n    import numpy as np\n    import pandas as pd\n    from skimage.measure import regionprops_table\n\n    df = pd.DataFrame(\n        regionprops_table(label_image, image, properties=(\"label\", \"area\", \"intensity_mean\"))\n    )\n    mean_cols = [c for c in df.columns if c.startswith(\"intensity_mean\")]\n    sum_cols = [f\"intensity_sum-{i}\" for i in range(len(mean_cols))]\n    \n    df[sum_cols] = df[mean_cols] * df[\"area\"].to_numpy()\n    \n    selected_ids = df.loc[(df[sum_cols] > threshold).all(axis=1), \"label\"].to_numpy()\n    \n    below_threshold_mask = np.isin(label_image, selected_ids, invert=False)\n    filtered_labels = label_image * below_threshold_mask\n\n    return filtered_labels", "result": "passed", "passed": true}
{"task_id": "../test_cases/stack_and_merge.ipynb", "completion": "\n    import numpy as np\n    stacked_image = np.stack((image1, image2), axis=0)\n    stitched_image = np.concatenate((stacked_image, image3), axis=2)\n    return stitched_image.shape", "full_response": "\n    import numpy as np\n    stacked_image = np.stack((image1, image2), axis=0)\n    stitched_image = np.concatenate((stacked_image, image3), axis=2)\n    return stitched_image.shape", "result": "passed", "passed": true}
{"task_id": "../test_cases/subsample_image.ipynb", "completion": "\n    return image[::n,::n]", "full_response": "\n    return image[::n,::n]", "result": "passed", "passed": true}
{"task_id": "../test_cases/subtract_background_tophat.ipynb", "completion": "\n    from skimage.morphology import white_tophat\n    from skimage.morphology import disk\n    filtered_image = white_tophat(image, footprint=disk(radius))\n    \n    return filtered_image", "full_response": "\n    from skimage.morphology import white_tophat\n    from skimage.morphology import disk\n    filtered_image = white_tophat(image, footprint=disk(radius))\n    \n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/sum_images.ipynb", "completion": "\n    return image1 + image2", "full_response": "\n    return image1 + image2", "result": "passed", "passed": true}
{"task_id": "../test_cases/sum_intensity_projection.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).sum(axis=0)", "full_response": "\n    import numpy as np\n    return np.asarray(image).sum(axis=0)", "result": "passed", "passed": true}
{"task_id": "../test_cases/tiled_image_processing.ipynb", "completion": "\n    import dask\n    import dask.array as da\n\n    tiles = da.from_array(image, chunks=(tile_size, tile_size))\n    \n    def procedure(image):\n        from scipy.ndimage import maximum_filter\n        return maximum_filter(image, size=radius*2+1)\n\n    # setup a lazy result (not computed yet)\n    tile_map = da.map_blocks(procedure, tiles)\n\n    # actually apply filter\n    result = tile_map.compute()\n\n    return result", "full_response": "\n    import dask\n    import dask.array as da\n\n    tiles = da.from_array(image, chunks=(tile_size, tile_size))\n    \n    def procedure(image):\n        from scipy.ndimage import maximum_filter\n        return maximum_filter(image, size=radius*2+1)\n\n    # setup a lazy result (not computed yet)\n    tile_map = da.map_blocks(procedure, tiles)\n\n    # actually apply filter\n    result = tile_map.compute()\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/translate_3d_image_along_vector.ipynb", "completion": "\n    from pyclesperanto_prototype import translate\n\n    # translate 3d image along t_x, t_y and t_z\n    return translate(image, translate_x = t_x, translate_y = t_y, translate_z = t_z)", "full_response": "\n    from pyclesperanto_prototype import translate\n\n    # translate 3d image along t_x, t_y and t_z\n    return translate(image, translate_x = t_x, translate_y = t_y, translate_z = t_z)", "result": "passed", "passed": true}
{"task_id": "../test_cases/transpose_image_axes.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).T", "full_response": "\n    import numpy as np\n    return np.asarray(image).T", "result": "passed", "passed": true}
{"task_id": "../test_cases/t_test.ipynb", "completion": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    return scipy.stats.ttest_rel(data1, data2)[1]\n    ", "full_response": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    return scipy.stats.ttest_rel(data1, data2)[1]\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_batch_process_folder_count_labels.ipynb", "completion": "\n    import os\n    from skimage.io import imread\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]\n    result = {}\n\n    for filename in file_list:\n        image = imread(folder_location + filename)\n\n        labels = np.unique(image).tolist()\n        labels.pop(0)\n\n        count = len(labels)\n\n        result[filename] = count\n\n    return result", "full_response": "\n    import os\n    from skimage.io import imread\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]\n    result = {}\n\n    for filename in file_list:\n        image = imread(folder_location + filename)\n\n        labels = np.unique(image).tolist()\n        labels.pop(0)\n\n        count = len(labels)\n\n        result[filename] = count\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_batch_process_folder_measure_intensity.ipynb", "completion": "\n    import os\n    import pandas as pd\n    from skimage.io import imread\n    from skimage.measure import regionprops\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(image_folder_location) if str(fn[-4:]) in supported_fileendings]\n\n    result = []\n\n    for filename in file_list:\n        image = imread(image_folder_location + filename)[...,0]\n        labels = imread(labels_folder_location + filename)\n\n        stats = regionprops(labels, intensity_image=image)\n\n        for s in stats:\n            result.append({\n                \"filename\":filename,\n                \"label\":s.label,\n                \"min_intensity\":s.min_intensity,\n                \"mean_intensity\":s.mean_intensity,\n                \"max_intensity\":s.max_intensity,\n            })\n\n    return pd.DataFrame(result)", "full_response": "\n    import os\n    import pandas as pd\n    from skimage.io import imread\n    from skimage.measure import regionprops\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(image_folder_location) if str(fn[-4:]) in supported_fileendings]\n\n    result = []\n\n    for filename in file_list:\n        image = imread(image_folder_location + filename)[...,0]\n        labels = imread(labels_folder_location + filename)\n\n        stats = regionprops(labels, intensity_image=image)\n\n        for s in stats:\n            result.append({\n                \"filename\":filename,\n                \"label\":s.label,\n                \"min_intensity\":s.min_intensity,\n                \"mean_intensity\":s.mean_intensity,\n                \"max_intensity\":s.max_intensity,\n            })\n\n    return pd.DataFrame(result)", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segmentation_counting.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    average_intensity = np.asarray(image).mean()\n    binary = image > average_intensity\n    labels = skimage.measure.label(binary)\n    return labels.max()", "full_response": "\n    import skimage\n    import numpy as np\n    average_intensity = np.asarray(image).mean()\n    binary = image > average_intensity\n    labels = skimage.measure.label(binary)\n    return labels.max()", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segmentation_measurement_summary.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n    label_image = skimage.measure.label(binary_image)\n    stats = skimage.measure.regionprops(label_image)\n    areas = [s.area for s in stats]\n    return np.mean(areas)", "full_response": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n    label_image = skimage.measure.label(binary_image)\n    stats = skimage.measure.regionprops(label_image)\n    areas = [s.area for s in stats]\n    return np.mean(areas)", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segment_measure_umap.ipynb", "completion": "\n    import numpy as np\n    import pandas as pd\n    import umap\n    from skimage.measure import label, regionprops_table\n\n    image = np.asarray(image)\n\n    # segment\n    binary = image > 0.5 * image.max()\n    labels = label(binary)\n\n    # measure\n    dataframe = pd.DataFrame(regionprops_table(labels, intensity_image=image, \n                                              properties=['area', 'perimeter', 'mean_intensity', \n                                                          'minor_axis_length', 'major_axis_length']))\n\n    # append UMAP\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    return dataframe", "full_response": "\n    import numpy as np\n    import pandas as pd\n    import umap\n    from skimage.measure import label, regionprops_table\n\n    image = np.asarray(image)\n\n    # segment\n    binary = image > 0.5 * image.max()\n    labels = label(binary)\n\n    # measure\n    dataframe = pd.DataFrame(regionprops_table(labels, intensity_image=image, \n                                              properties=['area', 'perimeter', 'mean_intensity', \n                                                          'minor_axis_length', 'major_axis_length']))\n\n    # append UMAP\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    return dataframe", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_watershed_segmentation_correction_measurement.ipynb", "completion": "\n    import skimage\n    blurred = skimage.filters.gaussian(image * 255, sigma=1)\n    minima = skimage.morphology.local_minima(blurred)\n    spots = skimage.measure.label(minima)\n    labels = skimage.segmentation.watershed(blurred, spots)\n    labels_without_border = skimage.segmentation.clear_border(labels)   \n    binary = labels_without_border > 0\n    return binary.sum()", "full_response": "\n    import skimage\n    blurred = skimage.filters.gaussian(image * 255, sigma=1)\n    minima = skimage.morphology.local_minima(blurred)\n    spots = skimage.measure.label(minima)\n    labels = skimage.segmentation.watershed(blurred, spots)\n    labels_without_border = skimage.segmentation.clear_border(labels)   \n    binary = labels_without_border > 0\n    return binary.sum()", "result": "passed", "passed": true}
{"task_id": "../test_cases/apply_otsu_threshold_and_count_positive_pixels.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n\n    result = np.sum(binary_image)\n\n    return result", "full_response": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n\n    result = np.sum(binary_image)\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/binary_closing.ipynb", "completion": "\n    import numpy as np\n    import skimage\n    size = radius * 2 + 1\n    return skimage.morphology.binary_closing(binary_image, footprint=np.ones((size, size)))", "full_response": "\n    import numpy as np\n    import skimage\n    size = radius * 2 + 1\n    return skimage.morphology.binary_closing(binary_image, footprint=np.ones((size, size)))", "result": "passed", "passed": true}
{"task_id": "../test_cases/binary_skeleton.ipynb", "completion": "\n    from skimage.morphology import skeletonize\n    return skeletonize(binary_image)", "full_response": "\n    from skimage.morphology import skeletonize\n    return skeletonize(binary_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/bland_altman.ipynb", "completion": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    dataframe['mean'] = (data1 + data2) / 2\n    dataframe['diff'] = data2 - data1\n    return dataframe", "full_response": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    dataframe['mean'] = (data1 + data2) / 2\n    dataframe['diff'] = data2 - data1\n    return dataframe", "result": "passed", "passed": true}
{"task_id": "../test_cases/combine_columns_of_tables.ipynb", "completion": "\n    import pandas as pd\n    return pd.merge(dataframe1, dataframe2, how='outer', on='label')", "full_response": "\n    import pandas as pd\n    return pd.merge(dataframe1, dataframe2, how='outer', on='label')", "result": "passed", "passed": true}
{"task_id": "../test_cases/convert_points_polygon.ipynb", "completion": "\n    from shapely import Polygon\n    polygon = Polygon(coordinates)\n    return polygon\n", "full_response": "\n    from shapely import Polygon\n    polygon = Polygon(coordinates)\n    return polygon\n", "result": "passed", "passed": true}
{"task_id": "../test_cases/convex_hull_measure_area.ipynb", "completion": "\n    import vedo\n    convex_hull = vedo.shapes.ConvexHull(point_cloud)\n    return convex_hull.area()", "full_response": "\n    import vedo\n    convex_hull = vedo.shapes.ConvexHull(point_cloud)\n    return convex_hull.area()", "result": "passed", "passed": true}
{"task_id": "../test_cases/convolve_images.ipynb", "completion": "\n    import scipy\n    return scipy.ndimage.convolve(image, kernel_image)\n    ", "full_response": "\n    import scipy\n    return scipy.ndimage.convolve(image, kernel_image)\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_number_of_touching_neighbors.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n\n    touch_matrix = cle.generate_touch_matrix(label_image)\n    cle.set_row(touch_matrix, 0, 0)\n    cle.set_column(touch_matrix, 0, 0)\n\n    return np.asarray(cle.sum_y_projection(touch_matrix))[0,1:].tolist()", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n\n    touch_matrix = cle.generate_touch_matrix(label_image)\n    cle.set_row(touch_matrix, 0, 0)\n    cle.set_column(touch_matrix, 0, 0)\n\n    return np.asarray(cle.sum_y_projection(touch_matrix))[0,1:].tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_objects_over_time.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import label\n    labels = [label(binary_image) for binary_image in binary_image_list]\n    return [len(np.unique(label)) - 1 for label in labels]", "full_response": "\n    import numpy as np\n    from skimage.measure import label\n    labels = [label(binary_image) for binary_image in binary_image_list]\n    return [len(np.unique(label)) - 1 for label in labels]", "result": "passed", "passed": true}
{"task_id": "../test_cases/count_overlapping_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image_1, label_image_2, properties=('mean_intensity',))\n    return (pd.DataFrame(stats)['mean_intensity'] > 0).sum()", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image_1, label_image_2, properties=('mean_intensity',))\n    return (pd.DataFrame(stats)['mean_intensity'] > 0).sum()", "result": "passed", "passed": true}
{"task_id": "../test_cases/create_umap.ipynb", "completion": "\n    import umap\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    # no return value", "full_response": "\n    import umap\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    # no return value", "result": "passed", "passed": true}
{"task_id": "../test_cases/crop_quarter_image.ipynb", "completion": "\n    width = image.shape[1]\n    height = image.shape[0]\n\n    return image[:int(width/2),:int(height/2)]", "full_response": "\n    width = image.shape[1]\n    height = image.shape[0]\n\n    return image[:int(width/2),:int(height/2)]", "result": "passed", "passed": true}
{"task_id": "../test_cases/dataframe_column_rename.ipynb", "completion": "\n    for old_value, new_value in replacements.items():\n        df[column] = df[column].replace(old_value, new_value, regex=True)\n    return df", "full_response": "\n    for old_value, new_value in replacements.items():\n        df[column] = df[column].replace(old_value, new_value, regex=True)\n    return df", "result": "passed", "passed": true}
{"task_id": "../test_cases/deconvolve_image.ipynb", "completion": "\n    from scipy import fftpack\n\n    # adapted from: https://stackoverflow.com/questions/17473917/is-there-a-equivalent-of-scipy-signal-deconvolve-for-2d-arrays\n    star_fft = fftpack.fftshift(fftpack.fftn(image))\n    psf_fft = fftpack.fftshift(fftpack.fftn(kernel_image))\n    return fftpack.fftshift(fftpack.ifftn(fftpack.ifftshift(star_fft/psf_fft)))\n    ", "full_response": "\n    from scipy import fftpack\n\n    # adapted from: https://stackoverflow.com/questions/17473917/is-there-a-equivalent-of-scipy-signal-deconvolve-for-2d-arrays\n    star_fft = fftpack.fftshift(fftpack.fftn(image))\n    psf_fft = fftpack.fftshift(fftpack.fftn(kernel_image))\n    return fftpack.fftshift(fftpack.ifftn(fftpack.ifftshift(star_fft/psf_fft)))\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/detect_edges.ipynb", "completion": "\n    from scipy.ndimage import sobel\n    filtered_image = sobel(image)\n    return filtered_image", "full_response": "\n    from scipy.ndimage import sobel\n    filtered_image = sobel(image)\n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/detect_ellipse.ipynb", "completion": "\n    from skimage.transform import hough_ellipse\n    result = hough_ellipse(image,  accuracy=5, threshold=10)\n    result.sort(order='accumulator')\n    \n    # Estimated parameters for the ellipse\n    best = list(result[-1])\n    yc, xc, a, b = (int(round(x)) for x in best[1:5])\n    \n    return yc, xc", "full_response": "\n    from skimage.transform import hough_ellipse\n    result = hough_ellipse(image,  accuracy=5, threshold=10)\n    result.sort(order='accumulator')\n    \n    # Estimated parameters for the ellipse\n    best = list(result[-1])\n    yc, xc, a, b = (int(round(x)) for x in best[1:5])\n    \n    return yc, xc", "result": "passed", "passed": true}
{"task_id": "../test_cases/distance_between_maxima.ipynb", "completion": "\n    import numpy as np\n\n    im1 = np.asarray(image1)\n    im2 = np.asarray(image2)\n\n    x1,y1 = np.unravel_index(im1.argmax(), im1.shape)\n    x2,y2 = np.unravel_index(im2.argmax(), im2.shape)\n\n    distance = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n\n    return distance", "full_response": "\n    import numpy as np\n\n    im1 = np.asarray(image1)\n    im2 = np.asarray(image2)\n\n    x1,y1 = np.unravel_index(im1.argmax(), im1.shape)\n    x2,y2 = np.unravel_index(im2.argmax(), im2.shape)\n\n    distance = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n\n    return distance", "result": "passed", "passed": true}
{"task_id": "../test_cases/expand_labels_without_overlap.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.expand_labels(label_image, distance=radius)", "full_response": "\n    import skimage\n    return skimage.segmentation.expand_labels(label_image, distance=radius)", "result": "passed", "passed": true}
{"task_id": "../test_cases/extract_surface_measure_area.ipynb", "completion": "\n    import vedo\n    volume = vedo.Volume(binary_volume_image)\n    iso_surface = volume.isosurface()\n    return iso_surface.area()", "full_response": "\n    import vedo\n    volume = vedo.Volume(binary_volume_image)\n    iso_surface = volume.isosurface()\n    return iso_surface.area()", "result": "passed", "passed": true}
{"task_id": "../test_cases/fft_spectrum.ipynb", "completion": "\n        import numpy as np\n    \n        # computing padding tuple:\n        pad_width = ((padding, padding),)*nd_image.ndim\n    \n        # Padding:\n        image_padded = np.pad(nd_image, pad_width=pad_width, mode='symmetric')\n        \n        # prepare the apodization window in 1D:\n        from scipy import signal\n        window_tuple = (signal.windows.hamming(length+2*padding) for length in nd_image.shape)\n        \n        # prepare the apodization window in nD:\n        import functools\n        window = functools.reduce(np.multiply.outer, window_tuple)\n        \n        # Apodize:\n        image_padded_apodized = window*image_padded\n    \n        # Compute the Fourier transform of the image:\n        image_fft = np.fft.fftn(image_padded_apodized)\n        \n        # Shift the zero-frequency component to the center of the spectrum:\n        image_fft_shifted = np.fft.fftshift(image_fft)\n        \n        # Compute the magnitude spectrum:\n        magnitude_spectrum = np.log1p(np.abs(image_fft_shifted))\n            \n        return(magnitude_spectrum)\n    \n    import numpy as np   \n\n    # Test image:\n    image = np.ones((5, 6, 7), dtype=np.int16)\n\n    # Padding:\n    padding_width = 10\n\n    # running the candidate function:\n    magnitude_spectrum_candidate = candidate(image, padding_width)\n    \n    # Reference implementation:\n    magnitude_spectrum_reference = fft_spectrum_reference(image, padding_width)\n    \n    assert np.allclose(magnitude_spectrum_candidate, magnitude_spectrum_reference)", "full_response": "\n        import numpy as np\n    \n        # computing padding tuple:\n        pad_width = ((padding, padding),)*nd_image.ndim\n    \n        # Padding:\n        image_padded = np.pad(nd_image, pad_width=pad_width, mode='symmetric')\n        \n        # prepare the apodization window in 1D:\n        from scipy import signal\n        window_tuple = (signal.windows.hamming(length+2*padding) for length in nd_image.shape)\n        \n        # prepare the apodization window in nD:\n        import functools\n        window = functools.reduce(np.multiply.outer, window_tuple)\n        \n        # Apodize:\n        image_padded_apodized = window*image_padded\n    \n        # Compute the Fourier transform of the image:\n        image_fft = np.fft.fftn(image_padded_apodized)\n        \n        # Shift the zero-frequency component to the center of the spectrum:\n        image_fft_shifted = np.fft.fftshift(image_fft)\n        \n        # Compute the magnitude spectrum:\n        magnitude_spectrum = np.log1p(np.abs(image_fft_shifted))\n            \n        return(magnitude_spectrum)\n    \n    import numpy as np   \n\n    # Test image:\n    image = np.ones((5, 6, 7), dtype=np.int16)\n\n    # Padding:\n    padding_width = 10\n\n    # running the candidate function:\n    magnitude_spectrum_candidate = candidate(image, padding_width)\n    \n    # Reference implementation:\n    magnitude_spectrum_reference = fft_spectrum_reference(image, padding_width)\n    \n    assert np.allclose(magnitude_spectrum_candidate, magnitude_spectrum_reference)", "result": "timed out", "passed": false}
{"task_id": "../test_cases/find_closest_neighbors.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import centroid\n    \n    # Identify all centroid locations\n    label_count = np.max(label_image)\n    centroids = {}\n    for i in range(1, label_count + 1):\n        binary_image = (label_image == i)\n        centroids[i] = centroid(binary_image)\n    \n    # Find the closest top n\n    distances = [(other, np.linalg.norm(centroids[target_label] - centroids[other])) for other in centroids.keys() if other != target_label]\n    sorted_distances = sorted(distances, key = lambda pair: pair[1])\n    topn = [label for label, _ in sorted_distances[:n]]\n\n    return topn", "full_response": "\n    import numpy as np\n    from skimage.measure import centroid\n    \n    # Identify all centroid locations\n    label_count = np.max(label_image)\n    centroids = {}\n    for i in range(1, label_count + 1):\n        binary_image = (label_image == i)\n        centroids[i] = centroid(binary_image)\n    \n    # Find the closest top n\n    distances = [(other, np.linalg.norm(centroids[target_label] - centroids[other])) for other in centroids.keys() if other != target_label]\n    sorted_distances = sorted(distances, key = lambda pair: pair[1])\n    topn = [label for label, _ in sorted_distances[:n]]\n\n    return topn", "result": "passed", "passed": true}
{"task_id": "../test_cases/fit_circle.ipynb", "completion": "\n    import circle_fit as cf\n    xc, yc, r, _ = cf.least_squares_circle(list_of_2d_points)\n    return xc,yc,r", "full_response": "\n    import circle_fit as cf\n    xc, yc, r, _ = cf.least_squares_circle(list_of_2d_points)\n    return xc,yc,r", "result": "passed", "passed": true}
{"task_id": "../test_cases/fit_gaussian_to_spot.ipynb", "completion": "\n    import numpy as np\n    import scipy \n\n    image = np.asarray(image)\n    num_px = image.shape[0]\n    [xx, yy] = np.meshgrid(np.arange(0,num_px), np.arange(0,num_px))\n\n\n    def twoDGauss(x,y,ux,uy,sigma):\n        '''\n        Creates theoretical normalized 2D gaussian spot, centered around (ux,uy) \n        with standard deviation sigma, on grid specified by x and y\n        '''\n        p = 1/(2*np.pi*sigma**2) * np.exp(- ( (x-ux)**2+(y-uy)**2 ) / (2*sigma**2))\n        return p\n\n    def expected(x,y,params):   \n        '''\n        Creates simulated realistic Gaussian spot on x-y grid, with following\n        parameters = [x0,y0,sigma,bg,N], speficically:\n            - x0 = x-position of gaussian (px coord., first pixel is (0,0))\n            - y0 = y-positoin of gaussian (px coord.)\n            - sigma = stdev of gaussian (px coord)\n            - bg = number of photons in background\n            - N = number of photons in spot\n        '''\n        E = params[4] * twoDGauss(x,y,params[0],params[1],params[2]) + params[3]\n        return E\n\n    def SSE(params):\n        '''\n        Calculates sum-of-squared errors difference between 'image' and expected Gaussian defined by 'params'\n        This is essentially the cost-function that is minimized in the fit\n        '''\n        Expec = expected(xx,yy,params)\n        sse = np.sum((image -  Expec)**2)\n        return sse\n\n\n    #guess fit parameters:\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    sigma_guess = 2                 #assume sigma is 2 pixels\n    bg_guess = (np.sum(image) - np.sum(image[1:-1,1:-1]))/(4*num_px-4)           \n                                    #average of border pixels\n    N_guess = np.sum(image) - bg_guess * num_px**2\n                                    #sum of intensities, minus background\n    params_guess = [x_guess,x_guess,sigma_guess, bg_guess, N_guess]\n\n    #perform the fit\n    param = scipy.optimize.fmin(func=SSE,x0=params_guess, maxiter=10000,maxfun=10000,ftol=1e-5,disp=0)\n\n    xc_fit      = param[0]  #fitted x-position\n    yc_fit      = param[1]  #fitted y-position\n    sigma_fit   = param[2]  #fitted sigma\n\n    return (xc_fit, yc_fit, sigma_fit)", "full_response": "\n    import numpy as np\n    import scipy \n\n    image = np.asarray(image)\n    num_px = image.shape[0]\n    [xx, yy] = np.meshgrid(np.arange(0,num_px), np.arange(0,num_px))\n\n\n    def twoDGauss(x,y,ux,uy,sigma):\n        '''\n        Creates theoretical normalized 2D gaussian spot, centered around (ux,uy) \n        with standard deviation sigma, on grid specified by x and y\n        '''\n        p = 1/(2*np.pi*sigma**2) * np.exp(- ( (x-ux)**2+(y-uy)**2 ) / (2*sigma**2))\n        return p\n\n    def expected(x,y,params):   \n        '''\n        Creates simulated realistic Gaussian spot on x-y grid, with following\n        parameters = [x0,y0,sigma,bg,N], speficically:\n            - x0 = x-position of gaussian (px coord., first pixel is (0,0))\n            - y0 = y-positoin of gaussian (px coord.)\n            - sigma = stdev of gaussian (px coord)\n            - bg = number of photons in background\n            - N = number of photons in spot\n        '''\n        E = params[4] * twoDGauss(x,y,params[0],params[1],params[2]) + params[3]\n        return E\n\n    def SSE(params):\n        '''\n        Calculates sum-of-squared errors difference between 'image' and expected Gaussian defined by 'params'\n        This is essentially the cost-function that is minimized in the fit\n        '''\n        Expec = expected(xx,yy,params)\n        sse = np.sum((image -  Expec)**2)\n        return sse\n\n\n    #guess fit parameters:\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    x_guess = image.shape[0]/2      #assume gaussian is in the center of FOV\n    sigma_guess = 2                 #assume sigma is 2 pixels\n    bg_guess = (np.sum(image) - np.sum(image[1:-1,1:-1]))/(4*num_px-4)           \n                                    #average of border pixels\n    N_guess = np.sum(image) - bg_guess * num_px**2\n                                    #sum of intensities, minus background\n    params_guess = [x_guess,x_guess,sigma_guess, bg_guess, N_guess]\n\n    #perform the fit\n    param = scipy.optimize.fmin(func=SSE,x0=params_guess, maxiter=10000,maxfun=10000,ftol=1e-5,disp=0)\n\n    xc_fit      = param[0]  #fitted x-position\n    yc_fit      = param[1]  #fitted y-position\n    sigma_fit   = param[2]  #fitted sigma\n\n    return (xc_fit, yc_fit, sigma_fit)", "result": "passed", "passed": true}
{"task_id": "../test_cases/flow_field_deformation.ipynb", "completion": "\n    import SimpleITK as sitk\n\n    target = sitk.GetImageFromArray(target)\n\n    displacement = sitk.DisplacementFieldTransform(2)\n    field_size = list(flow_field.shape[:2])\n    field_origin = [0, 0]\n    field_spacing = [1.0, 1.0]\n    field_direction = [1, 0, 0, 1]  # direction cosine matrix (row major order)\n\n    # Concatenate all the information into a single list\n    displacement.SetFixedParameters(\n        field_size + field_origin + field_spacing + field_direction\n    )\n    # Set the interpolator to nearest neighbor\n    displacement.SetInterpolator(sitk.sitkNearestNeighbor)\n\n    originalDisplacements = flow_field.reshape((-1, 2)).flatten()\n    displacement.SetParameters(originalDisplacements)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetTransform(displacement)\n    resampler.SetReferenceImage(target)\n    resampled = resampler.Execute(target)\n\n    return sitk.GetArrayFromImage(resampled)", "full_response": "\n    import SimpleITK as sitk\n\n    target = sitk.GetImageFromArray(target)\n\n    displacement = sitk.DisplacementFieldTransform(2)\n    field_size = list(flow_field.shape[:2])\n    field_origin = [0, 0]\n    field_spacing = [1.0, 1.0]\n    field_direction = [1, 0, 0, 1]  # direction cosine matrix (row major order)\n\n    # Concatenate all the information into a single list\n    displacement.SetFixedParameters(\n        field_size + field_origin + field_spacing + field_direction\n    )\n    # Set the interpolator to nearest neighbor\n    displacement.SetInterpolator(sitk.sitkNearestNeighbor)\n\n    originalDisplacements = flow_field.reshape((-1, 2)).flatten()\n    displacement.SetParameters(originalDisplacements)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetTransform(displacement)\n    resampler.SetReferenceImage(target)\n    resampled = resampler.Execute(target)\n\n    return sitk.GetArrayFromImage(resampled)", "result": "passed", "passed": true}
{"task_id": "../test_cases/generate_image_histogram.ipynb", "completion": "\n    import numpy as np\n    return np.histogram(image,bins=num_bins)[0]", "full_response": "\n    import numpy as np\n    return np.histogram(image,bins=num_bins)[0]", "result": "passed", "passed": true}
{"task_id": "../test_cases/identify_centroids.ipynb", "completion": "\n    import numpy as np\n    from skimage.measure import centroid\n    n = np.max(label_image)\n    out = {}\n    for i in range(1, n + 1):\n        binary_image = (label_image == i)\n        out[i] = centroid(binary_image)\n    return out", "full_response": "\n    import numpy as np\n    from skimage.measure import centroid\n    n = np.max(label_image)\n    out = {}\n    for i in range(1, n + 1):\n        binary_image = (label_image == i)\n        out[i] = centroid(binary_image)\n    return out", "result": "passed", "passed": true}
{"task_id": "../test_cases/interpolate_stack.ipynb", "completion": "\n    import numpy as np\n\n    return np.linspace(start_slice, end_slice, num)", "full_response": "\n    import numpy as np\n\n    return np.linspace(start_slice, end_slice, num)", "result": "passed", "passed": true}
{"task_id": "../test_cases/label_binary_image_and_count_labels.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    label_image = skimage.measure.label(binary_image)\n\n    return len(np.unique(label_image)) - 1", "full_response": "\n    import skimage\n    import numpy as np\n    label_image = skimage.measure.label(binary_image)\n\n    return len(np.unique(label_image)) - 1", "result": "passed", "passed": true}
{"task_id": "../test_cases/label_sequentially.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.relabel_sequential(label_image)[0]", "full_response": "\n    import skimage\n    return skimage.segmentation.relabel_sequential(label_image)[0]", "result": "passed", "passed": true}
{"task_id": "../test_cases/linear_intensity_profile.ipynb", "completion": "\n    from skimage.measure import profile_line\n    return profile_line(image, starting_point, ending_point)", "full_response": "\n    from skimage.measure import profile_line\n    return profile_line(image, starting_point, ending_point)", "result": "passed", "passed": true}
{"task_id": "../test_cases/list_image_files_in_folder.ipynb", "completion": "\n    import os\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    return [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]", "full_response": "\n    import os\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    return [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]", "result": "passed", "passed": true}
{"task_id": "../test_cases/load_tif_and_output_rgb.ipynb", "completion": "\n    from cv2 import imread, cvtColor, COLOR_BGR2RGB\n    image = imread(path_to_tif)\n    return cvtColor(image, COLOR_BGR2RGB)", "full_response": "\n    from cv2 import imread, cvtColor, COLOR_BGR2RGB\n    image = imread(path_to_tif)\n    return cvtColor(image, COLOR_BGR2RGB)", "result": "failed: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n", "passed": false}
{"task_id": "../test_cases/local_maxima_from_distance_transform.ipynb", "completion": "\n    import scipy.ndimage as ndi\n    import skimage.feature as skf\n    \n    distance_transform = ndi.distance_transform_edt(binary_image)\n    \n    image_max = ndi.maximum_filter(distance_transform, size=nms_window, mode='constant')\n    \n    # suppress non-maxima values by setting them to -1\n    mask = distance_transform == image_max\n    image_max[~mask] = -1\n    \n    local_maxima = skf.peak_local_max(image_max)\n\n    return local_maxima.tolist()", "full_response": "\n    import scipy.ndimage as ndi\n    import skimage.feature as skf\n    \n    distance_transform = ndi.distance_transform_edt(binary_image)\n    \n    image_max = ndi.maximum_filter(distance_transform, size=nms_window, mode='constant')\n    \n    # suppress non-maxima values by setting them to -1\n    mask = distance_transform == image_max\n    image_max[~mask] = -1\n    \n    local_maxima = skf.peak_local_max(image_max)\n\n    return local_maxima.tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/map_pixel_count_of_labels.ipynb", "completion": "\n    import pyclesperanto_prototype as cle\n    return cle.pixel_count_map(label_image)", "full_response": "\n    import pyclesperanto_prototype as cle\n    return cle.pixel_count_map(label_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/mask_image.ipynb", "completion": "\n    import numpy as np\n    return image * mask", "full_response": "\n    import numpy as np\n    return image * mask", "result": "passed", "passed": true}
{"task_id": "../test_cases/maximum_intensity_projection.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).max(axis=0)", "full_response": "\n    import numpy as np\n    return np.asarray(image).max(axis=0)", "result": "passed", "passed": true}
{"task_id": "../test_cases/mean_squared_error.ipynb", "completion": "\n    return ((image1 - image2)**2).mean()\n    # adapted from : https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy", "full_response": "\n    return ((image1 - image2)**2).mean()\n    # adapted from : https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy", "result": "passed", "passed": true}
{"task_id": "../test_cases/mean_std_column.ipynb", "completion": "\n    import numpy as np\n    data = dataframe[column]\n    return np.mean(data), np.std(data)", "full_response": "\n    import numpy as np\n    data = dataframe[column]\n    return np.mean(data), np.std(data)", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_aspect_ratio_of_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = pd.DataFrame(skimage.measure.regionprops_table(label_image, properties=('minor_axis_length', 'major_axis_length')))\n    stats['aspect_ratio'] = stats['major_axis_length'] / stats['minor_axis_length']\n    return stats", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = pd.DataFrame(skimage.measure.regionprops_table(label_image, properties=('minor_axis_length', 'major_axis_length')))\n    stats['aspect_ratio'] = stats['major_axis_length'] / stats['minor_axis_length']\n    return stats", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_intensity_of_labels.ipynb", "completion": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image, intensity_image)\n    return [s.mean_intensity for s in stats]", "full_response": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image, intensity_image)\n    return [s.mean_intensity for s in stats]", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_intensity_over_time.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image_list).mean(axis=(1,2)).tolist()", "full_response": "\n    import numpy as np\n    return np.asarray(image_list).mean(axis=(1,2)).tolist()", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_mean_image_intensity.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).mean()", "full_response": "\n    import numpy as np\n    return np.asarray(image).mean()", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_pixel_count_of_labels.ipynb", "completion": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image)\n    return [s.area for s in stats]", "full_response": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image)\n    return [s.area for s in stats]", "result": "passed", "passed": true}
{"task_id": "../test_cases/measure_properties_of_regions.ipynb", "completion": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\n    return pd.DataFrame(stats)", "full_response": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\n    return pd.DataFrame(stats)", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_image_read_voxel_size.ipynb", "completion": "\n    from aicsimageio import AICSImage\n    aics_image = AICSImage(image_filename)\n\n    return aics_image.physical_pixel_sizes.Z, \\\n            aics_image.physical_pixel_sizes.Y, \\\n            aics_image.physical_pixel_sizes.X", "full_response": "\n    from aicsimageio import AICSImage\n    aics_image = AICSImage(image_filename)\n\n    return aics_image.physical_pixel_sizes.Z, \\\n            aics_image.physical_pixel_sizes.Y, \\\n            aics_image.physical_pixel_sizes.X", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_image_return_dimensions.ipynb", "completion": "\n    from skimage.io import imread\n    image = imread(image_file_location)\n    return image.shape", "full_response": "\n    from skimage.io import imread\n    image = imread(image_file_location)\n    return image.shape", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_nifti_image.ipynb", "completion": "\n    \n    import nibabel as nib\n    import numpy as nb\n\n    img = nib.load(image_file_location)\n    data = img.get_fdata()\n    return(data)", "full_response": "\n    \n    import nibabel as nib\n    import numpy as nb\n\n    img = nib.load(image_file_location)\n    data = img.get_fdata()\n    return(data)", "result": "passed", "passed": true}
{"task_id": "../test_cases/open_zarr.ipynb", "completion": "\n    import zarr\n    array = zarr.load(zarr_file_location)\n    return array", "full_response": "\n    import zarr\n    array = zarr.load(zarr_file_location)\n    return array", "result": "passed", "passed": true}
{"task_id": "../test_cases/pair_wise_correlation_matrix.ipynb", "completion": "\n    return dataframe.corr()", "full_response": "\n    return dataframe.corr()", "result": "passed", "passed": true}
{"task_id": "../test_cases/radial_intensity_profile.ipynb", "completion": "\n    import numpy as np\n    y, x = np.indices((image.shape))\n    r = np.sqrt((x - xc)**2 + (y - yc)**2)\n    r = r.astype(int)\n    summed_values = np.bincount(r.ravel(), image.ravel())\n    number_of_pixels_at_r = np.bincount(r.ravel())\n    radial_profile = summed_values / number_of_pixels_at_r\n    return radial_profile ", "full_response": "\n    import numpy as np\n    y, x = np.indices((image.shape))\n    r = np.sqrt((x - xc)**2 + (y - yc)**2)\n    r = r.astype(int)\n    summed_values = np.bincount(r.ravel(), image.ravel())\n    number_of_pixels_at_r = np.bincount(r.ravel())\n    radial_profile = summed_values / number_of_pixels_at_r\n    return radial_profile ", "result": "passed", "passed": true}
{"task_id": "../test_cases/read_imagej_tif_metadata.ipynb", "completion": "\n    from tifffile import TiffFile\n    \n    with (TiffFile(image_filename) as tif):\n        imagej_metadata = tif.imagej_metadata\n    return imagej_metadata", "full_response": "\n    from tifffile import TiffFile\n    \n    with (TiffFile(image_filename) as tif):\n        imagej_metadata = tif.imagej_metadata\n    return imagej_metadata", "result": "passed", "passed": true}
{"task_id": "../test_cases/read_ome_metadata_from_ome_xml.ipynb", "completion": "\n    from ome_types import from_xml\n    ome = from_xml(img_path)\n    return ome.images[0]", "full_response": "\n    from ome_types import from_xml\n    ome = from_xml(img_path)\n    return ome.images[0]", "result": "failed: Could not parse XML from '../example_data/ome_xml_example.xml'", "passed": false}
{"task_id": "../test_cases/region_growing_segmentation.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.flood(image, point)", "full_response": "\n    import skimage\n    return skimage.segmentation.flood(image, point)", "result": "passed", "passed": true}
{"task_id": "../test_cases/register_timelapse.ipynb", "completion": "\n    from skimage import registration\n    import scipy.ndimage as ndi\n\n    new_video = video.copy()\n    ref_frame = new_video[-1]\n    for t in range(len(video) - 1, 0, -1):\n        mov_frame = video[t - 1]\n        shift, _, _ = registration.phase_cross_correlation(\n            ref_frame,\n            mov_frame,\n            upsample_factor=4,\n            normalization=None,\n        )\n        # replaces old ref_frame with shifted mov_frame\n        ref_frame = ndi.shift(mov_frame, shift, order=1)\n        new_video[t - 1] = ref_frame\n\n    return new_video", "full_response": "\n    from skimage import registration\n    import scipy.ndimage as ndi\n\n    new_video = video.copy()\n    ref_frame = new_video[-1]\n    for t in range(len(video) - 1, 0, -1):\n        mov_frame = video[t - 1]\n        shift, _, _ = registration.phase_cross_correlation(\n            ref_frame,\n            mov_frame,\n            upsample_factor=4,\n            normalization=None,\n        )\n        # replaces old ref_frame with shifted mov_frame\n        ref_frame = ndi.shift(mov_frame, shift, order=1)\n        new_video[t - 1] = ref_frame\n\n    return new_video", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_labels_on_edges.ipynb", "completion": "\n    import skimage\n    return skimage.segmentation.clear_border(label_image)", "full_response": "\n    import skimage\n    return skimage.segmentation.clear_border(label_image)", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_noise_edge_preserving.ipynb", "completion": "\n    from scipy.ndimage import median_filter\n    filtered_image = median_filter(image, size=radius * 2 + 1)\n    return filtered_image", "full_response": "\n    from scipy.ndimage import median_filter\n    filtered_image = median_filter(image, size=radius * 2 + 1)\n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/remove_small_labels.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.exclude_small_labels(label_image, maximum_size=size_threshold))", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.exclude_small_labels(label_image, maximum_size=size_threshold))", "result": "passed", "passed": true}
{"task_id": "../test_cases/reshape_array.ipynb", "completion": "\n    import numpy as np\n    \n    array = np.asarray(image)\n    array = np.transpose(array, axes=[2, 0, 1])\n    return array", "full_response": "\n    import numpy as np\n    \n    array = np.asarray(image)\n    array = np.transpose(array, axes=[2, 0, 1])\n    return array", "result": "passed", "passed": true}
{"task_id": "../test_cases/return_hello_world.ipynb", "completion": "\n    return \"hello world\"", "full_response": "\n    return \"hello world\"", "result": "passed", "passed": true}
{"task_id": "../test_cases/rgb_to_grey_image_transform.ipynb", "completion": "\n    rgb_sum = r + g + b\n    r = r / rgb_sum\n    g = g / rgb_sum\n    b = b / rgb_sum\n    \n    import numpy as np\n    channel_r = rgb_image[...,0]\n    channel_g = rgb_image[...,1]\n    channel_b = rgb_image[...,2]\n    grey_image = channel_r * r + \\\n                 channel_g * g + \\\n                 channel_b * b\n    \n    return grey_image", "full_response": "\n    rgb_sum = r + g + b\n    r = r / rgb_sum\n    g = g / rgb_sum\n    b = b / rgb_sum\n    \n    import numpy as np\n    channel_r = rgb_image[...,0]\n    channel_g = rgb_image[...,1]\n    channel_b = rgb_image[...,2]\n    grey_image = channel_r * r + \\\n                 channel_g * g + \\\n                 channel_b * b\n    \n    return grey_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/roi_imagej_to_ezomero.ipynb", "completion": "\n    list_of_tuples = list(dataframe.itertuples(index=False, name=None))\n    return list_of_tuples", "full_response": "\n    list_of_tuples = list(dataframe.itertuples(index=False, name=None))\n    return list_of_tuples", "result": "passed", "passed": true}
{"task_id": "../test_cases/rotate_image_by_90_degrees.ipynb", "completion": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.rotate(image, angle_around_z_in_degrees=90))", "full_response": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n    return np.asarray(cle.rotate(image, angle_around_z_in_degrees=90))", "result": "passed", "passed": true}
{"task_id": "../test_cases/save_image_with_voxel_size.ipynb", "completion": "\n    from aicsimageio import AICSImage \n    from aicsimageio.types import PhysicalPixelSizes\n    from tempfile import tempdir\n    import os \n\n    image = AICSImage(image)\n    AICSImage.physical_pixel_sizes = PhysicalPixelSizes(Z=vz,Y=vy,X=vx)\n    img_path = os.path.join(tempdir, 'voxel_save_test.ome.tiff')\n    image.save(img_path)\n    return img_path", "full_response": "\n    from aicsimageio import AICSImage \n    from aicsimageio.types import PhysicalPixelSizes\n    from tempfile import tempdir\n    import os \n\n    image = AICSImage(image)\n    AICSImage.physical_pixel_sizes = PhysicalPixelSizes(Z=vz,Y=vy,X=vx)\n    img_path = os.path.join(tempdir, 'voxel_save_test.ome.tiff')\n    image.save(img_path)\n    return img_path", "result": "passed", "passed": true}
{"task_id": "../test_cases/scale_image_affine_transform.ipynb", "completion": "\n    from pyclesperanto_prototype import AffineTransform3D\n    import pyclesperanto_prototype as cle \n    import numpy as np\n    \n    output_img_shape =  (image.shape[0]*sy, image.shape[1]*sx)\n\n    transform = AffineTransform3D()\n    transform.center(image.shape)\n    transform.scale(scale_x = sx, scale_y = sy)\n    transform.center(output_img_shape,undo=True)\n    scaled_image = np.array(cle.affine_transform(image,transform=transform,auto_size=True))\n    return scaled_image, transform._matrix", "full_response": "\n    from pyclesperanto_prototype import AffineTransform3D\n    import pyclesperanto_prototype as cle \n    import numpy as np\n    \n    output_img_shape =  (image.shape[0]*sy, image.shape[1]*sx)\n\n    transform = AffineTransform3D()\n    transform.center(image.shape)\n    transform.scale(scale_x = sx, scale_y = sy)\n    transform.center(output_img_shape,undo=True)\n    scaled_image = np.array(cle.affine_transform(image,transform=transform,auto_size=True))\n    return scaled_image, transform._matrix", "result": "passed", "passed": true}
{"task_id": "../test_cases/select_coexpressing_cells.ipynb", "completion": "\n    import numpy as np\n    import pandas as pd\n    from skimage.measure import regionprops_table\n\n    df = pd.DataFrame(\n        regionprops_table(label_image, image, properties=(\"label\", \"area\", \"intensity_mean\"))\n    )\n    mean_cols = [c for c in df.columns if c.startswith(\"intensity_mean\")]\n    sum_cols = [f\"intensity_sum-{i}\" for i in range(len(mean_cols))]\n    \n    df[sum_cols] = df[mean_cols] * df[\"area\"].to_numpy()\n    \n    selected_ids = df.loc[(df[sum_cols] > threshold).all(axis=1), \"label\"].to_numpy()\n    \n    below_threshold_mask = np.isin(label_image, selected_ids, invert=False)\n    filtered_labels = label_image * below_threshold_mask\n\n    return filtered_labels", "full_response": "\n    import numpy as np\n    import pandas as pd\n    from skimage.measure import regionprops_table\n\n    df = pd.DataFrame(\n        regionprops_table(label_image, image, properties=(\"label\", \"area\", \"intensity_mean\"))\n    )\n    mean_cols = [c for c in df.columns if c.startswith(\"intensity_mean\")]\n    sum_cols = [f\"intensity_sum-{i}\" for i in range(len(mean_cols))]\n    \n    df[sum_cols] = df[mean_cols] * df[\"area\"].to_numpy()\n    \n    selected_ids = df.loc[(df[sum_cols] > threshold).all(axis=1), \"label\"].to_numpy()\n    \n    below_threshold_mask = np.isin(label_image, selected_ids, invert=False)\n    filtered_labels = label_image * below_threshold_mask\n\n    return filtered_labels", "result": "passed", "passed": true}
{"task_id": "../test_cases/stack_and_merge.ipynb", "completion": "\n    import numpy as np\n    stacked_image = np.stack((image1, image2), axis=0)\n    stitched_image = np.concatenate((stacked_image, image3), axis=2)\n    return stitched_image.shape", "full_response": "\n    import numpy as np\n    stacked_image = np.stack((image1, image2), axis=0)\n    stitched_image = np.concatenate((stacked_image, image3), axis=2)\n    return stitched_image.shape", "result": "passed", "passed": true}
{"task_id": "../test_cases/subsample_image.ipynb", "completion": "\n    return image[::n,::n]", "full_response": "\n    return image[::n,::n]", "result": "passed", "passed": true}
{"task_id": "../test_cases/subtract_background_tophat.ipynb", "completion": "\n    from skimage.morphology import white_tophat\n    from skimage.morphology import disk\n    filtered_image = white_tophat(image, footprint=disk(radius))\n    \n    return filtered_image", "full_response": "\n    from skimage.morphology import white_tophat\n    from skimage.morphology import disk\n    filtered_image = white_tophat(image, footprint=disk(radius))\n    \n    return filtered_image", "result": "passed", "passed": true}
{"task_id": "../test_cases/sum_images.ipynb", "completion": "\n    return image1 + image2", "full_response": "\n    return image1 + image2", "result": "passed", "passed": true}
{"task_id": "../test_cases/sum_intensity_projection.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).sum(axis=0)", "full_response": "\n    import numpy as np\n    return np.asarray(image).sum(axis=0)", "result": "passed", "passed": true}
{"task_id": "../test_cases/tiled_image_processing.ipynb", "completion": "\n    import dask\n    import dask.array as da\n\n    tiles = da.from_array(image, chunks=(tile_size, tile_size))\n    \n    def procedure(image):\n        from scipy.ndimage import maximum_filter\n        return maximum_filter(image, size=radius*2+1)\n\n    # setup a lazy result (not computed yet)\n    tile_map = da.map_blocks(procedure, tiles)\n\n    # actually apply filter\n    result = tile_map.compute()\n\n    return result", "full_response": "\n    import dask\n    import dask.array as da\n\n    tiles = da.from_array(image, chunks=(tile_size, tile_size))\n    \n    def procedure(image):\n        from scipy.ndimage import maximum_filter\n        return maximum_filter(image, size=radius*2+1)\n\n    # setup a lazy result (not computed yet)\n    tile_map = da.map_blocks(procedure, tiles)\n\n    # actually apply filter\n    result = tile_map.compute()\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/translate_3d_image_along_vector.ipynb", "completion": "\n    from pyclesperanto_prototype import translate\n\n    # translate 3d image along t_x, t_y and t_z\n    return translate(image, translate_x = t_x, translate_y = t_y, translate_z = t_z)", "full_response": "\n    from pyclesperanto_prototype import translate\n\n    # translate 3d image along t_x, t_y and t_z\n    return translate(image, translate_x = t_x, translate_y = t_y, translate_z = t_z)", "result": "passed", "passed": true}
{"task_id": "../test_cases/transpose_image_axes.ipynb", "completion": "\n    import numpy as np\n    return np.asarray(image).T", "full_response": "\n    import numpy as np\n    return np.asarray(image).T", "result": "passed", "passed": true}
{"task_id": "../test_cases/t_test.ipynb", "completion": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    return scipy.stats.ttest_rel(data1, data2)[1]\n    ", "full_response": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    return scipy.stats.ttest_rel(data1, data2)[1]\n    ", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_batch_process_folder_count_labels.ipynb", "completion": "\n    import os\n    from skimage.io import imread\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]\n    result = {}\n\n    for filename in file_list:\n        image = imread(folder_location + filename)\n\n        labels = np.unique(image).tolist()\n        labels.pop(0)\n\n        count = len(labels)\n\n        result[filename] = count\n\n    return result", "full_response": "\n    import os\n    from skimage.io import imread\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(folder_location) if str(fn[-4:]) in supported_fileendings]\n    result = {}\n\n    for filename in file_list:\n        image = imread(folder_location + filename)\n\n        labels = np.unique(image).tolist()\n        labels.pop(0)\n\n        count = len(labels)\n\n        result[filename] = count\n\n    return result", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_batch_process_folder_measure_intensity.ipynb", "completion": "\n    import os\n    import pandas as pd\n    from skimage.io import imread\n    from skimage.measure import regionprops\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(image_folder_location) if str(fn[-4:]) in supported_fileendings]\n\n    result = []\n\n    for filename in file_list:\n        image = imread(image_folder_location + filename)[...,0]\n        labels = imread(labels_folder_location + filename)\n\n        stats = regionprops(labels, intensity_image=image)\n\n        for s in stats:\n            result.append({\n                \"filename\":filename,\n                \"label\":s.label,\n                \"min_intensity\":s.min_intensity,\n                \"mean_intensity\":s.mean_intensity,\n                \"max_intensity\":s.max_intensity,\n            })\n\n    return pd.DataFrame(result)", "full_response": "\n    import os\n    import pandas as pd\n    from skimage.io import imread\n    from skimage.measure import regionprops\n    import numpy as np\n\n    supported_fileendings = [\".tif\", \".jpg\", \".png\"]    \n    file_list = [fn for fn in os.listdir(image_folder_location) if str(fn[-4:]) in supported_fileendings]\n\n    result = []\n\n    for filename in file_list:\n        image = imread(image_folder_location + filename)[...,0]\n        labels = imread(labels_folder_location + filename)\n\n        stats = regionprops(labels, intensity_image=image)\n\n        for s in stats:\n            result.append({\n                \"filename\":filename,\n                \"label\":s.label,\n                \"min_intensity\":s.min_intensity,\n                \"mean_intensity\":s.mean_intensity,\n                \"max_intensity\":s.max_intensity,\n            })\n\n    return pd.DataFrame(result)", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segmentation_counting.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    average_intensity = np.asarray(image).mean()\n    binary = image > average_intensity\n    labels = skimage.measure.label(binary)\n    return labels.max()", "full_response": "\n    import skimage\n    import numpy as np\n    average_intensity = np.asarray(image).mean()\n    binary = image > average_intensity\n    labels = skimage.measure.label(binary)\n    return labels.max()", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segmentation_measurement_summary.ipynb", "completion": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n    label_image = skimage.measure.label(binary_image)\n    stats = skimage.measure.regionprops(label_image)\n    areas = [s.area for s in stats]\n    return np.mean(areas)", "full_response": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n    label_image = skimage.measure.label(binary_image)\n    stats = skimage.measure.regionprops(label_image)\n    areas = [s.area for s in stats]\n    return np.mean(areas)", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_segment_measure_umap.ipynb", "completion": "\n    import numpy as np\n    import pandas as pd\n    import umap\n    from skimage.measure import label, regionprops_table\n\n    image = np.asarray(image)\n\n    # segment\n    binary = image > 0.5 * image.max()\n    labels = label(binary)\n\n    # measure\n    dataframe = pd.DataFrame(regionprops_table(labels, intensity_image=image, \n                                              properties=['area', 'perimeter', 'mean_intensity', \n                                                          'minor_axis_length', 'major_axis_length']))\n\n    # append UMAP\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    return dataframe", "full_response": "\n    import numpy as np\n    import pandas as pd\n    import umap\n    from skimage.measure import label, regionprops_table\n\n    image = np.asarray(image)\n\n    # segment\n    binary = image > 0.5 * image.max()\n    labels = label(binary)\n\n    # measure\n    dataframe = pd.DataFrame(regionprops_table(labels, intensity_image=image, \n                                              properties=['area', 'perimeter', 'mean_intensity', \n                                                          'minor_axis_length', 'major_axis_length']))\n\n    # append UMAP\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    return dataframe", "result": "passed", "passed": true}
{"task_id": "../test_cases/workflow_watershed_segmentation_correction_measurement.ipynb", "completion": "\n    import skimage\n    blurred = skimage.filters.gaussian(image * 255, sigma=1)\n    minima = skimage.morphology.local_minima(blurred)\n    spots = skimage.measure.label(minima)\n    labels = skimage.segmentation.watershed(blurred, spots)\n    labels_without_border = skimage.segmentation.clear_border(labels)   \n    binary = labels_without_border > 0\n    return binary.sum()", "full_response": "\n    import skimage\n    blurred = skimage.filters.gaussian(image * 255, sigma=1)\n    minima = skimage.morphology.local_minima(blurred)\n    spots = skimage.measure.label(minima)\n    labels = skimage.segmentation.watershed(blurred, spots)\n    labels_without_border = skimage.segmentation.clear_border(labels)   \n    binary = labels_without_border > 0\n    return binary.sum()", "result": "passed", "passed": true}
