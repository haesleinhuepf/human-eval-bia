{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary of relevant functions separated by their category or purpose\n",
    "\n",
    "functions_by_category = {\n",
    "    \"Image Preprocessing\": [\n",
    "        \"rgb_to_grey_image_transform\",\n",
    "        \"rotate_image_by_90_degrees\",\n",
    "        \"crop_quarter_image\",\n",
    "        \"transpose_image_axes\",\n",
    "        \"remove_noise_edge_preserving\",\n",
    "        \"subtract_background_tophat\",\n",
    "        \"mask_image\",\n",
    "        \"expand_labels_without_overlap\",\n",
    "        \"detect_edges\",\n",
    "        \"convolve_images\",\n",
    "        \"deconvolve_image\",\n",
    "        \"maximum_intensity_projection\",\n",
    "        \"subsample_image\",\n",
    "        \"sum_images\",\n",
    "        \"sum_intensity_projection\",\n",
    "        \"tiled_image_processing\"\n",
    "    ],\n",
    "    \"Segmentation\": [\n",
    "        \"apply_otsu_threshold_and_count_postiive_pixels\",\n",
    "        \"region_growing_segmentation\",\n",
    "        \"workflow_watershed_segmentation_correction_measurement\",\n",
    "        \"workflow_segment_measure_umap\",\n",
    "        \"workflow_segmentation_measurement_summary\",\n",
    "        \"workflow_segmentation_counting\"\n",
    "\n",
    "    ],\n",
    "    \"Morphological Operations\": [\n",
    "        \"binary_closing\",\n",
    "        \"binary_skeleton\",\n",
    "        \"label_binary_image_and_count_labels\",\n",
    "        \"label_sequentially\",\n",
    "        \"remove_labels_on_edges\",\n",
    "        \"remove_small_labels\"\n",
    "    ],\n",
    "    \"Quantification and Measurement\": [\n",
    "        \"convex_hull_measure_area\",\n",
    "        \"count_number_of_touching_neighbors\",\n",
    "        \"measure_aspect_ratio_of_regions\",\n",
    "        \"measure_intensity_of_labels\",\n",
    "        \"measure_intensity_over_time\",\n",
    "        \"measure_mean_image_intensity\",\n",
    "        \"measure_pixel_count_of_labels\",\n",
    "        \"measure_properties_of_regions\",\n",
    "        \"extract_surface_measure_area\",\n",
    "        \"count_objects_over_time\",\n",
    "        \"count_overlapping_regions\",\n",
    "        \"radial_intensity_profile\",\n",
    "        \"fit_circle\",\n",
    "        \"create_umap\",\n",
    "        \"map_pixel_count_of_labels\",\n",
    "        \"workflow_watershed_segmentation_correction_measurement\",\n",
    "        \"workflow_segment_measure_umap\",\n",
    "        \"workflow_segmentation_measurement_summary\",\n",
    "        \"workflow_segmentation_counting\"\n",
    "    ],\n",
    "    \"Feature Extraction\": [\n",
    "        \"create_umap\",\n",
    "        \"workflow_segment_measure_umap\",\n",
    "        \"measure_properties_of_regions\",\n",
    "        \"convex_hull_measure_area\",\n",
    "        \"count_number_of_touching_neighbors\",\n",
    "        \"measure_aspect_ratio_of_regions\",\n",
    "        \"measure_intensity_of_labels\",\n",
    "        \"measure_intensity_over_time\",\n",
    "        \"measure_mean_image_intensity\",\n",
    "        \n",
    "    ],\n",
    "    \"File I/O\": [\n",
    "        \"list_image_files_in_folder\",\n",
    "        \"open_image_read_voxel_size\",\n",
    "        \"open_image_return_dimensions\",\n",
    "        \"open_nifti_image\",\n",
    "        \"open_zarr\"\n",
    "    ],\n",
    "    \"Statistical Analysis\": [\n",
    "        \"bland_altman\",\n",
    "        \"t_test\",\n",
    "        \"pair_wise_correlation_matrix\",\n",
    "        \"mean_std_column\",\n",
    "        \"mean_squared_error\",\n",
    "        \"combine_columns_of_tables\"\n",
    "    ],\n",
    "    \"Pipeline/Workflow Automation\": [\n",
    "        \"workflow_batch_process_folder_count_labels\",\n",
    "        \"workflow_batch_process_folder_measure_intensity\",\n",
    "        \"workflow_segment_measure_umap\",\n",
    "        \"workflow_segmentation_measurement_summary\",\n",
    "        \"workflow_watershed_segmentation_correction_measurement\",\n",
    "        \"tiled_image_processing\",\n",
    "        \"workflow_segmentation_counting\"\n",
    "    ],\n",
    "    \"hello_world\": [\n",
    "        \"return_hello_world\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workflow_watershed_segmentation_correction_measurement\n",
      "workflow_segment_measure_umap\n",
      "workflow_segmentation_measurement_summary\n",
      "workflow_segmentation_counting\n",
      "create_umap\n",
      "workflow_segment_measure_umap\n",
      "measure_properties_of_regions\n",
      "convex_hull_measure_area\n",
      "count_number_of_touching_neighbors\n",
      "measure_aspect_ratio_of_regions\n",
      "measure_intensity_of_labels\n",
      "measure_intensity_over_time\n",
      "measure_mean_image_intensity\n",
      "workflow_segment_measure_umap\n",
      "workflow_segmentation_measurement_summary\n",
      "workflow_watershed_segmentation_correction_measurement\n",
      "tiled_image_processing\n",
      "workflow_segmentation_counting\n"
     ]
    }
   ],
   "source": [
    "#tasks that repeat through categories\n",
    "vals = []\n",
    "for key in functions_by_category:\n",
    "    for val in functions_by_category[key]:\n",
    "        if val in vals:\n",
    "            print(val)\n",
    "        else:\n",
    "            vals.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(75)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get total number of items in dictionary \n",
    "import pandas as pd \n",
    "pd.DataFrame.from_dict(functions_by_category, orient='index').stack().reset_index(drop=True).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as a yaml file\n",
    "import yaml\n",
    "with open('functions_by_category_dict.yaml', 'w') as file:\n",
    "    documents = yaml.dump(functions_by_category, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above prompt was created using ChatGPT (GPT-4o) using the prompt:\n",
    "\n",
    "I have some python functions and each of them perform a specific operation in bioimage analysis. Classify them into categories based on their function and where they will fit in the image analysis pipeline.\n",
    "\n",
    "apply_otsu_threshold_and_count_postiive_pixels: Takes an image, applies Otsu's threshold method to it to create a binary image and counts the positive pixels.\n",
    "\n",
    "binary_closing: Applies binary closing to a binary_image with a square footprint with a given radius.\n",
    "\n",
    "binary_skeleton: Applies skeletonization to a 2D binary image.\n",
    "\n",
    "bland_altman: Takes two specified columns from a given dataframe and applies Bland-Altman-Analysis to them. Therefore, it adds two new columns, one called 'mean' containing the mean of the two corresponding values, and one called 'diff' containing the difference between the two.\n",
    "\n",
    "combine_columns_of_tables: This function combines to dataframes and makes sure the data is merged using the given index column, which must be present in both dataframes. The dataframes should be merged in a way that no data is lost and missing fields are filled with NaN.\n",
    "\n",
    "convex_hull_measure_area: Take a 3D point_cloud, determines the convex hull around the points and returns the surface area of the convex hull.\n",
    "\n",
    "convolve_images: Convolve an image with a kernel_image and return the result\n",
    "\n",
    "count_number_of_touching_neighbors: Takes a label image and returns a list of number of touching neighbors for each labeled object.\n",
    "\n",
    "count_objects_over_time: Takes a timelapse (list of binary images), counts the number of connected components and returns the resulting counts as list.\n",
    "\n",
    "count_overlapping_regions: Takes two label images and counts how many objects in label_image_1 overlap with any label in label_image_2 with at least one pixel. It returns the count of overlapping objects.\n",
    "\n",
    "create_umap: Takes a dataframe and computes a UMAP from all columns. The two UMAP vectors are stored in the dataframe as umap0 and umap1.\n",
    "\n",
    "crop_quarter_image: Crops out the first half image in both dimensions (width and height). The resulting image will be of quarter size compared to the original image.\n",
    "\n",
    "deconvolve_image: Deconvolve an image with a kernel_image and return the result.\n",
    "\n",
    "detect_edges: Applies an edge-detection filter to an image.\n",
    "\n",
    "expand_labels_without_overlap: Takes a label_image and enlarges all labels by a given radius, without labels overwriting each other.\n",
    "\n",
    "extract_surface_measure_area: Take a 3D binary_volume_image, extracts the surface of the white (voxel value != 0) object and returns the surface area of the object.\n",
    "\n",
    "fit_circle: Implements 2D circle fitting Input: Collection of 2d points, represented as a list of lists [ [x0,y0], [x1,y1], ... ]\n",
    "Output: Tuple: xc, yc, radius\n",
    "\n",
    "label_binary_image_and_count_labels: Consumes as input a binary image, applies connected component labeling to it, counts the labeled objects and returns their count as single number.\n",
    "\n",
    "label_sequentially: Takes a label_image with n labels and relabels the objects, to make sure all integer labels between 0 and n are used. No gaps are there.\n",
    "\n",
    "list_image_files_in_folder: Lists all image files in a folder.\n",
    "\n",
    "map_pixel_count_of_labels: Takes a label_image, determines the pixel-count per label and creates an image where the label values are replaced by the corresponding pixel count.\n",
    "\n",
    "mask_image: Takes a 2D input image and a 2D binary mask image, then applies the mask to the input image and returns the result.\n",
    "\n",
    "maximum_intensity_projection: Performs a maximum intensity projection along the first axis of an image.\n",
    "\n",
    "mean_squared_error: Computes the mean-squared-error of two images compared pixel-by-pixel\n",
    "\n",
    "mean_std_column: Computes the mean average and standard deviation of a specified column in a given dataframe and returns these two values.\n",
    "\n",
    "measure_aspect_ratio_of_regions: Takes a label image and returns a pandas dataframe with measurements for aspect_ratio of the objects\n",
    "\n",
    "measure_intensity_of_labels: Takes a label image and an intensity image, and returns a list of mean intensities of all pixels in the intensity image, belonging to a given label.\n",
    "\n",
    "measure_intensity_over_time: Takes a timelapse (list of images), measures the average intensity over time and returns the resulting measurements as list.\n",
    "\n",
    "measure_mean_image_intensity: Takes an image and returns its mean intensity\n",
    "\n",
    "measure_pixel_count_of_labels: Takes a label image and returns a list of counts of number of pixels per label.\n",
    "\n",
    "measure_properties_of_regions: Takes a label image and an intensity image, and returns pandas dataframe with measurements for area, perimeter and mean_intensity.\n",
    "\n",
    "open_image_read_voxel_size: Reads an image file and return its voxel size in Z-Y-X order.\n",
    "\n",
    "open_image_return_dimensions: Opens an image and returns its dimensions\n",
    "\n",
    "open_nifti_image: This function loads a nifti image from the file at image_location and returns the image data as a numpy array.\n",
    "\n",
    "open_zarr: Opens a zarr file and returns the array\n",
    "\n",
    "pair_wise_correlation_matrix: Takes a pandas dataframe and computes for all columns their Pearson's correlation coefficient for all columns in the dataframe. For n columns, this is a n x n matrix of coefficients. The matrix is returned as dataframe.\n",
    "\n",
    "radial_intensity_profile: Computes the radial intensity profile of an image around a given coordinate Inputs:\n",
    "\n",
    "image: 2d numpy array\n",
    "xy, yc: the center coordinates Output:\n",
    "an array containing the average intensities\n",
    "region_growing_segmentation: Segments an image using the region-growing/flood filling starting from a single point.\n",
    "\n",
    "remove_labels_on_edges: Takes a label_image and removes all objects which touch the image border.\n",
    "\n",
    "remove_noise_edge_preserving: Applies an edge-preserving noise-removal filter to an image.\n",
    "\n",
    "remove_small_labels: Takes a label_image and removes all objects that are smaller than a given size_threshold.\n",
    "\n",
    "return_hello_world: Returns the string \"hello world\".\n",
    "\n",
    "rgb_to_grey_image_transform: Convert an RGB image to a single-channel gray scale image with configurable weights r, g and b. The weights are normalized to be 1 in sum.\n",
    "\n",
    "rotate_image_by_90_degrees: Rotates an image by 90 degrees clockwise around the center of the image.\n",
    "\n",
    "subsample_image: Subsamples an image by skipping every n'th pixel in X and Y.\n",
    "\n",
    "subtract_background_tophat: Applies a top-hat filter with a given radius to an image with dark background (low values) and bright foreground (high values).\n",
    "\n",
    "sum_images: Sums two images pixel-by-pixel and returns the result\n",
    "\n",
    "sum_intensity_projection: Performs a maximum intensity projection along the first axis of an image.\n",
    "\n",
    "tiled_image_processing: Apply a maximum filter with a given radius to the image using a tile-by-tile strategy. The tile_size denotes the size of the tiles in X and Y.\n",
    "\n",
    "transpose_image_axes: Transposes the first two axes of an image.\n",
    "\n",
    "t_test: Takes two specified columns from a given dataframe and applies a paired T-test to it to determine the p-value.\n",
    "\n",
    "workflow_batch_process_folder_count_labels: This functions goes through all .tif image files in a specified folder, loads the images and count labels each image. It returns a dictionary with filenames and corresponding counts.\n",
    "\n",
    "workflow_batch_process_folder_measure_intensity: This functions goes through all .tif image files in a specified image folder and corresponding label images in another labels folder. It loads the images and corresponding labels, and measures min, mean and max intensity of all labels. The function returns a dataframe with five columns: min_intensity, mean_intensity, max_intensity, label and filename.\n",
    "\n",
    "workflow_segmentation_counting: This function segments objects in an image with intensity above average and returns their count.\n",
    "\n",
    "workflow_segmentation_measurement_summary: This function implements a workflow consisting of these steps:\n",
    "\n",
    "threshold intensity input image using Otsu's method\n",
    "label connected components\n",
    "measure area of the labeled objects\n",
    "determine mean area of all objects\n",
    "workflow_segment_measure_umap: This function takes a single channel intensity image, segments objects with intensity above half the maximum intensity, labels connected components, measures area, perimeter, mean_intensity, minor and major axis of the labeled objects, and produces a UMAP from the given measurements. The two UMAP vectors are saved as umap0 and umap1 togther with the measurements in a dataframe. The function returns this dataframe.\n",
    "\n",
    "workflow_watershed_segmentation_correction_measurement: This function implements a workflow consisting of these steps:\n",
    "\n",
    "blurs the image a bit\n",
    "detect local minima in the blurred image\n",
    "apply watershed segmentation flooding the blurred image from the detected minima to retrieve a label image\n",
    "remove all objects which touch the image border\n",
    "measure the area of all remaining objects together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_explor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
