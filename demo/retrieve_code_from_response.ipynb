{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3347e0fa-4825-4701-9c91-4b08c75fd56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from human_eval.data import write_jsonl, read_problems, extract_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fa3c5f1-2d7a-49c2-85d0-2a4846b900f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Here is the complete code:\\n```python\\nimport ...\n",
       "1      Plan:\\n\\n1. Import the necessary libraries for...\n",
       "2      [PYTHON]\\nimport numpy as np\\nfrom skimage imp...\n",
       "3      Here is a possible implementation of the bland...\n",
       "4      Here's the code for the function `combine_colu...\n",
       "                             ...                        \n",
       "565    Here is the complete code for the function `wo...\n",
       "566    Plan:\\n\\n1. Convert the input image to graysca...\n",
       "567    Here is the complete code for the function `wo...\n",
       "568    ```python\\nimport numpy as np\\nimport pandas a...\n",
       "569    Here is the complete code for the function `wo...\n",
       "Name: full_response, Length: 570, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"../data/samples_codellama.jsonl\", lines=True)\n",
    "df[\"full_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7251bbad-8ae8-42f9-ac0d-a46f01b6d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../data/\"\n",
    "\n",
    "collection = []\n",
    "for filename in os.listdir(directory):\n",
    "    jsonl_file = filename.endswith(\".jsonl\") and not filename.endswith(\"results.jsonl\") and not filename.endswith(\"bia.jsonl\")\n",
    "    results_jsonl_file = filename.endswith(\"_results.jsonl\")\n",
    "    if jsonl_file:\n",
    "        df = pd.read_json(directory + filename, lines=True)\n",
    "        df['model'] = filename.replace(\".jsonl\", \"\").replace(\"samples_\", \"\")\n",
    "        collection.append(df)\n",
    "    # if results_jsonl_file:\n",
    "    #     df = pd.read_json(directory + filename, lines=True)\n",
    "    #     df['model'] = filename.replace(\"_results.jsonl\", \"\").replace(\"samples_\", \"\")\n",
    "    #     collection.append(df)\n",
    "\n",
    "df = pd.concat(collection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b17733a-dbc0-4c76-a80a-e6214dfa7ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>completion</th>\n",
       "      <th>full_response</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../test_cases/apply_otsu_threshold_and_count_p...</td>\n",
       "      <td>\\n# Plan:\\n# 1. Import required libraries (cv2...</td>\n",
       "      <td>Here's the completed code with a step-by-step ...</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../test_cases/binary_closing.ipynb</td>\n",
       "      <td>\\n# Plan:\\n# 1. Import necessary libraries (nu...</td>\n",
       "      <td>Here's the completed code with a plan, necessa...</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../test_cases/binary_skeleton.ipynb</td>\n",
       "      <td>\\n# Plan:\\n# 1. Import necessary libraries (sk...</td>\n",
       "      <td>Here's the completed code with a step-by-step ...</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../test_cases/bland_altman.ipynb</td>\n",
       "      <td>\\n# Plan:\\n# 1. Import required libraries (pan...</td>\n",
       "      <td>Here's the completed code with a plan, necessa...</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../test_cases/combine_columns_of_tables.ipynb</td>\n",
       "      <td>\\n# Plan:\\n# 1. Import required library (panda...</td>\n",
       "      <td>Here's the completed code with a step-by-step ...</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>../test_cases/workflow_batch_process_folder_me...</td>\n",
       "      <td>\\n    import os\\n    import pandas as pd\\n    ...</td>\n",
       "      <td>\\n    import os\\n    import pandas as pd\\n    ...</td>\n",
       "      <td>reference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>../test_cases/workflow_segmentation_counting.i...</td>\n",
       "      <td>\\n    import skimage\\n    import numpy as np\\n...</td>\n",
       "      <td>\\n    import skimage\\n    import numpy as np\\n...</td>\n",
       "      <td>reference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>../test_cases/workflow_segmentation_measuremen...</td>\n",
       "      <td>\\n    import skimage\\n    import numpy as np\\n...</td>\n",
       "      <td>\\n    import skimage\\n    import numpy as np\\n...</td>\n",
       "      <td>reference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>../test_cases/workflow_segment_measure_umap.ipynb</td>\n",
       "      <td>\\n    import numpy as np\\n    import pandas as...</td>\n",
       "      <td>\\n    import numpy as np\\n    import pandas as...</td>\n",
       "      <td>reference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>../test_cases/workflow_watershed_segmentation_...</td>\n",
       "      <td>\\n    import skimage\\n    blurred = skimage.fi...</td>\n",
       "      <td>\\n    import skimage\\n    blurred = skimage.fi...</td>\n",
       "      <td>reference</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11400 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               task_id  \\\n",
       "0    ../test_cases/apply_otsu_threshold_and_count_p...   \n",
       "1                   ../test_cases/binary_closing.ipynb   \n",
       "2                  ../test_cases/binary_skeleton.ipynb   \n",
       "3                     ../test_cases/bland_altman.ipynb   \n",
       "4        ../test_cases/combine_columns_of_tables.ipynb   \n",
       "..                                                 ...   \n",
       "565  ../test_cases/workflow_batch_process_folder_me...   \n",
       "566  ../test_cases/workflow_segmentation_counting.i...   \n",
       "567  ../test_cases/workflow_segmentation_measuremen...   \n",
       "568  ../test_cases/workflow_segment_measure_umap.ipynb   \n",
       "569  ../test_cases/workflow_watershed_segmentation_...   \n",
       "\n",
       "                                            completion  \\\n",
       "0    \\n# Plan:\\n# 1. Import required libraries (cv2...   \n",
       "1    \\n# Plan:\\n# 1. Import necessary libraries (nu...   \n",
       "2    \\n# Plan:\\n# 1. Import necessary libraries (sk...   \n",
       "3    \\n# Plan:\\n# 1. Import required libraries (pan...   \n",
       "4    \\n# Plan:\\n# 1. Import required library (panda...   \n",
       "..                                                 ...   \n",
       "565  \\n    import os\\n    import pandas as pd\\n    ...   \n",
       "566  \\n    import skimage\\n    import numpy as np\\n...   \n",
       "567  \\n    import skimage\\n    import numpy as np\\n...   \n",
       "568  \\n    import numpy as np\\n    import pandas as...   \n",
       "569  \\n    import skimage\\n    blurred = skimage.fi...   \n",
       "\n",
       "                                         full_response  \\\n",
       "0    Here's the completed code with a step-by-step ...   \n",
       "1    Here's the completed code with a plan, necessa...   \n",
       "2    Here's the completed code with a step-by-step ...   \n",
       "3    Here's the completed code with a plan, necessa...   \n",
       "4    Here's the completed code with a step-by-step ...   \n",
       "..                                                 ...   \n",
       "565  \\n    import os\\n    import pandas as pd\\n    ...   \n",
       "566  \\n    import skimage\\n    import numpy as np\\n...   \n",
       "567  \\n    import skimage\\n    import numpy as np\\n...   \n",
       "568  \\n    import numpy as np\\n    import pandas as...   \n",
       "569  \\n    import skimage\\n    blurred = skimage.fi...   \n",
       "\n",
       "                          model  \n",
       "0    claude-3-5-sonnet-20240620  \n",
       "1    claude-3-5-sonnet-20240620  \n",
       "2    claude-3-5-sonnet-20240620  \n",
       "3    claude-3-5-sonnet-20240620  \n",
       "4    claude-3-5-sonnet-20240620  \n",
       "..                          ...  \n",
       "565                   reference  \n",
       "566                   reference  \n",
       "567                   reference  \n",
       "568                   reference  \n",
       "569                   reference  \n",
       "\n",
       "[11400 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3e62ac8-4624-4680-821e-693f8eb9588d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncode\\n\\ncode2\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"\"\"\n",
    "hallo\n",
    "```\n",
    "code\n",
    "```\n",
    "bla\n",
    "```\n",
    "code2\n",
    "```\n",
    "\"\"\"\n",
    "extract_python(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adbd273b-e041-4532-b56a-0d6c61691ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function-mapping to extract python code from full_response\n",
    "output_dir = directory # overwrite input\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "df[\"completion\"] = df[\"full_response\"].astype(str).apply(extract_python)\n",
    "grouped = df.groupby(\"model\")\n",
    "\n",
    "for name, group in grouped:\n",
    "    records = group.drop(\"model\", axis=1).to_dict(\"records\")\n",
    "    write_jsonl(f\"{output_dir}/samples_{name}.jsonl\", records)\n",
    "\n",
    "# Testing code after \n",
    "for filename in os.listdir(directory):\n",
    "    jsonl_file = filename.endswith(\".jsonl\") and not filename.endswith(\"results.jsonl\") and not filename.endswith(\"bia.jsonl\")\n",
    "    results_jsonl_file = filename.endswith(\"_results.jsonl\")\n",
    "    if jsonl_file:\n",
    "        model_id = filename.split(\".jsonl\")[0]\n",
    "        df_orig = pd.read_json(directory+filename, lines=True)\n",
    "        df_new = pd.read_json(f\"{output_dir}{model_id}.jsonl\", lines=True)\n",
    "        \n",
    "        if not df_orig.equals(df_new):\n",
    "            # checks inequalities\n",
    "            num_diff = np.size(np.where(~np.all((df_orig == df_new).to_numpy(), axis=1)))\n",
    "            print(f\"{model_id} is different in {num_diff} entries\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
